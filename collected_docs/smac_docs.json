[
  {
    "title": "Getting Started - SMAC3",
    "content": "Getting Started\n#\nSMAC needs four core components (configuration space, target function, scenario and a facade) to run an\noptimization process, all of which are explained on this page.\nThey interact in the following way:\nInteraction of SMAC's components\nConfiguration Space\n#\nThe configuration space defines the search space of the hyperparameters and, therefore, the tunable parameters' legal\nranges and default values.\nfrom\nConfigSpace\nimport\nConfigSpace\ncs\n=\nConfigurationSpace\n({\n\"myfloat\"\n:\n(\n0.1\n,\n1.5\n),\n# Uniform Float\n\"myint\"\n:\n(\n2\n,\n10\n),\n# Uniform Integer\n\"species\"\n:\n[\n\"mouse\"\n,\n\"cat\"\n,\n\"dog\"\n],\n# Categorical\n})\nPlease see the documentation of\nConfigurationSpace\nfor more details.\nTarget Function\n#\nThe target function takes a configuration from the configuration space and returns a performance value.\nFor example, you could use a Neural Network to predict on your data and get some validation performance.\nIf, for instance, you would tune the learning rate of the Network's optimizer, every learning rate will\nchange the final validation performance of the network. This is the target function.\nSMAC tries to find the best performing learning rate by trying different values and evaluating the target function -\nin an efficient way.\ndef\ntrain\n(\nself\n,\nconfig\n:\nConfiguration\n,\nseed\n:\nint\n)\n->\nfloat\n:\nmodel\n=\nMultiLayerPerceptron\n(\nlearning_rate\n=\nconfig\n[\n\"learning_rate\"\n])\nmodel\n.\nfit\n(\n...\n)\naccuracy\n=\nmodel\n.\nvalidate\n(\n...\n)\nreturn\n1\n-\naccuracy\n# SMAC always minimizes (the smaller the better)\nNote\nIn general, the arguments of the target function depend on the intensifier. However,\nin all cases, the first argument must be the configuration (arbitrary argument name is possible here) and a seed.\nIf you specified instances in the scenario, SMAC requires\ninstance\nas argument additionally. If you use\nSuccessiveHalving\nor\nHyperband\nas intensifier but you did not specify instances, SMAC passes\nbudget\nas\nargument to the target function. But don't worry: SMAC will tell you if something is missing or if something is not\nused.\nWarning\nSMAC\nalways\nminimizes the value returned from the target function.\nWarning\nSMAC passes either\ninstance\nor\nbudget\nto the target function but never both.\nScenario\n#\nThe\nScenario\nis used to provide environment variables. For example, \nif you want to limit the optimization process by a time limit or want to specify where to save the results.\nfrom\nsmac\nimport\nScenario\nscenario\n=\nScenario\n(\nconfigspace\n=\ncs\n,\nname\n=\n\"experiment_name\"\n,\noutput_directory\n=\nPath\n(\n\"your_output_directory\"\n)\nwalltime_limit\n=\n120\n,\n# Limit to two minutes\nn_trials\n=\n500\n,\n# Evaluated max 500 trials\nn_workers\n=\n8\n,\n# Use eight workers\n...\n)\nNote\nIf no\nname\nis given, a hash of the experiment is used. Running the same experiment again at a later time will result in exactly the same hash. This is important, because the optimization will warmstart on the preexisting evaluations, if not otherwise specified in the\nFacade\n.\nFacade\n#\nWarn\nBy default Facades will try to warmstart on preexisting logs. This behavior can be specified using the\noverwrite\nparameter.\nA\nfacade\nis the entry point to SMAC, which constructs a default optimization \npipeline for you. SMAC offers various facades, which satisfy many common use cases and are crucial to\nachieving peak performance. The idea behind the facades is to provide a simple interface to all of SMAC's components,\nwhich is easy to use and understand and without the need of deep diving into the material. However, experts are\ninvited to change the components to their specific hyperparameter optimization needs. The following\ntable (horizontally scrollable) shows you what is supported and reveals the default\ncomponents\n:\nBlack-Box\nHyperparameter Optimization\nMulti-Fidelity\nAlgorithm Configuration\nRandom\nHyperband\n#Parameters\nlow\nlow/medium/high\nlow/medium/high\nlow/medium/high\nlow/medium/high\nlow/medium/high\nSupports Instances\n❌\n✅\n✅\n✅\n✅\n✅\nSupports Multi-Fidelity\n❌\n❌\n✅\n✅\n❌\n✅\nInitial Design\nSobol\nSobol\nRandom\nDefault\nDefault\nDefault\nSurrogate Model\nGaussian Process\nRandom Forest\nRandom Forest\nRandom Forest\nNot used\nNot used\nAcquisition Function\nExpected Improvement\nLog Expected Improvement\nLog Expected Improvement\nExpected Improvement\nNot used\nNot used\nAcquisition Maximizer\nLocal and Sorted Random Search\nLocal and Sorted Random Search\nLocal and Sorted Random Search\nLocal and Sorted Random Search\nNot Used\nNot Used\nIntensifier\nDefault\nDefault\nHyperband\nDefault\nDefault\nHyperband\nRunhistory Encoder\nDefault\nLog\nLog\nDefault\nDefault\nDefault\nRandom Design Probability\n8.5%\n20%\n20%\n50%\nNot used\nNot used\nInfo\nThe multi-fidelity facade is the closest implementation to\nBOHB\n.\nNote\nWe want to emphasize that SMAC is a highly modular optimization framework.\nThe facade accepts many arguments to specify components of the pipeline. Please also note, that in contrast\nto previous versions, instantiated objects are passed instead of\nkwargs\n.\nThe facades can be imported directly from the\nsmac\nmodule.\nfrom\nsmac\nimport\nBlackBoxFacade\nas\nBBFacade\nfrom\nsmac\nimport\nHyperparameterOptimizationFacade\nas\nHPOFacade\nfrom\nsmac\nimport\nMultiFidelityFacade\nas\nMFFacade\nfrom\nsmac\nimport\nAlgorithmConfigurationFacade\nas\nACFacade\nfrom\nsmac\nimport\nRandomFacade\nas\nRFacade\nfrom\nsmac\nimport\nHyperbandFacade\nas\nHBFacade\nsmac\n=\nHPOFacade\n(\nscenario\n=\nscenario\n,\ntarget_function\n=\ntrain\n)\nsmac\n=\nMFFacade\n(\nscenario\n=\nscenario\n,\ntarget_function\n=\ntrain\n)\nsmac\n=\nACFacade\n(\nscenario\n=\nscenario\n,\ntarget_function\n=\ntrain\n)\nsmac\n=\nRFacade\n(\nscenario\n=\nscenario\n,\ntarget_function\n=\ntrain\n)\nsmac\n=\nHBFacade\n(\nscenario\n=\nscenario\n,\ntarget_function\n=\ntrain\n)",
    "url": "https://automl.github.io/SMAC3/latest/3_getting_started/"
  },
  {
    "title": "Multi-Fidelity Optimization - SMAC3",
    "content": "Multi-Fidelity Optimization\n#\nMulti-fidelity refers to running an algorithm on multiple budgets (such as number of epochs or\nsubsets of data) and thereby evaluating the performance prematurely. You can run a multi-fidelity optimization\nwhen using\nSuccessive Halving\nor\nHyperband\n.\nHyperband\nis the default intensifier in the\nmulti-fidelity facade\nand requires the arguments\nmin_budget\nand\nmax_budget\nin the scenario if no instances are used.\nIn general, multi-fidelity works for both real-valued and instance budgets. In the real-valued case,\nthe budget is directly passed to the target function. In the instance case, the budget is not passed to the \ntarget function but\nmin_budget\nand\nmax_budget\nare used internally to determine the number of instances of \neach stage. That's also the reason why\nmin_budget\nand\nmax_budget\nare\nnot required\nwhen using instances: \nThe\nmax_budget\nis simply the max number of instances, whereas the\nmin_budget\nis simply 1.\nWarning\nsmac.main.config_selector.ConfigSelector\ncontains the\nmin_trials\nparameter. This parameter determines\nhow many samples are required to train the surrogate model. If budgets are involved, the highest budgets \nare checked first. For example, if min_trials is three, but we find only two trials in the runhistory for\nthe highest budget, we will use trials of a lower budget instead.\nPlease have a look into our\nmulti-fidelity examples\nto see how to use\nmulti-fidelity optimization in real-world applications.",
    "url": "https://automl.github.io/SMAC3/latest/advanced_usage/2_multi_fidelity/"
  },
  {
    "title": "Components - SMAC3",
    "content": "Components\n#\nIn addition to the basic components mentioned in\nGetting Started\n, all other components are\nexplained in the following paragraphs to give a better picture of SMAC. These components are all used to guide\nthe optimization process and simple changes can influence the results drastically.\nBefore diving into the components, we shortly want to explain the main Bayesian optimization loop in SMAC.\nThe\nSMBO\nreceives all instantiated components from the facade and the logic happens here.\nIn general, a while loop is used to ask for the next trial, submit it to the runner, and wait for the runner to \nfinish the evaluation. Since the runner and the\nSMBO\nobject are decoupled, the while loop continues and asks for even \nmore trials (e.g., in case of multi-threading), which also can be submitted to the runner. If all workers are\noccupied, SMAC will wait until a new worker is available again. Moreover, limitations like wallclock time and remaining \ntrials are checked in every iteration.\nSurrogate Model\n#\nThe surrogate model is used to approximate the objective function of configurations. In previous versions, the model was \nreferred to as the Empirical Performance Model (EPM). Mostly, Bayesian optimization is used/associated with Gaussian\nprocesses. However, SMAC also incorporates random forests as surrogate models, which makes it possible to optimize for \nhigher dimensional and complex spaces.\nThe data used to train the surrogate model is collected by the runhistory encoder (receives data from the runhistory \nand transforms it). If budgets are\ninvolved, the highest budget which satisfies\nmin_trials\n(defaults to 1) in\nsmac.main.config_selector\nis\nused. If no budgets are used, all observations are used.\nIf you are using instances, it is recommended to use instance features. The model is trained on each instance \nassociated with its features. Imagine you have two hyperparameters, two instances and no instance features, the model \nwould be trained on:\nHP 1\nHP 2\nObjective Value\n0.1\n0.8\n0.5\n0.1\n0.8\n0.75\n505\n7\n2.4\n505\n7\n1.3\nYou can see that the same inputs lead to different objective values because of two instances. If you associate\neach instance with a feature, you would end-up with the following data points:\nHP 1\nHP 2\nInstance Feature\nObjective Value\n0.1\n0.8\n0\n0.5\n0.1\n0.8\n1\n0.75\n505\n7\n0\n2.4\n505\n7\n1\n1.3\nThe steps to receiving data are as follows:\nThe intensifier requests new configurations via\nnext(self.config_generator)\n.\nThe config selector collects the data via the runhistory encoder which iterates over the runhistory trials.\nThe runhistory encoder only collects trials which are in\nconsidered_states\nand timeout trials. Also, only the\n   highest budget is considered if budgets are used. In this step, multi-objective values are scalarized using the\nnormalize_costs\nfunction (uses\nobjective_bounds\nfrom the runhistory) and the multi-objective algorithm.\n   For example, when ParEGO is used, the scalarization would be different in each training.\nThe selected trial objectives are transformed (e.g., log-transformed, depending on the selected\n   encoder).\nThe hyperparameters might still have inactive values. The model takes care of that after the collected data\n   are passed to the model.\nAcquisition Function\n#\nAcquisition functions are mathematical techniques that guide how the parameter space should be explored during Bayesian \noptimization. They use the predicted mean and predicted variance generated by the surrogate model.\nThe acquisition function is used by the acquisition maximizer (see next section). Otherwise, SMAC provides\na bunch of different acquisition functions (Lower Confidence Bound, Expected Improvement, Probability Improvement, \nThompson, integrated acquisition functions and prior acquisition functions). We refer to literature \nfor more information about acquisition functions.\nNote\nThe acquisition function calculates the acquisition value for each configuration. However, the configurations\nare provided by the acquisition maximizer. Therefore, the acquisition maximizer is responsible for receiving\nthe next configurations.\nAcquisition Maximize\n#\nThe acquisition maximizer is a wrapper for the acquisition function. It returns the next configurations. SMAC\nsupports local search, (sorted) random search, local and (sorted) random search, and differential evolution.\nWhile local search checks neighbours of the best configurations, random search makes sure to explore the configuration\nspace. When using sorted random search, random configurations are sorted by the value of the acquisition function.\nWarning\nPay attention to the number of challengers: If you experience RAM issues or long computational times in the\nacquisition function, you might lower the number of challengers.\nThe acquisition maximizer also incorporates the\nRandom Design\n. Please see the\nChallengerList\nfor more information.\nInitial Design\n#\nThe surrogate model needs data to be trained. Therefore, the initial design is used to generate the initial data points.\nWe provide random, latin hypercube, sobol, factorial and default initial designs. The default initial design uses\nthe default configuration from the configuration space and with the factorial initial design, we generate corner\npoints of the configuration space. The sobol sequences are an example of quasi-random low-discrepancy sequences and\nthe latin hypercube design is a statistical method for generating a near-random sample of parameter values from\na multidimensional distribution.\nThe initial design configurations are yielded by the config selector first. Moreover, the config selector keeps\ntrack of which configurations already have been returned to make sure a configuration is not returned twice.\nRandom Design\n#\nThe random design is used in the acquisition maximizer to tell whether the next configuration should be\nrandom or sampled from the acquisition function. For example, if we use a random design with a probability of \n50%, we have a 50% chance to sample a random configuration and a 50% chance to sample a configuration from the\nacquisition function (although the acquisition function includes exploration and exploitation trade-off already). \nThis design makes sure that the optimization process is not stuck in a local optimum and we \nare\nguaranteed\nto find the best configuration over time.\nIn addition to simple probability random design, we also provide annealing and modulus random design.\nIntensifier\n#\nThe intensifier compares different configurations based on evaluated :term:\ntrial<Trial>\nso far. It decides\nwhich configuration should be\nintensified\nor, in other words, if a configuration is worth to spend more time on (e.g.,\nevaluate another seed pair, evaluate on another instance, or evaluate on a higher budget).\nWarning\nAlways pay attention to\nmax_config_calls\nor\nn_seeds\n: If this argument is set high, the intensifier might \nspend a lot of time on a single configuration.\nDepending on the components and arguments, the intensifier tells you which seeds, budgets, and/or instances\nare used throughout the optimization process. You can use the methods\nuses_seeds\n,\nuses_budgets\n, and\nuses_instances\n(directly callable via the facade) to (sanity-)check whether the intensifier uses these arguments.\nAnother important fact is that the intensifier keeps track of the current incumbent (a.k.a. the best configuration \nfound so far). In case of multi-objective, multiple incumbents could be found.\nAll intensifiers support multi-objective, multi-fidelity, and multi-threading:\nMulti-Objective: Keeping track of multiple incumbents at once.\nMulti-Fidelity: Incorporating instances or budgets.\nMulti-Threading: Intensifier are implemented as generators so that calling\nnext\non the intensifier can be\n  repeated as often as needed. Intensifier are not required to receive results as the results are directly taken from\n  the runhistory.\nNote\nAll intensifiers are working on the runhistory and recognize previous logged trials (e.g., if the user already\nevaluated something beforehand). Previous configurations (in the best case, also complete trials) are added to the \nqueue/tracker again so that they are integrated into the intensification process.\nThat means continuing a run as well as incorporating user inputs are natively supported.\nConfiguration Selector\n#\nThe configuration selector uses the initial design, surrogate model, acquisition maximizer/function, runhistory,\nrunhistory encoder, and random design to select the next configuration. The configuration selector is directly\nused by the intensifier and is called everytime a new configuration is requested.\nThe idea behind the configuration selector is straight forward:\nYield the initial design configurations.\nTrain the surrogate model with the data from the runhistory encoder.\nGet the next\nretrain_after\nconfigurations from the acquisition function/maximizer and yield them.\nAfter all\nretrain_after\nconfigurations were yield, go back to step 2.\nNote\nThe configuration selector is a generator and yields configurations. Therefore, the current state of the \nselector is saved and when the intensifier calls\nnext\n, the selector continues there where it stopped.\nNote\nEverytime the surrogate model is trained, the multi-objective algorithm is updated via\nupdate_on_iteration_start\n.\nMulti-Objective Algorithm\n#\nThe multi-objective algorithm is used to scalarize multi-objective values. The multi-objective algorithm \ngets normalized objective values passed and returns a single value. The resulting value (called by the \nrunhistory encoder) is then used to train the surrogate model.\nWarning\nDepending on the multi-objective algorithm, the values for the runhistory encoder might differ each time \nthe surrogate model is trained. Let's take ParEGO for example:\nEverytime a new configuration is sampled (see ConfigSelector), the objective weights are updated. Therefore,\nthe scalarized values are different and the acquisition maximizer might return completely different configurations.\nRunHistory\n#\nThe runhistory holds all (un-)evaluated trials of the optimization run. You can use the runhistory to \nget (running) configs, (running) trials, trials of a specific config, and more.\nThe runhistory encoder iterates over the runhistory to receive data for the surrogate model. The following \ncode shows how to iterate over the runhistory:\nsmac\n=\nHPOFacade\n(\n...\n)\n# Iterate over all trials\nfor\ntrial_info\n,\ntrial_value\nin\nsmac\n.\nrunhistory\n.\nitems\n():\n# Trial info\nconfig\n=\ntrial_info\n.\nconfig\ninstance\n=\ntrial_info\n.\ninstance\nbudget\n=\ntrial_info\n.\nbudget\nseed\n=\ntrial_info\n.\nseed\n# Trial value\ncost\n=\ntrial_value\n.\ncost\ntime\n=\ntrial_value\n.\ntime\nstatus\n=\ntrial_value\n.\nstatus\nstarttime\n=\ntrial_value\n.\nstarttime\nendtime\n=\ntrial_value\n.\nendtime\nadditional_info\n=\ntrial_value\n.\nadditional_info\n# Iterate over all configs\nfor\nconfig\nin\nsmac\n.\nrunhistory\n.\nget_configs\n():\n# Get the cost of all trials of this config\naverage_cost\n=\nsmac\n.\nrunhistory\n.\naverage_cost\n(\nconfig\n)\nWarning\nThe intensifier uses a callback to update the incumbent everytime a new trial is added to the runhistory.\nRunHistory Encoder\n#\nThe runhistory encoder is used to encode the runhistory data into a format that can be used by the surrogate model.\nOnly trials with the status\nconsidered_states\nand timeout trials are considered. Multi-objective values are \nscalarized using the\nnormalize_costs\nfunction (uses\nobjective_bounds\nfrom the runhistory). Afterwards, the \nnormalized value is processed by the multi-objective algorithm.\nCallback\n#\nCallbacks provide the ability to easily execute code before, inside, and after the Bayesian optimization loop.\nTo add a callback, you have to inherit from\nsmac.Callback\nand overwrite the methods (if needed).\nAfterwards, you can pass the callbacks to any facade.\nfrom\nsmac\nimport\nMultiFidelityFacade\n,\nCallback\nclass\nCustomCallback\n(\nCallback\n):\ndef\non_start\n(\nself\n,\nsmbo\n:\nSMBO\n)\n->\nNone\n:\npass\ndef\non_end\n(\nself\n,\nsmbo\n:\nSMBO\n)\n->\nNone\n:\npass\ndef\non_iteration_start\n(\nself\n,\nsmbo\n:\nSMBO\n)\n->\nNone\n:\npass\ndef\non_iteration_end\n(\nself\n,\nsmbo\n:\nSMBO\n,\ninfo\n:\nRunInfo\n,\nvalue\n:\nRunValue\n)\n->\nbool\n|\nNone\n:\n# We just do a simple printing here\nprint\n(\ninfo\n,\nvalue\n)\nsmac\n=\nMultiFidelityFacade\n(\n...\ncallbacks\n=\n[\nCustomCallback\n()]\n)\nsmac\n.\noptimize\n()",
    "url": "https://automl.github.io/SMAC3/latest/advanced_usage/1_components/"
  }
]