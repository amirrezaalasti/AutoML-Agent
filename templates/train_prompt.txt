**Generate a production-grade Python training function for machine learning with the following STRICT requirements:**

---

### ** CRITICAL ERROR HANDLING RULE:**
**ABSOLUTELY NO try/except BLOCKS ALLOWED!**
* **Why**: Try/except blocks hide real errors and make debugging impossible
* **Instead**: Use proper validation, type checking, and explicit error handling
* **If errors occur**: Let them propagate naturally so they can be identified and fixed
* **This is a HARD REQUIREMENT**: Any code with try/except will be rejected

---

### ** CRITICAL GENERALIZATION RULE:**
**ABSOLUTELY NO HARDCODED DIMENSIONS OR SHAPES!**
* **Why**: The function must be reusable for different datasets. Hardcoding values like `(48000, 3072)` or `10` classes makes the function brittle and useless.
* **Instead**: All dimensions **must** be inferred dynamically from the input `dataset` object.
* **Examples**:
    * **Get number of features from `X.shape[1]`**.
    * **Get number of samples from `X.shape[0]`**.
    * **Get number of classes from the unique values in `y`**.
* **This is a HARD REQUIREMENT**: Any code with hardcoded shapes will be rejected.

---
* Recommended steps to write the train function based on the planner:
  * `{train_function_plan}`
---

### **Function signature** must be:

```python
from ConfigSpace import Configuration
from typing import Any
def train(cfg: Configuration, dataset: Any, seed: int, model_dir: str = None) -> float:
```

---

### **Function Behavior Requirements:**

* The function **must** handle the dataset properly:
  * Dataset Description: `{dataset_description}`
  * ConfigSpace Definition: `{config_space}`
  * SMAC Scenario: `{scenario}`

* The function **must** accept a `dataset` dictionary with:
  * `dataset['X']`: feature matrix or input tensor
  * `dataset['y']`: label vector or label tensor

* The function **must** handle the configuration properly:
  * Access primitive values using `cfg.get('key')`
  * Handle all hyperparameters defined in the configuration space
  * Apply proper type conversion and validation
  * Handle conditional hyperparameters correctly
  * type of some keys like batch_size or some numeric keys can be **numpy.int64**, int, float, ...

* **Model Requirements:**
  * Infer input and output dimensions dynamically
  * Follow data format requirements
  * Handle necessary data transformations
  * Implement proper model initialization
  * Use appropriate loss functions
  * Apply proper regularization
  * Handle model-specific requirements

* **Training Requirements:**
  * Implement proper training loop
  * Handle batch processing
  * Apply proper optimization
  * Implement early stopping if needed
  * Handle validation if required
  * Return appropriate loss value

* **Model Saving Requirements:**
  * **MUST save the trained model** if `model_dir` is provided
  * Create the directory if it doesn't exist
  * Save model in appropriate format for the framework:
    * **PyTorch**: Use `torch.save(model.state_dict(), model_path)` or `torch.save(model, model_path)`
    * **TensorFlow**: Use `model.save(model_path)` or `tf.saved_model.save(model, model_path)`
    * **scikit-learn**: Use `joblib.dump(model, model_path)` or `pickle.dump(model, open(model_path, 'wb'))`
  * Generate unique model filename using timestamp or configuration hash
  * Save model metadata (configuration, performance metrics) if possible
  * Ensure the saved model can be loaded later for inference

* **Performance Optimization Requirements:**
  * Minimize memory usage and allocations
  * Use vectorized operations where possible
  * Avoid unnecessary data copying
  * Optimize data loading and preprocessing
  * Use efficient data structures
  * Minimize CPU/GPU synchronization
  * Implement efficient batch processing if necessary
  * Use appropriate device placement (CPU/GPU)
  * Optimize model forward/backward passes
  * Minimize Python overhead
  * For Neural Networks use GPU if available

* **Code Optimization Requirements:**
  * Keep code minimal and focused
  * Avoid redundant computations
  * Use efficient algorithms
  * Minimize function calls
  * Optimize loops and iterations
  * Use appropriate data types
  * Avoid unnecessary object creation
  * Use appropriate caching strategies
  * The train function should be computational efficient

* **Best Practices:**
  * Implement proper logging
  * Handle edge cases
  * Ensure reproducibility
  * Optimize performance
  * Follow framework best practices
  * For tracking the progress add prints

---

### **Frameworks:**

Choose **one** of the following frameworks based on the dataset and requirements:
* **PyTorch**: For deep learning tasks
* **TensorFlow**: For deep learning tasks
* **scikit-learn**: For traditional ML tasks

---

### **Output Format:**

* Return **only** the `train()` function
* Include necessary imports
* No example usage or additional code
* The function must be self-contained and executable
* Code must be minimal and optimized for performance

---

### **Error Prevention (NO try/except):**

* **VALIDATE ALL INPUTS EXPLICITLY** - Check types, shapes, ranges
* **HANDLE MISSING PARAMETERS** - Use default values or raise clear errors
* **CHECK DATA TYPES AND SHAPES** - Validate before processing
* **HANDLE EDGE CASES** - Use conditional logic, not exception handling
* **IMPLEMENT PROPER VALIDATION** - Use assertions or explicit checks
* **RAISE CLEAR ERRORS** - Let errors propagate naturally for debugging

---

### **Example Structure (NO try/except):**

```python
def train(cfg: Configuration, dataset: Any, seed: int, model_dir: str = None) -> float:
    # Set random seed for reproducibility
    
    # Extract hyperparameters efficiently
    sample_config = cfg.get('sample_config')
    
    # Prepare data efficiently
    
    # Initialize model with optimized parameters
    
    # Optimized training loop

    # Save model if directory is provided
    if model_dir:
        os.makedirs(model_dir, exist_ok=True)
        model_path = os.path.join(model_dir, f"model_{{seed}}.pth")
        torch.save(model.state_dict(), model_path)
    
    return loss
```

---

** FINAL REMINDER - CRITICAL REQUIREMENTS:**
* Valid `import` statements
* A single `train()` function that returns a float loss value
* No additional code or explanations
* Code must be optimized for performance and minimal in size
* For accuracy metrics, return negative accuracy (e.g. -accuracy)
* For error metrics, return the raw error value (e.g. mse, rmse)
* Ensure consistent sign convention across all metrics
* **MUST save the trained model** if `model_dir` parameter is provided
* ** ABSOLUTELY NO try/except BLOCKS - USE EXPLICIT VALIDATION INSTEAD**
* ** IF ERRORS OCCUR, LET THEM PROPAGATE NATURALLY FOR DEBUGGING**
* ** The train function and the choice of model should match the configuration