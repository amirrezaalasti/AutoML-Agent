**Generate production-grade Python code for a machine learning training function with the following STRICT requirements:**

---

### **Function signature** must be:

```python
from ConfigSpace import Configuration
def train(cfg: Configuration, seed: int, dataset: Any) -> float:
```

---

### **Function Behavior Requirements:**

* The function **must accept** a `dataset` dictionary with:

  * `dataset['X']`: feature matrix or input tensor
  * `dataset['y']`: label vector or label tensor

* Assume `cfg` is a sampled configuration object:

  * Access primitive values using `cfg.get('key')` (only `int`, `float`, `str`, etc.).
  * **Do not access or manipulate non-primitive hyperparameter objects**.
  * Set `random_state=seed` or equivalent to ensure reproducibility in your chosen framework.

* The function must return the **average training loss** over 10 epochs.

* You must check whether dataset['X'] is already image-shaped (e.g., len(X.shape) == 4). If not, and CNN is used, reshape carefully and raise a ValueError if the input size is not a perfect square.

* Do not assume dataset['X'] has a specific shape. Always verify input dimensions before reshaping.

* If using a CNN model, you must validate that reshaping is safe and explain your assumption.

```python
return loss  # float
```

* Lower `loss` means a better model.

---

### **Frameworks**

You may choose **PyTorch**, **TensorFlow**, or **scikit-learn**, depending on the dataset and supporting code provided.

---

### **Model Requirements**

* Infer input and output dimensions dynamically from the dataset:

  ```python
  input_size = dataset['X'].shape[1]
  num_classes = len(np.unique(dataset['y']))
  ```

---

### **Optimizer Logic**

If `learning_rate` is specified in `cfg`, use:

* `'constant'`:

  * Use SGD with `lr=eta0` (supported in all frameworks)
* `'invscaling'`:

  * Use SGD with `lr=eta0` and `momentum=power_t` (if supported, otherwise fall back gracefully)
* `'adaptive'`:

  * Use Adam or equivalent with `lr=eta0`

- Only use valid parameters for each optimizer. Do **not** use unsupported arguments (e.g., `eta0` in PyTorch ASGD or `AdaptiveASGD`).

---

### **Supporting Code Provided:**

* ConfigSpace definition: `{config_space}`
* SMAC scenario: `{scenario}`
* Dataset description: `{dataset_description}`

---

### **Additional Instructions**

* The code must not hardcode dataset dimensions like `784` or class count `10`.
* The function must be runnable and not assume unavailable classes or modules.
* You must only output the `def train(...)` function and nothing else.
