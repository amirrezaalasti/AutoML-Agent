**Generate a production-grade Python training function for machine learning with the following STRICT requirements:**

---

### **Function signature** must be:

```python
from ConfigSpace import Configuration
from typing import Any
def train(cfg: Configuration, dataset: Any, seed: int) -> float:
```

---

### **Function Behavior Requirements:**

* The function **must** handle the dataset properly:
  * Dataset Description: `{dataset_description}`
  * ConfigSpace Definition: `{config_space}`
  * SMAC Scenario: `{scenario}`

* The function **must** accept a `dataset` dictionary with:
  * `dataset['X']`: feature matrix or input tensor
  * `dataset['y']`: label vector or label tensor

* **CRITICAL: Data Type Handling**
  * **ALWAYS** check for mixed data types (numerical + categorical)
  * **ALWAYS** separate numerical and categorical features before preprocessing
  * **NEVER** apply scaling to categorical features
  * Use proper data type detection:
    ```python
    # Correct way to detect numerical features:
    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # WRONG - this causes isnan errors:
    # numerical_features = X.select_dtypes(include=np.number).columns.tolist()
    ```

* The function **must** handle the configuration properly:
  * Access primitive values using `cfg.get('key')`
  * Handle all hyperparameters defined in the configuration space
  * Apply proper type conversion and validation
  * Handle conditional hyperparameters correctly

* **Model Requirements:**
  * Infer input and output dimensions dynamically
  * Follow data format requirements
  * Handle necessary data transformations
  * Implement proper model initialization
  * Use appropriate loss functions
  * Apply proper regularization
  * Handle model-specific requirements

* **Training Requirements:**
  * Implement proper training loop
  * Handle batch processing
  * Apply proper optimization
  * Implement early stopping if needed
  * Handle validation if required
  * Return appropriate loss value

* **Performance Optimization Requirements:**
  * Minimize memory usage and allocations
  * Use vectorized operations where possible
  * Avoid unnecessary data copying
  * Optimize data loading and preprocessing
  * Use efficient data structures
  * Minimize CPU/GPU synchronization
  * Implement efficient batch processing
  * Use appropriate device placement (CPU/GPU)
  * Optimize model forward/backward passes
  * Minimize Python overhead

* **Code Optimization Requirements:**
  * Keep code minimal and focused
  * Avoid redundant computations
  * Use efficient algorithms
  * Minimize function calls
  * Optimize loops and iterations
  * Use appropriate data types
  * Avoid unnecessary object creation
  * Use appropriate caching strategies
  * The train function should be computational efficient

* **Best Practices:**
  * Implement proper logging
  * Handle edge cases
  * Ensure reproducibility
  * Optimize performance
  * Follow framework best practices
  * For tracking the progress add prints

---

### **Frameworks:**

Choose **one** of the following frameworks based on the dataset and requirements:
* **PyTorch**: For deep learning tasks
* **TensorFlow**: For deep learning tasks
* **scikit-learn**: For traditional ML tasks

---

### **Output Format:**

* Return **only** the `train()` function
* Include necessary imports
* No example usage or additional code
* The function must be self-contained and executable
* Code must be minimal and optimized for performance

---

### **Error Prevention:**

* Validate all inputs
* Handle missing or invalid hyperparameters
* Check data types and shapes
* Handle edge cases
* Implement proper error messages
* **ALWAYS handle mixed data types properly**

---

### **Key Principles (NOT Examples):**

* **Data Type Safety**: Always detect and handle mixed data types before preprocessing
* **Framework Appropriateness**: Choose the best framework for the specific task and dataset
* **Configuration Consistency**: Use hyperparameters that match the provided config space
* **Model Specificity**: Implement the specific model type indicated by the config space
* **Preprocessing Flexibility**: Adapt preprocessing to the actual data characteristics
* **Error Resilience**: Handle edge cases and provide meaningful error messages
* **Performance Focus**: Optimize for computational efficiency and minimal overhead

---

**Reminder:** The output must be limited to:
* Valid `import` statements
* A single `train()` function that returns a float loss value
* No additional code or explanations
* Code must be optimized for performance and minimal in size
* Return negative loss/error since SMAC minimizes the objective
* For accuracy metrics, return negative accuracy (e.g. -accuracy)
* For error metrics, return the raw error value (e.g. mse, rmse)
* Ensure consistent sign convention across all metrics
* Do not cheat in order to escape an Error and do not use Try Except
* **ALWAYS handle mixed data types properly to avoid isnan errors**
* **Choose the most appropriate framework and model for the specific task**