Generate production-grade Python code for a machine learning training function with the following STRICT requirements:

---

**Function signature** must be:

```python
def train(cfg: Configuration, seed: int, dataset: Any) -> float:
```

---

**The function must:**

- Accept a `dataset` object with the attributes:
  - `dataset['X']` — feature matrix
  - `dataset['y']` — label vector

- Assume that `cfg` is a **sampled configuration** object, where:
  - `cfg.get('key')` returns a plain **Python primitive** value (`float`, `int`, `str`, etc.).
  - **Never use** hyperparameter objects like `UniformFloatHyperparameter` inside `train`.

- Use stratified k-fold cross-validation (`sklearn.model_selection.cross_val_score`).
  - `random_state=seed` must be set for reproducibility.

- Train a **scikit-learn classification model** that:
  - Supports **early stopping** if `max_iter` is provided.
  - Has `warm_start=True`.
  - Accepts `random_state=seed`.
  - Accepts `learning_rate` (`'constant'` or `'adaptive'`).
  - Accepts `C = 1.0 / alpha` as the regularization strength.

- If `learning_rate == 'constant'`, set `eta0` correctly.
- Otherwise, `eta0` should be ignored.

- Must compute and return a **loss value** (`float`) where **lower = better**.
  - Loss = `1.0 - mean cross-validation accuracy`.

---

**Hyperparameter usage rules:**

- Only use these hyperparameters:
  - `learning_rate` (categorical: `'constant'` or `'adaptive'`)
  - `alpha` (float, log-scaled) (this is directly C in LogisticRegression)
  - `max_iter` (integer)
  - `eta0` (float, only if `learning_rate == 'constant'`)

- Extract hyperparameters like this:
  ```python
  value = cfg.get('hyperparameter_name')
  ```

- Never use operations directly on hyperparameter objects.

---

**Additional Requirements:**

- Use scikit-learn version >= 1.3.0 APIs.
- Include all necessary imports.
- Full type annotations for all function arguments and variables.
- No example usages, no print statements, no extra text — **only pure code** output.

---

**Supporting code already available:**

- ConfigSpace definition: `{config_space}`
- SMAC scenario: `{scenario}`
- Dataset description: `{dataset_description}`

**Example:
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.linear_model import SGDClassifier
from typing import Any
from ConfigSpace import Configuration

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    X, y = dataset['X'], dataset['y']
    lr: str = cfg.get('learning_rate')
    alpha: float = cfg.get('alpha')
    max_iter: int = cfg.get('max_iter')
    eta0: float = cfg.get('eta0') if learning_rate == 'constant' else 0.1  # Ensure eta0 is > 0


    params = {{
        'learning_rate': lr,
        'alpha': alpha,
        'max_iter': max_iter,
        'early_stopping': True,
        'warm_start': True,
        'random_state': seed
        'eta0': eta0,
    }}

    model = SGDClassifier(**params)
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)
    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    return 1.0 - scores.mean()
