**Generate a production-grade Python training function for machine learning with the following STRICT requirements:**

---

### ** CRITICAL CODE GENERATION RULE FOR HYPERPARAMETER OPTIMIZATION:**
**GENERATE ROBUST CODE THAT DOESN'T NEED ERROR HANDLING!**
* **Why**: In hyperparameter optimization, the function will be called with diverse configurations
* **HPO Context**: The training function must handle all configurations without crashing
* **Generate Robust Code**: Write code that naturally handles all valid configurations
* **Let Errors Propagate**: Don't hide errors - let them show so they can be fixed
* **This is a HARD REQUIREMENT**: Generate inherently robust code, don't mask problems

---

### ** CRITICAL HPO ROBUSTNESS RULE:**
**GENERATE CODE THAT NATURALLY HANDLES MULTI-ALGORITHM CONFIGURATIONS!**
* **Context**: Configuration space may contain hyperparameters for multiple algorithms (RF, GB, SVM, NN)
* **Algorithm Selection**: Implement the algorithm(s) that match the configuration space definition
* **Parameter Extraction**: Extract and use all relevant parameters from the configuration
* **Safe Type Conversion**: Convert parameters to appropriate types with bounds checking
* **Default Values**: Use sensible defaults for all hyperparameters when not specified
* **Validate Ranges**: Ensure all parameters are within valid ranges before use
* **Multi-Algorithm Support**: If config space supports multiple algorithms, implement appropriate logic
* **Parameter Name Matching**: Use EXACT parameter names from ConfigSpace definition - never use generic names
* **Algorithm Detection**: Look at ConfigSpace parameter
* **This is a HARD REQUIREMENT**: Generate naturally robust code that handles configurations correctly

---

### ** CRITICAL GENERALIZATION RULE:**
**ABSOLUTELY NO HARDCODED DIMENSIONS OR SHAPES!**
* **Why**: The function must be reusable for different datasets. Hardcoding values like `(48000, 3072)` or `10` classes makes the function brittle and useless.
* **Instead**: All dimensions **must** be inferred dynamically from the input `dataset` object.
* **Examples**:
    * **Get number of features from `X.shape[1]`**.
    * **Get number of samples from `X.shape[0]`**.
    * **Get number of classes from the unique values in `y`**.
* **This is a HARD REQUIREMENT**: Any code with hardcoded shapes will be rejected.

---
* **Selected Facade**: `{suggested_facade}`
* Recommended steps to write the train function based on the planner:
  * `{train_function_plan}`
---

### **Function signature** must be:

```python
from ConfigSpace import Configuration
from typing import Any, Tuple
def train(cfg: Configuration, dataset: Any, seed: int, budget: int = None, model_dir: str = None) -> Tuple[float, Any]:
```

**CRITICAL**: The function signature **MUST** include the `budget` parameter even if not used by all facades:
- For **BlackBoxFacade** and **HyperparameterOptimizationFacade**: `budget` parameter will be `None` and should be ignored
- For **HyperbandFacade** and **MultiFidelityFacade**: `budget` parameter will contain the fidelity budget (e.g., number of epochs, training steps)
- **Always include the budget parameter** in the signature for compatibility with all facades
- Use conditional logic to handle the budget parameter appropriately based on the facade type

**Budget Parameter Handling Examples:**
```python
# For neural networks (epochs)
if budget is not None:
    epochs = budget
else:
    epochs = 100  # default value

# For iterative algorithms (iterations)
if budget is not None:
    max_iter = budget
else:
    max_iter = 1000  # default value

# For ensemble methods (estimators)
if budget is not None:
    n_estimators = budget
else:
    n_estimators = 100  # default value
```

---

### **Function Behavior Requirements:**

* The function **must** handle the dataset properly:
  * Dataset Description: `{dataset_description}`
  * ConfigSpace Definition (**very important for choosing the model**): `{config_space}`
  * SMAC Scenario: `{scenario}`

* **CRITICAL**: The function **must** use the EXACT parameter names from the ConfigSpace definition above
  * **INSPECT** the ConfigSpace definition carefully and extract only those parameters that exist

* The function **must** accept a `dataset` dictionary with:
  * `dataset['X']`: feature matrix or input tensor
  * `dataset['y']`: label vector or label tensor

* The function **must** handle the configuration properly:
  * Access primitive values using `cfg.get('key')`
  * Handle all hyperparameters defined in the configuration space
  * Apply proper type conversion and validation
  * Handle conditional hyperparameters correctly
  * type of some keys like batch_size or some numeric keys can be **numpy.int64**, int, float, ...

* **Model Requirements:**
  * Infer input and output dimensions dynamically
  * Follow data format requirements
  * Handle necessary data transformations
  * Implement proper model initialization
  * Use appropriate loss functions
  * Apply proper regularization
  * Handle model-specific requirements
  * **CRITICAL**: The returned model MUST have a `predict(X)` method for evaluation
  * **Model Wrapping**: If using PyTorch, TensorFlow, or other frameworks without built-in predict methods, 
    create a wrapper class that provides a standard `predict(X)` method
  * **Interface Consistency**: Regardless of the underlying framework, ensure the returned model 
    has a predict method that accepts feature matrix X and returns predictions
  * **Framework Flexibility**: You can use any ML framework (PyTorch, TensorFlow, scikit-learn, etc.) 
    but must provide a consistent interface

* **Training Requirements:**
  * Implement proper training loop
  * Handle batch processing
  * Apply proper optimization
  * Implement early stopping if needed
  * Handle validation if required
      * **PREVENT OVERFITTING**: Use proper validation split, regularization, early stopping
    * **ENSURE GENERALIZATION**: Avoid fitting too closely to training data
    * Return both loss value and trained model as a tuple (loss, model)

* **Model Saving Requirements:**
  * **MUST save the trained model** if `model_dir` is provided
  * Create the directory if it doesn't exist
  * Save model in appropriate format for the framework:
    * **PyTorch**: Use `torch.save(model.state_dict(), model_path)` or `torch.save(model, model_path)`
    * **TensorFlow**: Use `model.save(model_path)` or `tf.saved_model.save(model, model_path)`
    * **scikit-learn**: Use `joblib.dump(model, model_path)` or `pickle.dump(model, open(model_path, 'wb'))`
  * Generate unique model filename using timestamp or configuration hash
  * Save model metadata (configuration, performance metrics) if possible
  * Ensure the saved model can be loaded later for inference
  * **CRITICAL**: The function must return BOTH the loss value and the trained model as a tuple (loss, model)
  * **REASON**: Both values are needed for analysis and further use
  * **ACCESS MODEL**: The returned model can be used directly without loading from file

* **Performance Optimization Requirements:**
  * Minimize memory usage and allocations
  * Use vectorized operations where possible
  * Avoid unnecessary data copying
  * Optimize data loading and preprocessing
  * Use efficient data structures
  * Minimize CPU/GPU synchronization
  * Implement efficient batch processing if necessary
  * Use appropriate device placement (CPU/GPU)
  * Optimize model forward/backward passes
  * Minimize Python overhead
  * For Neural Networks **Always use GPU** if available

* **Code Optimization Requirements:**
  * Keep code minimal and focused
  * Avoid redundant computations
  * Use efficient algorithms
  * Minimize function calls
  * Optimize loops and iterations
  * Use appropriate data types
  * Avoid unnecessary object creation
  * Use appropriate caching strategies
  * The train function should be computational efficient

* **Best Practices:**
  * Implement proper logging
  * Handle edge cases
  * Ensure reproducibility
  * Optimize performance
  * Follow framework best practices
  * For tracking the progress add prints

---

### **Frameworks:**

Choose **one** of the following frameworks based on the dataset and requirements:
* **PyTorch**: For deep learning tasks
* **TensorFlow**: For deep learning tasks
* **scikit-learn**: For traditional ML tasks

---

### **Output Format:**

* Return **only** the `train()` function
* Include necessary imports
* No example usage or additional code
* The function must be self-contained and executable
* Code must be minimal and optimized for performance

---

### **Code Generation Best Practices for HPO:**

* **VALIDATE ALL INPUTS EXPLICITLY** - Check types, shapes, ranges before use
* **HANDLE MISSING PARAMETERS** - Use sensible defaults for all hyperparameters
* **CHECK DATA TYPES AND SHAPES** - Validate and convert before processing  
* **CONVERT TYPES SAFELY** - Convert budget and other parameters to appropriate types
* **BOUND ALL PARAMETERS** - Ensure parameters are within valid ranges
* **USE SENSIBLE DEFAULTS** - Provide reasonable defaults for all hyperparameters
* **IMPLEMENT MATCHING ALGORITHMS** - Implement algorithms that match the configuration space
* **USE EXACT PARAMETER NAMES** - Extract parameters using exact names from ConfigSpace definition
* **PREVENT OVERFITTING** - Use appropriate validation, regularization, and early stopping
* **HANDLE NUMPY TYPES** - Convert numpy.int64, numpy.float64 to native Python types
* **DYNAMIC DIMENSIONS** - Infer all dimensions from data, never hardcode shapes

---

### **General Structure Principles:**

**Your generated function should follow these principles:**

1. **Set random seed** for reproducibility
2. **Extract hyperparameters** from cfg with appropriate defaults and type conversion
3. **Validate and bound** all parameters to ensure they're within valid ranges
4. **Prepare data** efficiently, inferring dimensions dynamically
5. **Implement algorithm(s)** that match the configuration space definition
6. **Handle budget parameter** appropriately for the facade type
7. **Train the model** with the validated parameters
8. **Save the model** if model_dir is provided
9. **Return both the loss and trained model** as a tuple (loss, model)

**Do NOT copy specific implementation patterns** - generate code appropriate for the given configuration space and dataset requirements.

---

### **Example Structure (NO try/except):**

```python
def train(cfg: Configuration, dataset: Any, seed: int, budget: int = None, model_dir: str = None) -> Tuple[float, Any]:
    # Set random seed for reproducibility
    
    # Extract hyperparameters efficiently
    sample_config = cfg.get('sample_config')
    
    # Prepare data efficiently
    
    # Initialize model with optimized parameters
    
    # Optimized training loop

    # Save model if directory is provided
    if model_dir:
        os.makedirs(model_dir, exist_ok=True)
        model_path = os.path.join(model_dir, f"model_{{seed}}.pth")
        torch.save(model.state_dict(), model_path)
    
    return loss, model
```

---

### **Model Wrapping Example for PyTorch:**

```python
class ModelWrapper:
    def __init__(self, model, device='cpu'):
        self.model = model
        self.device = device
        
    def predict(self, X):
        self.model.eval()
        with torch.no_grad():
            # Handle different input types (DataFrame, numpy array, tensor)
            if hasattr(X, 'values'):  # pandas DataFrame/Series
                X = torch.tensor(X.values, dtype=torch.float32).to(self.device)
            elif isinstance(X, np.ndarray):
                X = torch.tensor(X, dtype=torch.float32).to(self.device)
            elif not isinstance(X, torch.Tensor):
                X = torch.tensor(X, dtype=torch.float32).to(self.device)
            else:
                X = X.to(self.device)
                
            outputs = self.model(X)
            # Handle different output formats (classification vs regression)
            if outputs.dim() > 1 and outputs.shape[1] > 1:
                predictions = torch.argmax(outputs, dim=1)  # Classification
            else:
                predictions = outputs.squeeze()  # Regression
            return predictions.cpu().numpy()

# Usage in train function:
# wrapped_model = ModelWrapper(pytorch_model, device)
# return loss, wrapped_model
```

---

** FINAL REMINDER - CRITICAL REQUIREMENTS:**
* Valid `import` statements
* A single `train()` function that returns a **TUPLE** (loss, model)
* No additional code or explanations
* Code must be optimized for performance and minimal in size
* For accuracy metrics, return (negative accuracy, model) as a tuple (e.g. (-accuracy, model))
* For error metrics, return (raw error value, model) as a tuple (e.g. (mse, model))
* Ensure consistent sign convention across all metrics
* **MUST save the trained model** if `model_dir` parameter is provided
* **CRITICAL**: ALWAYS return tuple (loss, model) - both values are needed
* **MUST handle multi-algorithm configuration spaces** by implementing appropriate algorithms
* **MUST use EXACT parameter names** from ConfigSpace definition - never use generic names
* **MUST implement algorithms** based on parameter prefixes in ConfigSpace
* **MUST convert budget parameter** to appropriate type and validate range
* **MUST use sensible defaults** for all hyperparameters with proper type conversion
* **MUST validate parameter ranges** to ensure they're within acceptable bounds
* **MUST prevent overfitting** with proper validation and regularization
* **NO try/except blocks** - let errors propagate so they can be fixed
* **The train function MUST be naturally robust** for hyperparameter optimization scenarios
* **CRITICAL**: **The returned model MUST have a working `predict(X)` method** for test evaluation
* **Model Wrapping**: If using PyTorch/TensorFlow models, wrap them in a class with a predict method
* **Framework Freedom**: You can use any ML framework but must provide consistent predict interface
* **Wrapper Examples**: For PyTorch models, create a wrapper class that handles forward pass and returns predictions