[2025-05-20 12:10:19] [Metadata: {'component': 'config'}] ```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer, ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace(seed=1234)

    # Define hyperparameters
    optimizer = Categorical("optimizer", ["sgd", "adam", "rmsprop"], default="adam")
    learning_rate = Float("learning_rate", (1e-5, 1e-2), log=True, default=1e-3)
    batch_size = Integer("batch_size", (32, 256), default=64, log=True)
    momentum = Float("momentum", (0.0, 0.99), default=0.9)
    beta1 = Float("beta1", (0.0, 0.999), default=0.9)

    # Add hyperparameters to the configuration space
    cs.add([optimizer, learning_rate, batch_size, momentum, beta1])

    # Add forbidden clauses
    forbidden_momentum = ForbiddenAndConjunction(
        ForbiddenEqualsClause(optimizer, "adam"),
        ForbiddenEqualsClause(momentum, 0.9)
    )

    cs.add_forbidden_clause(forbidden_momentum)

    return cs
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:19] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer, ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace(seed=1234)

    # Define hyperparameters
    optimizer = Categorical("optimizer", ["sgd", "adam", "rmsprop"], default="adam")
    learning_rate = Float("learning_rate", (1e-5, 1e-2), log=True, default=1e-3)
    batch_size = Integer("batch_size", (32, 256), default=64, log=True)
    momentum = Float("momentum", (0.0, 0.99), default=0.9)
    beta1 = Float("beta1", (0.0, 0.999), default=0.9)

    # Add hyperparameters to the configuration space
    cs.add([optimizer, learning_rate, batch_size, momentum, beta1])

    # Add forbidden clauses
    forbidden_momentum = ForbiddenAndConjunction(
        ForbiddenEqualsClause(optimizer, "adam"),
        ForbiddenEqualsClause(momentum, 0.9)
    )

    cs.add_forbidden_clause(forbidden_momentum)

    return cs

--------------------------------------------------------------------------------
[2025-05-20 12:10:19] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#1): Given vector violates forbidden clause: (Forbidden: momentum == 0.9 && Forbidden: optimizer == 'adam')
--------------------------------------------------------------------------------
[2025-05-20 12:10:21] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer, ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace(seed=1234)

    # Define hyperparameters
    optimizer = Categorical("optimizer", ["sgd", "adam", "rmsprop"], default="adam")
    learning_rate = Float("learning_rate", (1e-5, 1e-2), log=True, default=1e-3)
    batch_size = Integer("batch_size", (32, 256), default=64, log=True)
    momentum = Float("momentum", (0.0, 0.9), default=0.9)
    beta1 = Float("beta1", (0.0, 0.999), default=0.9)

    # Add hyperparameters to the configuration space
    cs.add([optimizer, learning_rate, batch_size, momentum, beta1])

    # Add forbidden clauses
    forbidden_momentum = ForbiddenAndConjunction(
        ForbiddenEqualsClause(optimizer, "adam"),
        ForbiddenEqualsClause(momentum, 0.9)
    )

    cs.add_forbidden_clause(forbidden_momentum)

    return cs
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:21] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer, ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace(seed=1234)

    # Define hyperparameters
    optimizer = Categorical("optimizer", ["sgd", "adam", "rmsprop"], default="adam")
    learning_rate = Float("learning_rate", (1e-5, 1e-2), log=True, default=1e-3)
    batch_size = Integer("batch_size", (32, 256), default=64, log=True)
    momentum = Float("momentum", (0.0, 0.9), default=0.9)
    beta1 = Float("beta1", (0.0, 0.999), default=0.9)

    # Add hyperparameters to the configuration space
    cs.add([optimizer, learning_rate, batch_size, momentum, beta1])

    # Add forbidden clauses
    forbidden_momentum = ForbiddenAndConjunction(
        ForbiddenEqualsClause(optimizer, "adam"),
        ForbiddenEqualsClause(momentum, 0.9)
    )

    cs.add_forbidden_clause(forbidden_momentum)

    return cs

--------------------------------------------------------------------------------
[2025-05-20 12:10:21] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#2): Given vector violates forbidden clause: (Forbidden: momentum == 0.9 && Forbidden: optimizer == 'adam')
--------------------------------------------------------------------------------
[2025-05-20 12:10:23] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer, ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace(seed=1234)

    # Define hyperparameters
    optimizer = Categorical("optimizer", ["sgd", "adam", "rmsprop"], default="adam")
    learning_rate = Float("learning_rate", (1e-5, 1e-2), log=True, default=1e-3)
    batch_size = Integer("batch_size", (32, 256), default=64, log=True)
    momentum = Float("momentum", (0.0, 0.9), default=0.0)
    beta1 = Float("beta1", (0.0, 0.999), default=0.9)

    # Add hyperparameters to the configuration space
    cs.add([optimizer, learning_rate, batch_size, momentum, beta1])

    # Add forbidden clauses
    forbidden_momentum = ForbiddenAndConjunction(
        ForbiddenEqualsClause(optimizer, "adam"),
        ForbiddenEqualsClause(momentum, 0.9)
    )

    cs.add_forbidden_clause(forbidden_momentum)

    return cs
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:23] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer, ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace(seed=1234)

    # Define hyperparameters
    optimizer = Categorical("optimizer", ["sgd", "adam", "rmsprop"], default="adam")
    learning_rate = Float("learning_rate", (1e-5, 1e-2), log=True, default=1e-3)
    batch_size = Integer("batch_size", (32, 256), default=64, log=True)
    momentum = Float("momentum", (0.0, 0.9), default=0.0)
    beta1 = Float("beta1", (0.0, 0.999), default=0.9)

    # Add hyperparameters to the configuration space
    cs.add([optimizer, learning_rate, batch_size, momentum, beta1])

    # Add forbidden clauses
    forbidden_momentum = ForbiddenAndConjunction(
        ForbiddenEqualsClause(optimizer, "adam"),
        ForbiddenEqualsClause(momentum, 0.9)
    )

    cs.add_forbidden_clause(forbidden_momentum)

    return cs

--------------------------------------------------------------------------------
[2025-05-20 12:10:23] [Metadata: {'component': 'config', 'status': 'success'}] Configuration space generated successfully
--------------------------------------------------------------------------------
[2025-05-20 12:10:23] [Metadata: {'component': 'scenario'}] ```python
from smac import Scenario
from ConfigSpace import ConfigurationSpace

def generate_scenario(cs):
    scenario = Scenario(
        configspace=cs,
        output_directory="./automl_results",
        deterministic=False,
        n_workers=2,
        min_budget=1,
        max_budget=9
    )
    return scenario
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:23] [Metadata: {'component': 'scenario', 'action': 'run'}] from smac import Scenario
from ConfigSpace import ConfigurationSpace

def generate_scenario(cs):
    scenario = Scenario(
        configspace=cs,
        output_directory="./automl_results",
        deterministic=False,
        n_workers=2,
        min_budget=1,
        max_budget=9
    )
    return scenario

--------------------------------------------------------------------------------
[2025-05-20 12:10:23] [Metadata: {'component': 'scenario', 'status': 'success'}] Scenario generated successfully
--------------------------------------------------------------------------------
[2025-05-20 12:10:32] [Metadata: {'component': 'train_function'}] ```python
from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {epoch+1}, Loss: {avg_epoch_loss}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:32] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {epoch+1}, Loss: {avg_epoch_loss}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)

--------------------------------------------------------------------------------
[2025-05-20 12:10:32] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#1): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-05-20 12:10:40] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {{epoch+1}}, Loss: {{avg_epoch_loss}}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:40] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {{epoch+1}}, Loss: {{avg_epoch_loss}}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)

--------------------------------------------------------------------------------
[2025-05-20 12:10:40] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#2): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-05-20 12:10:47] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {{{{epoch+1}}}}, Loss: {{{{avg_epoch_loss}}}}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:47] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {{{{epoch+1}}}}, Loss: {{{{avg_epoch_loss}}}}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)

--------------------------------------------------------------------------------
[2025-05-20 12:10:47] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#3): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-05-20 12:10:55] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {epoch+1}, Loss: {avg_epoch_loss}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)
```
--------------------------------------------------------------------------------
[2025-05-20 12:10:55] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {X.shape[1]} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {epoch+1}, Loss: {avg_epoch_loss}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)

--------------------------------------------------------------------------------
[2025-05-20 12:10:55] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#4): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-05-20 12:11:03] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {{X.shape[1]}} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {{optimizer_name}}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {{epoch+1}}, Loss: {{avg_epoch_loss}}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)
```
--------------------------------------------------------------------------------
[2025-05-20 12:11:03] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from ConfigSpace import Configuration


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a neural network model on the provided dataset.

    Args:
        cfg (Configuration): A configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically from the dataset
    if len(X.shape) == 1:
       raise ValueError("Invalid feature data with dimensions 1")
    elif len(X.shape) == 2:
        input_size = X.shape[1]
    elif len(X.shape) == 4:  # Assuming image-shaped data (batch_size, channels, height, width)
        input_size = X.shape[1] * X.shape[2] * X.shape[3]  # Flattening for fully connected network
    else:
        raise ValueError("Unsupported input data shape.  Expected 2D or 4D array.")

    num_classes = len(np.unique(y))

    # Hyperparameter loading
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Reshape if needed and use a CNN
    use_cnn = True  # Assume we will use a CNN by default.
    if len(X.shape) != 4:  # data is not image shaped.
        if use_cnn: # User is requesting a CNN model. We must reshape to use it.
            side = int(np.sqrt(X.shape[1]))  # e.g., sqrt(784) = 28
            if side * side != X.shape[1]:
                raise ValueError(f"Input size {{X.shape[1]}} is not a perfect square. Cannot reshape to image for CNN.")
            X = X.reshape(-1, 1, side, side)  # Reshape to (batch_size, channels, height, width)
        input_channels = 1  # Assuming grayscale images if reshaping.
        image_size = side
    else:
        input_channels = X.shape[1]
        image_size = X.shape[2]

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Define a CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.relu2 = nn.ReLU()
            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (image_size // 4) * (image_size // 4), 128)
            self.relu3 = nn.ReLU()
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = self.pool1(self.relu1(self.conv1(x)))
            x = self.pool2(self.relu2(self.conv2(x)))
            x = x.view(x.size(0), -1)  # Flatten
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Use GPU if available
    model.to(device)
    # Define optimizer
    if optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum if momentum is not None else 0)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1 if beta1 is not None else 0.9, 0.999))
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {{optimizer_name}}")

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss
        #print(f"Epoch {{epoch+1}}, Loss: {{avg_epoch_loss}}") # Consider commenting to reduce log output

    avg_loss = total_loss / epochs
    return float(avg_loss)

--------------------------------------------------------------------------------
[2025-05-20 12:11:03] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#5): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-05-20 12:11:10] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any
import numpy as np
from ConfigSpace import Configuration
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

class SimpleCNN(nn.Module):
    def __init__(self, input_channels, num_classes):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Assuming 28x28 images after reshaping
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.maxpool2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu3(x)
        x = self.fc2(x)
        return x

def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a simple CNN on the given dataset for 10 epochs and returns the average training loss.

    Args:
        cfg (Configuration): A ConfigSpace Configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically
    num_classes = len(np.unique(y))

    # Hyperparameter extraction from Configuration object
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Device configuration
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Data Preprocessing
    X_tensor = torch.tensor(X, dtype=torch.float32)
    y_tensor = torch.tensor(y, dtype=torch.long)

    # Reshape the input if it's not already an image
    if len(X_tensor.shape) == 2:
        input_size = X_tensor.shape[1]
        side = int(np.sqrt(input_size))
        if side * side != input_size:
            raise ValueError("Input size is not a perfect square. Cannot reshape to image.")

        X_tensor = X_tensor.reshape(-1, 1, side, side)  # Reshape to (N, 1, side, side)
        input_channels = 1  # Grayscale images

        # Explanation:
        # The original data is a 2D tensor (N, 784) where 784 represents a flattened 28x28 image.
        # This reshape operation transforms the data into a 4D tensor (N, 1, 28, 28), which is suitable
        # for a CNN. The '1' in the second dimension represents a single channel (grayscale).  If we had
        # color images, this would be 3.
        # We are assuming each feature array can be perfectly formed to a NxNx1 channel image
    elif len(X_tensor.shape) == 4:
        # Assuming it is an image shaped tensor N x C x H x W
        input_channels = X_tensor.shape[1]

    else:
        raise ValueError("Unsupported input shape. Expecting 2D (N, features) or 4D (N, C, H, W) tensor.")

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X_tensor, y_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Model instantiation
    model = SimpleCNN(input_channels, num_classes).to(device)

    # Optimizer selection
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    total_loss = 0.0
    for epoch in range(10):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss

    avg_loss = total_loss / 10
    return float(avg_loss)

--------------------------------------------------------------------------------
[2025-05-20 12:11:10] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#1): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-05-20 12:11:17] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
from typing import Any
import numpy as np
from ConfigSpace import Configuration
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

class SimpleCNN(nn.Module):
    def __init__(self, input_channels, num_classes):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Assuming 28x28 images after reshaping
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.maxpool2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu3(x)
        x = self.fc2(x)
        return x

def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a simple CNN on the given dataset for 10 epochs and returns the average training loss.

    Args:
        cfg (Configuration): A ConfigSpace Configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically
    num_classes = len(np.unique(y))

    # Hyperparameter extraction from Configuration object
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Device configuration
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Data Preprocessing
    X = np.array(X)
    y = np.array(y)
    X_tensor = torch.tensor(X, dtype=torch.float32)
    y_tensor = torch.tensor(y, dtype=torch.long)

    # Reshape the input if it's not already an image
    if len(X_tensor.shape) == 2:
        input_size = X_tensor.shape[1]
        side = int(np.sqrt(input_size))
        if side * side != input_size:
            raise ValueError("Input size is not a perfect square. Cannot reshape to image.")

        X_tensor = X_tensor.reshape(-1, 1, side, side)  # Reshape to (N, 1, side, side)
        input_channels = 1  # Grayscale images

        # Explanation:
        # The original data is a 2D tensor (N, 784) where 784 represents a flattened 28x28 image.
        # This reshape operation transforms the data into a 4D tensor (N, 1, 28, 28), which is suitable
        # for a CNN. The '1' in the second dimension represents a single channel (grayscale).  If we had
        # color images, this would be 3.
        # We are assuming each feature array can be perfectly formed to a NxNx1 channel image
    elif len(X_tensor.shape) == 4:
        # Assuming it is an image shaped tensor N x C x H x W
        input_channels = X_tensor.shape[1]

    else:
        raise ValueError("Unsupported input shape. Expecting 2D (N, features) or 4D (N, C, H, W) tensor.")

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X_tensor, y_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Model instantiation
    model = SimpleCNN(input_channels, num_classes).to(device)

    # Optimizer selection
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    total_loss = 0.0
    for epoch in range(10):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss

    avg_loss = total_loss / 10
    return float(avg_loss)
```
--------------------------------------------------------------------------------
[2025-05-20 12:11:17] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any
import numpy as np
from ConfigSpace import Configuration
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

class SimpleCNN(nn.Module):
    def __init__(self, input_channels, num_classes):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Assuming 28x28 images after reshaping
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.maxpool2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu3(x)
        x = self.fc2(x)
        return x

def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a simple CNN on the given dataset for 10 epochs and returns the average training loss.

    Args:
        cfg (Configuration): A ConfigSpace Configuration object containing hyperparameters.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions dynamically
    num_classes = len(np.unique(y))

    # Hyperparameter extraction from Configuration object
    optimizer_name = cfg.get("optimizer")
    learning_rate = cfg.get("learning_rate")
    batch_size = cfg.get("batch_size")
    momentum = cfg.get("momentum")
    beta1 = cfg.get("beta1")

    # Device configuration
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Data Preprocessing
    X = np.array(X)
    y = np.array(y)
    X_tensor = torch.tensor(X, dtype=torch.float32)
    y_tensor = torch.tensor(y, dtype=torch.long)

    # Reshape the input if it's not already an image
    if len(X_tensor.shape) == 2:
        input_size = X_tensor.shape[1]
        side = int(np.sqrt(input_size))
        if side * side != input_size:
            raise ValueError("Input size is not a perfect square. Cannot reshape to image.")

        X_tensor = X_tensor.reshape(-1, 1, side, side)  # Reshape to (N, 1, side, side)
        input_channels = 1  # Grayscale images

        # Explanation:
        # The original data is a 2D tensor (N, 784) where 784 represents a flattened 28x28 image.
        # This reshape operation transforms the data into a 4D tensor (N, 1, 28, 28), which is suitable
        # for a CNN. The '1' in the second dimension represents a single channel (grayscale).  If we had
        # color images, this would be 3.
        # We are assuming each feature array can be perfectly formed to a NxNx1 channel image
    elif len(X_tensor.shape) == 4:
        # Assuming it is an image shaped tensor N x C x H x W
        input_channels = X_tensor.shape[1]

    else:
        raise ValueError("Unsupported input shape. Expecting 2D (N, features) or 4D (N, C, H, W) tensor.")

    # Create TensorDataset and DataLoader
    dataset = TensorDataset(X_tensor, y_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Model instantiation
    model = SimpleCNN(input_channels, num_classes).to(device)

    # Optimizer selection
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Loss function
    criterion = nn.CrossEntropyLoss()

    # Training loop
    total_loss = 0.0
    for epoch in range(10):
        epoch_loss = 0.0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        total_loss += avg_epoch_loss

    avg_loss = total_loss / 10
    return float(avg_loss)

--------------------------------------------------------------------------------
[2025-05-20 12:14:50] [Metadata: {'component': 'train_function', 'status': 'success', 'loss': 0.0876801808398055}] Training executed successfully, loss: 0.0876801808398055
--------------------------------------------------------------------------------
