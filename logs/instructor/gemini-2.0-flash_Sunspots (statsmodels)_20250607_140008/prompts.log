[2025-06-07 14:00:16] [Metadata: {'dataset_name': 'Sunspots (statsmodels)'}] You are a data science expert with deep knowledge of time_series datasets. Your task is to generate structured, and comprehensive instructions for effectively working with the dataset 'Sunspots (statsmodels)'. Dataset description: This is a time series dataset.
Number of samples: 289
Time index type: <class 'pandas.core.indexes.range.RangeIndex'>
Time range: 0 to 288
Features:
- 0

### Time Series Handling Requirements
- Assume `dataset['X']` is a 3D array or tensor with shape `(num_samples, sequence_length, num_features)`.
- If `dataset['X']` is 2D, raise a `ValueError` if the model is RNN-based (`LSTM`, `GRU`, `RNN`).
- Do **not** flatten the input when using RNN-based models.
- Use `batch_first=True` in all recurrent models to maintain `(batch, seq_len, features)` format.
- Dynamically infer sequence length as `X.shape[1]` and feature dimension as `X.shape[2]`.
- If `X.ndim != 3` and a sequential model is selected, raise a clear error with shape info.
- Example input validation check:
  ```python
  if model_type in ['LSTM', 'GRU', 'RNN'] and X_tensor.ndim != 3:
      raise ValueError(f"Expected 3D input (batch, seq_len, features) for {model_type}, got {X_tensor.shape}")
  ```
- Time index or datetime values can be logged but should not be used in the model unless specified.


Please perform the following tasks:
1. Describe the recommended data preprocessing steps specific to this dataset.
2. Outline useful feature engineering strategies relevant to the dataset's type and domain.
3. Mention any common challenges or important considerations when working with this dataset type.
4. If this dataset exists on OpenML:
   - Provide the exact dataset name as listed on OpenML.
   - Include the dataset's tag(s) on OpenML.
   - Provide the direct OpenML URL to the dataset.

Return all the above in a structured JSON format matching the following fields:
- dataset_name (str)
- dataset_tag (str)
- dataset_instructions (list of str)

--------------------------------------------------------------------------------
