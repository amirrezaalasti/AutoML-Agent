[2025-06-07 09:19:46] [Metadata: {'component': 'config'}] **TASK**

**Goal:**
Write a Python function named `get_configspace()` that returns a valid `ConfigurationSpace` object for a classification task.

---

**STRICT OUTPUT RULES**

* Output **only** the complete `get_configspace()` function and **required imports**.
* Do **not** include any explanations, comments, docstrings, or extra text.
* The code must be **syntactically correct**, **executable**, and **compatible with SMAC**.

---

**ALLOWED CLASSES**

**Core**

* `ConfigurationSpace`
* `Categorical`
* `Float`
* `Integer`
* `Constant`

**Conditions**

* `EqualsCondition`
* `InCondition`
* `OrConjunction`

**Forbidden Clauses**

* `ForbiddenEqualsClause`
* `ForbiddenAndConjunction` *(must include at least one)*

**Distributions (only if needed)**

* `Beta`
* `Normal`

**Serialization (only if needed)**

* `to_yaml()`
* `from_yaml()`

---

**CONSTRAINTS**

* Must include **at least one** `ForbiddenAndConjunction` to block invalid hyperparameter combinations.

---

**DATASET DESCRIPTION**

* Use the following information to design the configuration space:
  `This is an image dataset.

Number of classes: 10
Class distribution:
1    6742
7    6265
3    6131
2    5958
9    5949
0    5923
6    5918
8    5851
4    5842
5    5421
Name: count, dtype: int64

Image Data Handling Requirements:
1. Input Format Requirements:
   - For CNN models: Input must be in (batch, channels, height, width) format
   - For dense/linear layers: Input should be flattened

2. Data Processing Steps:
   a) For flattened input (2D):
      - Calculate dimensions: height = width = int(sqrt(n_features))
      - Verify square dimensions: height * height == n_features
      - Reshape to (N, 1, H, W) for CNNs
   b) For 3D input (N, H, W):
      - Add channel dimension: reshape to (N, 1, H, W)
   c) For 4D input:
      - Verify channel order matches framework requirements

3. Framework-Specific Format:
   - PyTorch: (N, C, H, W)
   - TensorFlow: (N, H, W, C)
   - Convert between formats if necessary

4. Normalization:
   - Scale pixel values to [0, 1] by dividing by 255.0
   - Or standardize to mean=0, std=1
`
* Hyperparameter choices and model types must be suitable for this classification dataset.

---

**SUGGESTED PARAMETERS From OpenML**

* Here are some parameter configurations for this dataset from OpenML (for inspiration only, not mandatory):
  `[{90199: OpenML Parameter
================
ID............: 90199
Flow ID.......: 10062
Flow Name.....: openml.extensions.pytorch.layers.reshape.Reshape.328b2b91dfac21a6(1)_shape
Flow URL......: https://www.openml.org/f/10062
Parameter Name: shape
  |__Data Type: None
  |__Default..: [-1, 1, 28, 28]
  |__Value....: [-1, 1, 28, 28], 90200: OpenML Parameter
================
ID............: 90200
Flow ID.......: 10063
Flow Name.....: torch.nn.modules.batchnorm.BatchNorm2d.56d85ffcb098f6c2(1)_affine
Flow URL......: https://www.openml.org/f/10063
Parameter Name: affine
  |__Data Type: None
  |__Default..: true
  |__Value....: true, 90201: OpenML Parameter
================
ID............: 90201
Flow ID.......: 10063
Flow Name.....: torch.nn.modules.batchnorm.BatchNorm2d.56d85ffcb098f6c2(1)_eps
Flow URL......: https://www.openml.org/f/10063
Parameter Name: eps
  |__Data Type: None
  |__Default..: 1e-05
  |__Value....: 1e-05, 90202: OpenML Parameter
================
ID............: 90202
Flow ID.......: 10063
Flow Name.....: torch.nn.modules.batchnorm.BatchNorm2d.56d85ffcb098f6c2(1)_momentum
Flow URL......: https://www.openml.org/f/10063
Parameter Name: momentum
  |__Data Type: None
  |__Default..: 0.1
  |__Value....: 0.1, 90203: OpenML Parameter
================
ID............: 90203
Flow ID.......: 10063
Flow Name.....: torch.nn.modules.batchnorm.BatchNorm2d.56d85ffcb098f6c2(1)_num_features
Flow URL......: https://www.openml.org/f/10063
Parameter Name: num_features
  |__Data Type: None
  |__Default..: 1
  |__Value....: 1, 90204: OpenML Parameter
================
ID............: 90204
Flow ID.......: 10063
Flow Name.....: torch.nn.modules.batchnorm.BatchNorm2d.56d85ffcb098f6c2(1)_track_running_stats
Flow URL......: https://www.openml.org/f/10063
Parameter Name: track_running_stats
  |__Data Type: None
  |__Default..: true
  |__Value....: true, 90211: OpenML Parameter
================
ID............: 90211
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_dilation
Flow URL......: https://www.openml.org/f/10065
Parameter Name: dilation
  |__Data Type: None
  |__Default..: [1, 1]
  |__Value....: [1, 1], 90212: OpenML Parameter
================
ID............: 90212
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_groups
Flow URL......: https://www.openml.org/f/10065
Parameter Name: groups
  |__Data Type: None
  |__Default..: 1
  |__Value....: 1, 90213: OpenML Parameter
================
ID............: 90213
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_in_channels
Flow URL......: https://www.openml.org/f/10065
Parameter Name: in_channels
  |__Data Type: None
  |__Default..: 1
  |__Value....: 1, 90214: OpenML Parameter
================
ID............: 90214
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_kernel_size
Flow URL......: https://www.openml.org/f/10065
Parameter Name: kernel_size
  |__Data Type: None
  |__Default..: [5, 5]
  |__Value....: [5, 5], 90215: OpenML Parameter
================
ID............: 90215
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_out_channels
Flow URL......: https://www.openml.org/f/10065
Parameter Name: out_channels
  |__Data Type: None
  |__Default..: 32
  |__Value....: 32, 90216: OpenML Parameter
================
ID............: 90216
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_padding
Flow URL......: https://www.openml.org/f/10065
Parameter Name: padding
  |__Data Type: None
  |__Default..: [0, 0]
  |__Value....: [0, 0], 90217: OpenML Parameter
================
ID............: 90217
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_padding_mode
Flow URL......: https://www.openml.org/f/10065
Parameter Name: padding_mode
  |__Data Type: None
  |__Default..: "zeros"
  |__Value....: "zeros", 90218: OpenML Parameter
================
ID............: 90218
Flow ID.......: 10065
Flow Name.....: torch.nn.modules.conv.Conv2d.ceceab9239e055e2(1)_stride
Flow URL......: https://www.openml.org/f/10065
Parameter Name: stride
  |__Data Type: None
  |__Default..: [1, 1]
  |__Value....: [1, 1], 90219: OpenML Parameter
================
ID............: 90219
Flow ID.......: 10066
Flow Name.....: torch.nn.modules.activation.ReLU.40f86af0866f5bca(1)_inplace
Flow URL......: https://www.openml.org/f/10066
Parameter Name: inplace
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90220: OpenML Parameter
================
ID............: 90220
Flow ID.......: 10067
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.39cd2fb91e9a87ce(1)_ceil_mode
Flow URL......: https://www.openml.org/f/10067
Parameter Name: ceil_mode
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90221: OpenML Parameter
================
ID............: 90221
Flow ID.......: 10067
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.39cd2fb91e9a87ce(1)_dilation
Flow URL......: https://www.openml.org/f/10067
Parameter Name: dilation
  |__Data Type: None
  |__Default..: 1
  |__Value....: 1, 90222: OpenML Parameter
================
ID............: 90222
Flow ID.......: 10067
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.39cd2fb91e9a87ce(1)_kernel_size
Flow URL......: https://www.openml.org/f/10067
Parameter Name: kernel_size
  |__Data Type: None
  |__Default..: 2
  |__Value....: 2, 90223: OpenML Parameter
================
ID............: 90223
Flow ID.......: 10067
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.39cd2fb91e9a87ce(1)_padding
Flow URL......: https://www.openml.org/f/10067
Parameter Name: padding
  |__Data Type: None
  |__Default..: 0
  |__Value....: 0, 90224: OpenML Parameter
================
ID............: 90224
Flow ID.......: 10067
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.39cd2fb91e9a87ce(1)_return_indices
Flow URL......: https://www.openml.org/f/10067
Parameter Name: return_indices
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90225: OpenML Parameter
================
ID............: 90225
Flow ID.......: 10067
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.39cd2fb91e9a87ce(1)_stride
Flow URL......: https://www.openml.org/f/10067
Parameter Name: stride
  |__Data Type: None
  |__Default..: 2
  |__Value....: 2, 90226: OpenML Parameter
================
ID............: 90226
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_dilation
Flow URL......: https://www.openml.org/f/10068
Parameter Name: dilation
  |__Data Type: None
  |__Default..: [1, 1]
  |__Value....: [1, 1], 90227: OpenML Parameter
================
ID............: 90227
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_groups
Flow URL......: https://www.openml.org/f/10068
Parameter Name: groups
  |__Data Type: None
  |__Default..: 1
  |__Value....: 1, 90228: OpenML Parameter
================
ID............: 90228
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_in_channels
Flow URL......: https://www.openml.org/f/10068
Parameter Name: in_channels
  |__Data Type: None
  |__Default..: 32
  |__Value....: 32, 90229: OpenML Parameter
================
ID............: 90229
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_kernel_size
Flow URL......: https://www.openml.org/f/10068
Parameter Name: kernel_size
  |__Data Type: None
  |__Default..: [5, 5]
  |__Value....: [5, 5], 90230: OpenML Parameter
================
ID............: 90230
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_out_channels
Flow URL......: https://www.openml.org/f/10068
Parameter Name: out_channels
  |__Data Type: None
  |__Default..: 64
  |__Value....: 64, 90231: OpenML Parameter
================
ID............: 90231
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_padding
Flow URL......: https://www.openml.org/f/10068
Parameter Name: padding
  |__Data Type: None
  |__Default..: [0, 0]
  |__Value....: [0, 0], 90232: OpenML Parameter
================
ID............: 90232
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_padding_mode
Flow URL......: https://www.openml.org/f/10068
Parameter Name: padding_mode
  |__Data Type: None
  |__Default..: "zeros"
  |__Value....: "zeros", 90233: OpenML Parameter
================
ID............: 90233
Flow ID.......: 10068
Flow Name.....: torch.nn.modules.conv.Conv2d.ae902066d559b75e(1)_stride
Flow URL......: https://www.openml.org/f/10068
Parameter Name: stride
  |__Data Type: None
  |__Default..: [1, 1]
  |__Value....: [1, 1], 90234: OpenML Parameter
================
ID............: 90234
Flow ID.......: 10069
Flow Name.....: torch.nn.modules.activation.ReLU.a40e7e5d2f93bf94(1)_inplace
Flow URL......: https://www.openml.org/f/10069
Parameter Name: inplace
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90235: OpenML Parameter
================
ID............: 90235
Flow ID.......: 10070
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.aeeca686c28657a0(1)_ceil_mode
Flow URL......: https://www.openml.org/f/10070
Parameter Name: ceil_mode
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90236: OpenML Parameter
================
ID............: 90236
Flow ID.......: 10070
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.aeeca686c28657a0(1)_dilation
Flow URL......: https://www.openml.org/f/10070
Parameter Name: dilation
  |__Data Type: None
  |__Default..: 1
  |__Value....: 1, 90237: OpenML Parameter
================
ID............: 90237
Flow ID.......: 10070
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.aeeca686c28657a0(1)_kernel_size
Flow URL......: https://www.openml.org/f/10070
Parameter Name: kernel_size
  |__Data Type: None
  |__Default..: 2
  |__Value....: 2, 90238: OpenML Parameter
================
ID............: 90238
Flow ID.......: 10070
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.aeeca686c28657a0(1)_padding
Flow URL......: https://www.openml.org/f/10070
Parameter Name: padding
  |__Data Type: None
  |__Default..: 0
  |__Value....: 0, 90239: OpenML Parameter
================
ID............: 90239
Flow ID.......: 10070
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.aeeca686c28657a0(1)_return_indices
Flow URL......: https://www.openml.org/f/10070
Parameter Name: return_indices
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90240: OpenML Parameter
================
ID............: 90240
Flow ID.......: 10070
Flow Name.....: torch.nn.modules.pooling.MaxPool2d.aeeca686c28657a0(1)_stride
Flow URL......: https://www.openml.org/f/10070
Parameter Name: stride
  |__Data Type: None
  |__Default..: 2
  |__Value....: 2, 90247: OpenML Parameter
================
ID............: 90247
Flow ID.......: 10072
Flow Name.....: openml.extensions.pytorch.layers.reshape.Reshape.2f3028d8c76a025f(1)_shape
Flow URL......: https://www.openml.org/f/10072
Parameter Name: shape
  |__Data Type: None
  |__Default..: [-1, 1024]
  |__Value....: [-1, 1024], 90248: OpenML Parameter
================
ID............: 90248
Flow ID.......: 10073
Flow Name.....: torch.nn.modules.linear.Linear.2d2f3aa785e955a1(1)_in_features
Flow URL......: https://www.openml.org/f/10073
Parameter Name: in_features
  |__Data Type: None
  |__Default..: 1024
  |__Value....: 1024, 90249: OpenML Parameter
================
ID............: 90249
Flow ID.......: 10073
Flow Name.....: torch.nn.modules.linear.Linear.2d2f3aa785e955a1(1)_out_features
Flow URL......: https://www.openml.org/f/10073
Parameter Name: out_features
  |__Data Type: None
  |__Default..: 256
  |__Value....: 256, 90250: OpenML Parameter
================
ID............: 90250
Flow ID.......: 10074
Flow Name.....: torch.nn.modules.activation.ReLU.69bff7845ad324cc(1)_inplace
Flow URL......: https://www.openml.org/f/10074
Parameter Name: inplace
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90251: OpenML Parameter
================
ID............: 90251
Flow ID.......: 10075
Flow Name.....: torch.nn.modules.dropout.Dropout.30a09ad2ec2018dd(1)_inplace
Flow URL......: https://www.openml.org/f/10075
Parameter Name: inplace
  |__Data Type: None
  |__Default..: false
  |__Value....: false, 90252: OpenML Parameter
================
ID............: 90252
Flow ID.......: 10075
Flow Name.....: torch.nn.modules.dropout.Dropout.30a09ad2ec2018dd(1)_p
Flow URL......: https://www.openml.org/f/10075
Parameter Name: p
  |__Data Type: None
  |__Default..: 0.5
  |__Value....: 0.5, 90253: OpenML Parameter
================
ID............: 90253
Flow ID.......: 10076
Flow Name.....: torch.nn.modules.linear.Linear.e23ca4172db5ceb4(1)_in_features
Flow URL......: https://www.openml.org/f/10076
Parameter Name: in_features
  |__Data Type: None
  |__Default..: 256
  |__Value....: 256, 90254: OpenML Parameter
================
ID............: 90254
Flow ID.......: 10076
Flow Name.....: torch.nn.modules.linear.Linear.e23ca4172db5ceb4(1)_out_features
Flow URL......: https://www.openml.org/f/10076
Parameter Name: out_features
  |__Data Type: None
  |__Default..: 10
  |__Value....: 10, 90255: OpenML Parameter
================
ID............: 90255
Flow ID.......: 10077
Flow Name.....: torch.nn.modules.activation.ReLU.73f9349d88348546(1)_inplace
Flow URL......: https://www.openml.org/f/10077
Parameter Name: inplace
  |__Data Type: None
  |__Default..: false
  |__Value....: false}, {83057: OpenML Parameter
================
ID............: 83057
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_batch_size
Flow URL......: https://www.openml.org/f/8599
Parameter Name: batch_size
  |__Data Type: None
  |__Default..: 1024
  |__Value....: 32, 83058: OpenML Parameter
================
ID............: 83058
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_build_fn
Flow URL......: https://www.openml.org/f/8599
Parameter Name: build_fn
  |__Data Type: None
  |__Default..: {"oml-python:serialized_object": "function", "value": "__main__.squeezenet"}
  |__Value....: {"oml-python:serialized_object": "function", "value": "__main__.squeezenet_mnist_mnist_5_32_False"}, 83059: OpenML Parameter
================
ID............: 83059
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_epochs
Flow URL......: https://www.openml.org/f/8599
Parameter Name: epochs
  |__Data Type: None
  |__Default..: 3
  |__Value....: 5, 83060: OpenML Parameter
================
ID............: 83060
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer0
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer0
  |__Data Type: None
  |__Default..: {"class_name": "InputLayer", "config": {"batch_input_shape": [null, 784], "dtype": "float32", "name": "input", "sparse": false}, "inbound_nodes": [], "name": "input"}
  |__Value....: {"class_name": "InputLayer", "config": {"batch_input_shape": [null, 784], "dtype": "float32", "name": "input", "sparse": false}, "inbound_nodes": [], "name": "input"}, 83061: OpenML Parameter
================
ID............: 83061
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer1
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer1
  |__Data Type: None
  |__Default..: {"class_name": "Reshape", "config": {"name": "reshape_1", "target_shape": [28, 28, 1], "trainable": true}, "inbound_nodes": [[["input", 0, 0, {}]]], "name": "reshape_1"}
  |__Value....: {"class_name": "Reshape", "config": {"name": "reshape_72", "target_shape": [28, 28, 1], "trainable": true}, "inbound_nodes": [[["input", 0, 0, {}]]], "name": "reshape_72"}, 83062: OpenML Parameter
================
ID............: 83062
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer10
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer10
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_6", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_5", 0, 0, {}]]], "name": "conv2d_6"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1852", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1851", 0, 0, {}]]], "name": "conv2d_1852"}, 83063: OpenML Parameter
================
ID............: 83063
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer11
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer11
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_7", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_5", 0, 0, {}]]], "name": "conv2d_7"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1853", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1851", 0, 0, {}]]], "name": "conv2d_1853"}, 83064: OpenML Parameter
================
ID............: 83064
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer12
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer12
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_2", "trainable": true}, "inbound_nodes": [[["conv2d_6", 0, 0, {}], ["conv2d_7", 0, 0, {}]]], "name": "concatenate_2"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_570", "trainable": true}, "inbound_nodes": [[["conv2d_1852", 0, 0, {}], ["conv2d_1853", 0, 0, {}]]], "name": "concatenate_570"}, 83065: OpenML Parameter
================
ID............: 83065
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer13
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer13
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_2", "trainable": true}, "inbound_nodes": [[["concatenate_2", 0, 0, {}]]], "name": "activation_2"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_570", "trainable": true}, "inbound_nodes": [[["concatenate_570", 0, 0, {}]]], "name": "activation_570"}, 83066: OpenML Parameter
================
ID............: 83066
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer14
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer14
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 32, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_8", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_2", 0, 0, {}]]], "name": "conv2d_8"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 32, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1854", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_570", 0, 0, {}]]], "name": "conv2d_1854"}, 83067: OpenML Parameter
================
ID............: 83067
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer15
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer15
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_9", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_8", 0, 0, {}]]], "name": "conv2d_9"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1855", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1854", 0, 0, {}]]], "name": "conv2d_1855"}, 83068: OpenML Parameter
================
ID............: 83068
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer16
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer16
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_10", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_8", 0, 0, {}]]], "name": "conv2d_10"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1856", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1854", 0, 0, {}]]], "name": "conv2d_1856"}, 83069: OpenML Parameter
================
ID............: 83069
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer17
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer17
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_3", "trainable": true}, "inbound_nodes": [[["conv2d_9", 0, 0, {}], ["conv2d_10", 0, 0, {}]]], "name": "concatenate_3"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_571", "trainable": true}, "inbound_nodes": [[["conv2d_1855", 0, 0, {}], ["conv2d_1856", 0, 0, {}]]], "name": "concatenate_571"}, 83070: OpenML Parameter
================
ID............: 83070
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer18
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer18
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_3", "trainable": true}, "inbound_nodes": [[["concatenate_3", 0, 0, {}]]], "name": "activation_3"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_571", "trainable": true}, "inbound_nodes": [[["concatenate_571", 0, 0, {}]]], "name": "activation_571"}, 83071: OpenML Parameter
================
ID............: 83071
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer19
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer19
  |__Data Type: None
  |__Default..: {"class_name": "MaxPooling2D", "config": {"data_format": "channels_last", "name": "max_pooling2d_2", "padding": "valid", "pool_size": [2, 2], "strides": [2, 2], "trainable": true}, "inbound_nodes": [[["activation_3", 0, 0, {}]]], "name": "max_pooling2d_2"}
  |__Value....: {"class_name": "MaxPooling2D", "config": {"data_format": "channels_last", "name": "max_pooling2d_215", "padding": "valid", "pool_size": [2, 2], "strides": [2, 2], "trainable": true}, "inbound_nodes": [[["activation_571", 0, 0, {}]]], "name": "max_pooling2d_215"}, 83072: OpenML Parameter
================
ID............: 83072
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer2
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer2
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 96, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1", "padding": "valid", "strides": [2, 2], "trainable": true, "use_bias": true}, "inbound_nodes": [[["reshape_1", 0, 0, {}]]], "name": "conv2d_1"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 96, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1847", "padding": "valid", "strides": [2, 2], "trainable": false, "use_bias": true}, "inbound_nodes": [[["reshape_72", 0, 0, {}]]], "name": "conv2d_1847"}, 83073: OpenML Parameter
================
ID............: 83073
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer20
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer20
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 32, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_11", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["max_pooling2d_2", 0, 0, {}]]], "name": "conv2d_11"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 32, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1857", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["max_pooling2d_215", 0, 0, {}]]], "name": "conv2d_1857"}, 83074: OpenML Parameter
================
ID............: 83074
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer21
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer21
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_12", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_11", 0, 0, {}]]], "name": "conv2d_12"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1858", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1857", 0, 0, {}]]], "name": "conv2d_1858"}, 83075: OpenML Parameter
================
ID............: 83075
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer22
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer22
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_13", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_11", 0, 0, {}]]], "name": "conv2d_13"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 128, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1859", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1857", 0, 0, {}]]], "name": "conv2d_1859"}, 83076: OpenML Parameter
================
ID............: 83076
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer23
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer23
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_4", "trainable": true}, "inbound_nodes": [[["conv2d_12", 0, 0, {}], ["conv2d_13", 0, 0, {}]]], "name": "concatenate_4"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_572", "trainable": true}, "inbound_nodes": [[["conv2d_1858", 0, 0, {}], ["conv2d_1859", 0, 0, {}]]], "name": "concatenate_572"}, 83077: OpenML Parameter
================
ID............: 83077
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer24
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer24
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_4", "trainable": true}, "inbound_nodes": [[["concatenate_4", 0, 0, {}]]], "name": "activation_4"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_572", "trainable": true}, "inbound_nodes": [[["concatenate_572", 0, 0, {}]]], "name": "activation_572"}, 83078: OpenML Parameter
================
ID............: 83078
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer25
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer25
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 48, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_14", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_4", 0, 0, {}]]], "name": "conv2d_14"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 48, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1860", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_572", 0, 0, {}]]], "name": "conv2d_1860"}, 83079: OpenML Parameter
================
ID............: 83079
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer26
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer26
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_15", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_14", 0, 0, {}]]], "name": "conv2d_15"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1861", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1860", 0, 0, {}]]], "name": "conv2d_1861"}, 83080: OpenML Parameter
================
ID............: 83080
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer27
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer27
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_16", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_14", 0, 0, {}]]], "name": "conv2d_16"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1862", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1860", 0, 0, {}]]], "name": "conv2d_1862"}, 83081: OpenML Parameter
================
ID............: 83081
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer28
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer28
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_5", "trainable": true}, "inbound_nodes": [[["conv2d_15", 0, 0, {}], ["conv2d_16", 0, 0, {}]]], "name": "concatenate_5"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_573", "trainable": true}, "inbound_nodes": [[["conv2d_1861", 0, 0, {}], ["conv2d_1862", 0, 0, {}]]], "name": "concatenate_573"}, 83082: OpenML Parameter
================
ID............: 83082
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer29
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer29
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_5", "trainable": true}, "inbound_nodes": [[["concatenate_5", 0, 0, {}]]], "name": "activation_5"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_573", "trainable": true}, "inbound_nodes": [[["concatenate_573", 0, 0, {}]]], "name": "activation_573"}, 83083: OpenML Parameter
================
ID............: 83083
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer3
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer3
  |__Data Type: None
  |__Default..: {"class_name": "MaxPooling2D", "config": {"data_format": "channels_last", "name": "max_pooling2d_1", "padding": "valid", "pool_size": [2, 2], "strides": [2, 2], "trainable": true}, "inbound_nodes": [[["conv2d_1", 0, 0, {}]]], "name": "max_pooling2d_1"}
  |__Value....: {"class_name": "MaxPooling2D", "config": {"data_format": "channels_last", "name": "max_pooling2d_214", "padding": "valid", "pool_size": [2, 2], "strides": [2, 2], "trainable": true}, "inbound_nodes": [[["conv2d_1847", 0, 0, {}]]], "name": "max_pooling2d_214"}, 83084: OpenML Parameter
================
ID............: 83084
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer30
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer30
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 48, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_17", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_5", 0, 0, {}]]], "name": "conv2d_17"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 48, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1863", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_573", 0, 0, {}]]], "name": "conv2d_1863"}, 83085: OpenML Parameter
================
ID............: 83085
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer31
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer31
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_18", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_17", 0, 0, {}]]], "name": "conv2d_18"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1864", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1863", 0, 0, {}]]], "name": "conv2d_1864"}, 83086: OpenML Parameter
================
ID............: 83086
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer32
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer32
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_19", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_17", 0, 0, {}]]], "name": "conv2d_19"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 192, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1865", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1863", 0, 0, {}]]], "name": "conv2d_1865"}, 83087: OpenML Parameter
================
ID............: 83087
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer33
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer33
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_6", "trainable": true}, "inbound_nodes": [[["conv2d_18", 0, 0, {}], ["conv2d_19", 0, 0, {}]]], "name": "concatenate_6"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_574", "trainable": true}, "inbound_nodes": [[["conv2d_1864", 0, 0, {}], ["conv2d_1865", 0, 0, {}]]], "name": "concatenate_574"}, 83088: OpenML Parameter
================
ID............: 83088
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer34
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer34
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_6", "trainable": true}, "inbound_nodes": [[["concatenate_6", 0, 0, {}]]], "name": "activation_6"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_574", "trainable": true}, "inbound_nodes": [[["concatenate_574", 0, 0, {}]]], "name": "activation_574"}, 83089: OpenML Parameter
================
ID............: 83089
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer35
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer35
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_20", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_6", 0, 0, {}]]], "name": "conv2d_20"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1866", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_574", 0, 0, {}]]], "name": "conv2d_1866"}, 83090: OpenML Parameter
================
ID............: 83090
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer36
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer36
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_21", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_20", 0, 0, {}]]], "name": "conv2d_21"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1867", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1866", 0, 0, {}]]], "name": "conv2d_1867"}, 83091: OpenML Parameter
================
ID............: 83091
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer37
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer37
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_22", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_20", 0, 0, {}]]], "name": "conv2d_22"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1868", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1866", 0, 0, {}]]], "name": "conv2d_1868"}, 83092: OpenML Parameter
================
ID............: 83092
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer38
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer38
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_7", "trainable": true}, "inbound_nodes": [[["conv2d_21", 0, 0, {}], ["conv2d_22", 0, 0, {}]]], "name": "concatenate_7"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_575", "trainable": true}, "inbound_nodes": [[["conv2d_1867", 0, 0, {}], ["conv2d_1868", 0, 0, {}]]], "name": "concatenate_575"}, 83093: OpenML Parameter
================
ID............: 83093
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer39
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer39
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_7", "trainable": true}, "inbound_nodes": [[["concatenate_7", 0, 0, {}]]], "name": "activation_7"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_575", "trainable": true}, "inbound_nodes": [[["concatenate_575", 0, 0, {}]]], "name": "activation_575"}, 83094: OpenML Parameter
================
ID............: 83094
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer4
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer4
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 16, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_2", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["max_pooling2d_1", 0, 0, {}]]], "name": "conv2d_2"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 16, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1848", "padding": "same", "strides": [1, 1], "trainable": false, "use_bias": true}, "inbound_nodes": [[["max_pooling2d_214", 0, 0, {}]]], "name": "conv2d_1848"}, 83095: OpenML Parameter
================
ID............: 83095
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer40
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer40
  |__Data Type: None
  |__Default..: {"class_name": "MaxPooling2D", "config": {"data_format": "channels_last", "name": "max_pooling2d_3", "padding": "valid", "pool_size": [2, 2], "strides": [2, 2], "trainable": true}, "inbound_nodes": [[["activation_7", 0, 0, {}]]], "name": "max_pooling2d_3"}
  |__Value....: {"class_name": "MaxPooling2D", "config": {"data_format": "channels_last", "name": "max_pooling2d_216", "padding": "valid", "pool_size": [2, 2], "strides": [2, 2], "trainable": true}, "inbound_nodes": [[["activation_575", 0, 0, {}]]], "name": "max_pooling2d_216"}, 83096: OpenML Parameter
================
ID............: 83096
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer41
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer41
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_23", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["max_pooling2d_3", 0, 0, {}]]], "name": "conv2d_23"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1869", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["max_pooling2d_216", 0, 0, {}]]], "name": "conv2d_1869"}, 83097: OpenML Parameter
================
ID............: 83097
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer42
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer42
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_24", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_23", 0, 0, {}]]], "name": "conv2d_24"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1870", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1869", 0, 0, {}]]], "name": "conv2d_1870"}, 83098: OpenML Parameter
================
ID............: 83098
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer43
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer43
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_25", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_23", 0, 0, {}]]], "name": "conv2d_25"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 256, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1871", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1869", 0, 0, {}]]], "name": "conv2d_1871"}, 83099: OpenML Parameter
================
ID............: 83099
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer44
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer44
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_8", "trainable": true}, "inbound_nodes": [[["conv2d_24", 0, 0, {}], ["conv2d_25", 0, 0, {}]]], "name": "concatenate_8"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_576", "trainable": true}, "inbound_nodes": [[["conv2d_1870", 0, 0, {}], ["conv2d_1871", 0, 0, {}]]], "name": "concatenate_576"}, 83100: OpenML Parameter
================
ID............: 83100
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer45
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer45
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_8", "trainable": true}, "inbound_nodes": [[["concatenate_8", 0, 0, {}]]], "name": "activation_8"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_576", "trainable": true}, "inbound_nodes": [[["concatenate_576", 0, 0, {}]]], "name": "activation_576"}, 83101: OpenML Parameter
================
ID............: 83101
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer46
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer46
  |__Data Type: None
  |__Default..: {"class_name": "Dropout", "config": {"name": "dropout_1", "noise_shape": null, "rate": 0.5, "seed": null, "trainable": true}, "inbound_nodes": [[["activation_8", 0, 0, {}]]], "name": "dropout_1"}
  |__Value....: {"class_name": "Dropout", "config": {"name": "dropout_72", "noise_shape": null, "rate": 0.5, "seed": null, "trainable": true}, "inbound_nodes": [[["activation_576", 0, 0, {}]]], "name": "dropout_72"}, 83102: OpenML Parameter
================
ID............: 83102
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer47
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer47
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "linear", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 10, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_26", "padding": "valid", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["dropout_1", 0, 0, {}]]], "name": "conv2d_26"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "linear", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 10, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1872", "padding": "valid", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["dropout_72", 0, 0, {}]]], "name": "conv2d_1872"}, 83103: OpenML Parameter
================
ID............: 83103
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer48
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer48
  |__Data Type: None
  |__Default..: {"class_name": "AveragePooling2D", "config": {"data_format": "channels_last", "name": "average_pooling2d_1", "padding": "same", "pool_size": [13, 13], "strides": [1, 1], "trainable": true}, "inbound_nodes": [[["conv2d_26", 0, 0, {}]]], "name": "average_pooling2d_1"}
  |__Value....: {"class_name": "AveragePooling2D", "config": {"data_format": "channels_last", "name": "average_pooling2d_72", "padding": "same", "pool_size": [13, 13], "strides": [1, 1], "trainable": true}, "inbound_nodes": [[["conv2d_1872", 0, 0, {}]]], "name": "average_pooling2d_72"}, 83104: OpenML Parameter
================
ID............: 83104
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer49
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer49
  |__Data Type: None
  |__Default..: {"class_name": "Flatten", "config": {"data_format": "channels_last", "name": "flatten_1", "trainable": true}, "inbound_nodes": [[["average_pooling2d_1", 0, 0, {}]]], "name": "flatten_1"}
  |__Value....: {"class_name": "Flatten", "config": {"data_format": "channels_last", "name": "flatten_72", "trainable": true}, "inbound_nodes": [[["average_pooling2d_72", 0, 0, {}]]], "name": "flatten_72"}, 83105: OpenML Parameter
================
ID............: 83105
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer5
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer5
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_3", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_2", 0, 0, {}]]], "name": "conv2d_3"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1849", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1848", 0, 0, {}]]], "name": "conv2d_1849"}, 83106: OpenML Parameter
================
ID............: 83106
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer50
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer50
  |__Data Type: None
  |__Default..: {"class_name": "Dense", "config": {"activation": "softmax", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "name": "dense_1", "trainable": true, "units": 10, "use_bias": true}, "inbound_nodes": [[["flatten_1", 0, 0, {}]]], "name": "dense_1"}
  |__Value....: {"class_name": "Dense", "config": {"activation": "softmax", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "name": "dense_72", "trainable": true, "units": 10, "use_bias": true}, "inbound_nodes": [[["flatten_72", 0, 0, {}]]], "name": "dense_72"}, 83107: OpenML Parameter
================
ID............: 83107
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer6
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer6
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_4", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_2", 0, 0, {}]]], "name": "conv2d_4"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 64, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [3, 3], "name": "conv2d_1850", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["conv2d_1848", 0, 0, {}]]], "name": "conv2d_1850"}, 83108: OpenML Parameter
================
ID............: 83108
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer7
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer7
  |__Data Type: None
  |__Default..: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_1", "trainable": true}, "inbound_nodes": [[["conv2d_3", 0, 0, {}], ["conv2d_4", 0, 0, {}]]], "name": "concatenate_1"}
  |__Value....: {"class_name": "Concatenate", "config": {"axis": 1, "name": "concatenate_569", "trainable": true}, "inbound_nodes": [[["conv2d_1849", 0, 0, {}], ["conv2d_1850", 0, 0, {}]]], "name": "concatenate_569"}, 83109: OpenML Parameter
================
ID............: 83109
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer8
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer8
  |__Data Type: None
  |__Default..: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_1", "trainable": true}, "inbound_nodes": [[["concatenate_1", 0, 0, {}]]], "name": "activation_1"}
  |__Value....: {"class_name": "Activation", "config": {"activation": "linear", "name": "activation_569", "trainable": true}, "inbound_nodes": [[["concatenate_569", 0, 0, {}]]], "name": "activation_569"}, 83110: OpenML Parameter
================
ID............: 83110
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_layer9
Flow URL......: https://www.openml.org/f/8599
Parameter Name: layer9
  |__Data Type: None
  |__Default..: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 16, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_5", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_1", 0, 0, {}]]], "name": "conv2d_5"}
  |__Value....: {"class_name": "Conv2D", "config": {"activation": "relu", "activity_regularizer": null, "bias_constraint": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "bias_regularizer": null, "data_format": "channels_last", "dilation_rate": [1, 1], "filters": 16, "kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "mode": "fan_avg", "scale": 1.0, "seed": null}}, "kernel_regularizer": null, "kernel_size": [1, 1], "name": "conv2d_1851", "padding": "same", "strides": [1, 1], "trainable": true, "use_bias": true}, "inbound_nodes": [[["activation_569", 0, 0, {}]]], "name": "conv2d_1851"}, 83111: OpenML Parameter
================
ID............: 83111
Flow ID.......: 8599
Flow Name.....: keras.wrappers.scikit_learn.KerasClassifier(InputLayer,Reshape,Conv2D,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Conv2D,Conv2D,Conv2D,Concatenate,Activation,MaxPooling2D,Conv2D,Conv2D,Conv2D,Concatenate,Activation,Dropout,Conv2D,AveragePooling2D,Flatten,Dense)(1)_verbose
Flow URL......: https://www.openml.org/f/8599
Parameter Name: verbose
  |__Data Type: None
  |__Default..: 2
  |__Value....: 2}]`

---

**IMPORTANT RULE**

* Do **not** use any class, function, method, or module outside the **ALLOWED CLASSES** list.

---

**EXAMPLES**

* See provided examples for valid usage of hyperparameters, conditions, forbidden clauses, and priors.

[EXAMPLES]

# Example 1: Basic ConfigurationSpace
```python
from ConfigSpace import ConfigurationSpace

cs = ConfigurationSpace(
    space={
        "C": (-1.0, 1.0),
        "max_iter": (10, 100),
    },
)
```
# Example 2: Adding Hyperparameters
```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer

kernel_type = Categorical('kernel_type', ['linear', 'poly', 'rbf', 'sigmoid'])
degree = Integer('degree', bounds=(2, 4), default=2)
coef0 = Float('coef0', bounds=(0, 1), default=0.0)
gamma = Float('gamma', bounds=(1e-5, 1e2), default=1, log=True)

cs = ConfigurationSpace()
cs.add([kernel_type, degree, coef0, gamma])
```
# Example 3: Adding Conditions
```python
from ConfigSpace import EqualsCondition, InCondition, OrConjunction

cond_1 = EqualsCondition(degree, kernel_type, 'poly')
cond_2 = OrConjunction(
    EqualsCondition(coef0, kernel_type, 'poly'),
    EqualsCondition(coef0, kernel_type, 'sigmoid')
)
cond_3 = InCondition(gamma, kernel_type, ['rbf', 'poly', 'sigmoid'])
```
# Example 4: Adding Forbidden Clauses
```pyhon
from ConfigSpace import ForbiddenEqualsClause, ForbiddenAndConjunction

penalty_and_loss = ForbiddenAndConjunction(
    ForbiddenEqualsClause(penalty, "l1"),
    ForbiddenEqualsClause(loss, "hinge")
)
constant_penalty_and_loss = ForbiddenAndConjunction(
    ForbiddenEqualsClause(dual, "False"),
    ForbiddenEqualsClause(penalty, "l2"),
    ForbiddenEqualsClause(loss, "hinge")
)
penalty_and_dual = ForbiddenAndConjunction(
    ForbiddenEqualsClause(dual, "False"),
    ForbiddenEqualsClause(penalty, "l1")
)
```
Example 5: Serialization
```python
from pathlib import Path
from ConfigSpace import ConfigurationSpace

path = Path("configspace.yaml")
cs = ConfigurationSpace(
    space={
        "C": (-1.0, 1.0),
        "max_iter": (10, 100),
    },
)
cs.to_yaml(path)
loaded_cs = ConfigurationSpace.from_yaml(path)
```
# Example 6: Priors
```python
import numpy as np
from ConfigSpace import ConfigurationSpace, Float, Categorical, Beta, Normal

cs = ConfigurationSpace(
    space={
        "lr": Float(
            'lr',
            bounds=(1e-5, 1e-1),
            default=1e-3,
            log=True,
            distribution=Normal(1e-3, 1e-1)
        ),
        "dropout": Float(
            'dropout',
            bounds=(0, 0.99),
            default=0.25,
            distribution=Beta(alpha=2, beta=4)
        ),
        "activation": Categorical(
            'activation',
            items=['tanh', 'relu'],
            weights=[0.2, 0.8]
        ),
    },
)
--------------------------------------------------------------------------------
[2025-06-07 09:19:46] [Metadata: {'component': 'config', 'action': 'run'}] Running config code:
--------------------------------------------------------------------------------
[2025-06-07 09:19:46] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#1): No module named 'ConfigSpace.Forbidden'
--------------------------------------------------------------------------------
[2025-06-07 09:19:46] [Metadata: {'component': 'config', 'action': 'fix'}] The following python code is generated by an LLM which now has run into the following errors:
No module named 'ConfigSpace.Forbidden'

Your task is to fix the issues in the code. The requirements below MUST be respected:

1. Do not change the function name or its purpose.
2. Fix all syntax and runtime errors.
3. Use only valid parameters.
4. Do not change the logic unless necessary for fixing errors.
5. Return ONLY the corrected function code  no explanations, comments, or extra output.
6. The function must be syntactically and semantically correct, and executable with `exec`.

Buggy code:
```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace.Forbidden import ForbiddenAndConjunction, ForbiddenEqualsClause
from ConfigSpace.Conditions import EqualsCondition

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    model_type = Categorical("model_type", ["cnn", "mlp"], default="cnn")
    normalize = Categorical("normalize", [True, False], default=True)
    
    # CNN hyperparameters
    cnn_layers = Integer("cnn_layers", (1, 3), default=2)
    cnn_filters_1 = Integer("cnn_filters_1", (8, 64), default=32, log=True)
    cnn_filters_2 = Integer("cnn_filters_2", (8, 64), default=32, log=True)
    cnn_filters_3 = Integer("cnn_filters_3", (8, 64), default=32, log=True)
    cnn_kernel_size = Integer("cnn_kernel_size", (3, 5), default=3)
    cnn_pooling = Categorical("cnn_pooling", ["max", "avg"], default="max")
    
    # MLP hyperparameters
    mlp_layers = Integer("mlp_layers", (1, 3), default=2)
    mlp_units_1 = Integer("mlp_units_1", (16, 512), default=128, log=True)
    mlp_units_2 = Integer("mlp_units_2", (16, 512), default=128, log=True)
    mlp_units_3 = Integer("mlp_units_3", (16, 512), default=128, log=True)
    dropout = Float("dropout", (0.0, 0.9), default=0.5)
    
    # Learning rate and optimizer
    learning_rate = Float("learning_rate", (1e-5, 1e-2), default=1e-3, log=True)
    optimizer = Categorical("optimizer", ["adam", "sgd"], default="adam")

    # Add hyperparameters to the ConfigurationSpace
    cs.add_hyperparameters([model_type, normalize, learning_rate, optimizer])
    
    # CNN parameters
    cs.add_hyperparameters([cnn_layers, cnn_filters_1, cnn_filters_2, cnn_filters_3, cnn_kernel_size, cnn_pooling])
    
    # MLP parameters
    cs.add_hyperparameters([mlp_layers, mlp_units_1, mlp_units_2, mlp_units_3, dropout])

    # Define conditions
    cnn_params = ["cnn_layers", "cnn_filters_1", "cnn_filters_2", "cnn_filters_3", "cnn_kernel_size", "cnn_pooling"]
    mlp_params = ["mlp_layers", "mlp_units_1", "mlp_units_2", "mlp_units_3", "dropout"]

    for param in cnn_params:
      cs.add_condition(EqualsCondition(cs[param].name, model_type, "cnn"))
    for param in mlp_params:
      cs.add_condition(EqualsCondition(cs[param].name, model_type, "mlp"))
    
    # Define forbidden clauses
    forbidden_filter_comb1 = ForbiddenAndConjunction(
        ForbiddenEqualsClause(model_type, "cnn"),
        ForbiddenEqualsClause(cnn_layers, 1),
        ForbiddenEqualsClause(cnn_filters_2, 32)
    )

    cs.add_forbidden_clause(forbidden_filter_comb1)

    return cs
```

--------------------------------------------------------------------------------
[2025-06-07 09:19:50] [Metadata: {'component': 'config', 'action': 'run'}] Running config code:
--------------------------------------------------------------------------------
[2025-06-07 09:19:51] [Metadata: {'component': 'scenario'}] ---

**Objective:**
Generate a **Python function** named `generate_scenario(cs)` that returns a valid `Scenario` object configured for SMAC (v2.0+), strictly following the rules below.

---

**Output Format Rules (Strict):**

* Output **only** the function `generate_scenario(cs)` and the **necessary import statements**.
* Use **Python 3.10 syntax** but **do not** include type annotations for the function or parameters.
* The code must be **fully executable** with the latest **SMAC v2.0+** version.
* Output **only valid Python code**  **no comments**, **no explanations**, **no extra text**, and **no example usage**.
* The function must be **self-contained**.

---

**Functional Requirements:**

* The input `cs` is a `ConfigurationSpace` object.
* Return a `Scenario` configured with the following:
  * `output_directory`: `"./automl_results"`
  * `deterministic`: `False` (enable variability)
  * `n_workers`: greater than 1 (to enable parallel optimization)
  * `min_budget` and `max_budget`: set appropriately for multi-fidelity tuning (e.g., training epochs)
---

**Reminder:** The output must be limited to:

* Valid `import` statements
* A single `generate_scenario(cs)` function that returns a properly configured `Scenario` object

---

            Based on the following SMAC documentation, analyze the dataset characteristics and choose appropriate:
            1. Facade type (e.g., MultiFidelityFacade for multi-fidelity optimization)
            2. Budget settings (min_budget and max_budget)
            3. Number of workers (n_workers)
            4. Other relevant scenario parameters

            SMAC Documentation:
            Getting Started
#
SMAC needs four core components (configuration space, target function, scenario and a facade) to run an
optimization process, all of which are explained on this page.
They interact in the following way:
Interaction of SMAC's components
Configuration Space
#
The configuration space defines the search space of the hyperparameters and, therefore, the tunable parameters' legal
ranges and default values.
from
ConfigSpace
import
ConfigSpace
cs
=
ConfigurationSpace
({
"myfloat"
:
(
0.1
,
1.5
),
# Uniform Float
"myint"
:
(
2
,
10
),
# Uniform Integer
"species"
:
[
"mouse"
,
"cat"
,
"dog"
],
# Categorical
})
Please see the documentation of
ConfigurationSpace
for more details.
Target Function
#
The target function takes a configuration from the configuration space and returns a performance value.
For example, you could use a Neural Network to predict on your data and get some validation performance.
If, for instance, you would tune the learning rate of the Network's optimizer, every learning rate will
change the final validation performance of the network. This is the target function.
SMAC tries to find the best performing learning rate by trying different values and evaluating the target function -
in an efficient way.
def
train
(
self
,
config
:
Configuration
,
seed
:
int
)
->
float
:
model
=
MultiLayerPerceptron
(
learning_rate
=
config
[
"learning_rate"
])
model
.
fit
(
...
)
accuracy
=
model
.
validate
(
...
)
return
1
-
accuracy
# SMAC always minimizes (the smaller the better)
Note
In general, the arguments of the target function depend on the intensifier. However,
in all cases, the first argument must be the configuration (arbitrary argument name is possible here) and a seed.
If you specified instances in the scenario, SMAC requires
instance
as argument additionally. If you use
SuccessiveHalving
or
Hyperband
as intensifier but you did not specify instances, SMAC passes
budget
as
argument to the target function. But don't worry: SMAC will tell you if something is missing or if something is not
used.
Warning
SMAC
always
minimizes the value returned from the target function.
Warning
SMAC passes either
instance
or
budget
to the target function but never both.
Scenario
#
The
Scenario
is used to provide environment variables. For example, 
if you want to limit the optimization process by a time limit or want to specify where to save the results.
from
smac
import
Scenario
scenario
=
Scenario
(
configspace
=
cs
,
name
=
"experiment_name"
,
output_directory
=
Path
(
"your_output_directory"
)
walltime_limit
=
120
,
# Limit to two minutes
n_trials
=
500
,
# Evaluated max 500 trials
n_workers
=
8
,
# Use eight workers
...
)
Note
If no
name
is given, a hash of the experiment is used. Running the same experiment again at a later time will result in exactly the same hash. This is important, because the optimization will warmstart on the preexisting evaluations, if not otherwise specified in the
Facade
.
Facade
#
Warn
By default Facades will try to warmstart on preexisting logs. This behavior can be specified using the
overwrite
parameter.
A
facade
is the entry point to SMAC, which constructs a default optimization 
pipeline for you. SMAC offers various facades, which satisfy many common use cases and are crucial to
achieving peak performance. The idea behind the facades is to provide a simple interface to all of SMAC's components,
which is easy to use and understand and without the need of deep diving into the material. However, experts are
invited to change the components to their specific hyperparameter optimization needs. The following
table (horizontally scrollable) shows you what is supported and reveals the default
components
:
Black-Box
Hyperparameter Optimization
Multi-Fidelity
Algorithm Configuration
Random
Hyperband
#Parameters
low
low/medium/high
low/medium/high
low/medium/high
low/medium/high
low/medium/high
Supports Instances






Supports Multi-Fidelity






Initial Design
Sobol
Sobol
Random
Default
Default
Default
Surrogate Model
Gaussian Process
Random Forest
Random Forest
Random Forest
Not used
Not used
Acquisition Function
Expected Improvement
Log Expected Improvement
Log Expected Improvement
Expected Improvement
Not used
Not used
Acquisition Maximizer
Local and Sorted Random Search
Local and Sorted Random Search
Local and Sorted Random Search
Local and Sorted Random Search
Not Used
Not Used
Intensifier
Default
Default
Hyperband
Default
Default
Hyperband
Runhistory Encoder
Default
Log
Log
Default
Default
Default
Random Design Probability
8.5%
20%
20%
50%
Not used
Not used
Info
The multi-fidelity facade is the closest implementation to
BOHB
.
Note
We want to emphasize that SMAC is a highly modular optimization framework.
The facade accepts many arguments to specify components of the pipeline. Please also note, that in contrast
to previous versions, instantiated objects are passed instead of
kwargs
.
The facades can be imported directly from the
smac
module.
from
smac
import
BlackBoxFacade
as
BBFacade
from
smac
import
HyperparameterOptimizationFacade
as
HPOFacade
from
smac
import
MultiFidelityFacade
as
MFFacade
from
smac
import
AlgorithmConfigurationFacade
as
ACFacade
from
smac
import
RandomFacade
as
RFacade
from
smac
import
HyperbandFacade
as
HBFacade
smac
=
HPOFacade
(
scenario
=
scenario
,
target_function
=
train
)
smac
=
MFFacade
(
scenario
=
scenario
,
target_function
=
train
)
smac
=
ACFacade
(
scenario
=
scenario
,
target_function
=
train
)
smac
=
RFacade
(
scenario
=
scenario
,
target_function
=
train
)
smac
=
HBFacade
(
scenario
=
scenario
,
target_function
=
train
)

Multi-Fidelity Optimization
#
Multi-fidelity refers to running an algorithm on multiple budgets (such as number of epochs or
subsets of data) and thereby evaluating the performance prematurely. You can run a multi-fidelity optimization
when using
Successive Halving
or
Hyperband
.
Hyperband
is the default intensifier in the
multi-fidelity facade
and requires the arguments
min_budget
and
max_budget
in the scenario if no instances are used.
In general, multi-fidelity works for both real-valued and instance budgets. In the real-valued case,
the budget is directly passed to the target function. In the instance case, the budget is not passed to the 
target function but
min_budget
and
max_budget
are used internally to determine the number of instances of 
each stage. That's also the reason why
min_budget
and
max_budget
are
not required
when using instances: 
The
max_budget
is simply the max number of instances, whereas the
min_budget
is simply 1.
Warning
smac.main.config_selector.ConfigSelector
contains the
min_trials
parameter. This parameter determines
how many samples are required to train the surrogate model. If budgets are involved, the highest budgets 
are checked first. For example, if min_trials is three, but we find only two trials in the runhistory for
the highest budget, we will use trials of a lower budget instead.
Please have a look into our
multi-fidelity examples
to see how to use
multi-fidelity optimization in real-world applications.

Components
#
In addition to the basic components mentioned in
Getting Started
, all other components are
explained in the following paragraphs to give a better picture of SMAC. These components are all used to guide
the optimization process and simple changes can influence the results drastically.
Before diving into the components, we shortly want to explain the main Bayesian optimization loop in SMAC.
The
SMBO
receives all instantiated components from the facade and the logic happens here.
In general, a while loop is used to ask for the next trial, submit it to the runner, and wait for the runner to 
finish the evaluation. Since the runner and the
SMBO
object are decoupled, the while loop continues and asks for even 
more trials (e.g., in case of multi-threading), which also can be submitted to the runner. If all workers are
occupied, SMAC will wait until a new worker is available again. Moreover, limitations like wallclock time and remaining 
trials are checked in every iteration.
Surrogate Model
#
The surrogate model is used to approximate the objective function of configurations. In previous versions, the model was 
referred to as the Empirical Performance Model (EPM). Mostly, Bayesian optimization is used/associated with Gaussian
processes. However, SMAC also incorporates random forests as surrogate models, which makes it possible to optimize for 
higher dimensional and complex spaces.
The data used to train the surrogate model is collected by the runhistory encoder (receives data from the runhistory 
and transforms it). If budgets are
involved, the highest budget which satisfies
min_trials
(defaults to 1) in
smac.main.config_selector
is
used. If no budgets are used, all observations are used.
If you are using instances, it is recommended to use instance features. The model is trained on each instance 
associated with its features. Imagine you have two hyperparameters, two instances and no instance features, the model 
would be trained on:
HP 1
HP 2
Objective Value
0.1
0.8
0.5
0.1
0.8
0.75
505
7
2.4
505
7
1.3
You can see that the same inputs lead to different objective values because of two instances. If you associate
each instance with a feature, you would end-up with the following data points:
HP 1
HP 2
Instance Feature
Objective Value
0.1
0.8
0
0.5
0.1
0.8
1
0.75
505
7
0
2.4
505
7
1
1.3
The steps to receiving data are as follows:
The intensifier requests new configurations via
next(self.config_generator)
.
The config selector collects the data via the runhistory encoder which iterates over the runhistory trials.
The runhistory encoder only collects trials which are in
considered_states
and timeout trials. Also, only the
   highest budget is considered if budgets are used. In this step, multi-objective values are scalarized using the
normalize_costs
function (uses
objective_bounds
from the runhistory) and the multi-objective algorithm.
   For example, when ParEGO is used, the scalarization would be different in each training.
The selected trial objectives are transformed (e.g., log-transformed, depending on the selected
   encoder).
The hyperparameters might still have inactive values. The model takes care of that after the collected data
   are passed to the model.
Acquisition Function
#
Acquisition functions are mathematical techniques that guide how the parameter space should be explored during Bayesian 
optimization. They use the predicted mean and predicted variance generated by the surrogate model.
The acquisition function is used by the acquisition maximizer (see next section). Otherwise, SMAC provides
a bunch of different acquisition functions (Lower Confidence Bound, Expected Improvement, Probability Improvement, 
Thompson, integrated acquisition functions and prior acquisition functions). We refer to literature 
for more information about acquisition functions.
Note
The acquisition function calculates the acquisition value for each configuration. However, the configurations
are provided by the acquisition maximizer. Therefore, the acquisition maximizer is responsible for receiving
the next configurations.
Acquisition Maximize
#
The acquisition maximizer is a wrapper for the acquisition function. It returns the next configurations. SMAC
supports local search, (sorted) random search, local and (sorted) random search, and differential evolution.
While local search checks neighbours of the best configurations, random search makes sure to explore the configuration
space. When using sorted random search, random configurations are sorted by the value of the acquisition function.
Warning
Pay attention to the number of challengers: If you experience RAM issues or long computational times in the
acquisition function, you might lower the number of challengers.
The acquisition maximizer also incorporates the
Random Design
. Please see the
ChallengerList
for more information.
Initial Design
#
The surrogate model needs data to be trained. Therefore, the initial design is used to generate the initial data points.
We provide random, latin hypercube, sobol, factorial and default initial designs. The default initial design uses
the default configuration from the configuration space and with the factorial initial design, we generate corner
points of the configuration space. The sobol sequences are an example of quasi-random low-discrepancy sequences and
the latin hypercube design is a statistical method for generating a near-random sample of parameter values from
a multidimensional distribution.
The initial design configurations are yielded by the config selector first. Moreover, the config selector keeps
track of which configurations already have been returned to make sure a configuration is not returned twice.
Random Design
#
The random design is used in the acquisition maximizer to tell whether the next configuration should be
random or sampled from the acquisition function. For example, if we use a random design with a probability of 
50%, we have a 50% chance to sample a random configuration and a 50% chance to sample a configuration from the
acquisition function (although the acquisition function includes exploration and exploitation trade-off already). 
This design makes sure that the optimization process is not stuck in a local optimum and we 
are
guaranteed
to find the best configuration over time.
In addition to simple probability random design, we also provide annealing and modulus random design.
Intensifier
#
The intensifier compares different configurations based on evaluated :term:
trial<Trial>
so far. It decides
which configuration should be
intensified
or, in other words, if a configuration is worth to spend more time on (e.g.,
evaluate another seed pair, evaluate on another instance, or evaluate on a higher budget).
Warning
Always pay attention to
max_config_calls
or
n_seeds
: If this argument is set high, the intensifier might 
spend a lot of time on a single configuration.
Depending on the components and arguments, the intensifier tells you which seeds, budgets, and/or instances
are used throughout the optimization process. You can use the methods
uses_seeds
,
uses_budgets
, and
uses_instances
(directly callable via the facade) to (sanity-)check whether the intensifier uses these arguments.
Another important fact is that the intensifier keeps track of the current incumbent (a.k.a. the best configuration 
found so far). In case of multi-objective, multiple incumbents could be found.
All intensifiers support multi-objective, multi-fidelity, and multi-threading:
Multi-Objective: Keeping track of multiple incumbents at once.
Multi-Fidelity: Incorporating instances or budgets.
Multi-Threading: Intensifier are implemented as generators so that calling
next
on the intensifier can be
  repeated as often as needed. Intensifier are not required to receive results as the results are directly taken from
  the runhistory.
Note
All intensifiers are working on the runhistory and recognize previous logged trials (e.g., if the user already
evaluated something beforehand). Previous configurations (in the best case, also complete trials) are added to the 
queue/tracker again so that they are integrated into the intensification process.
That means continuing a run as well as incorporating user inputs are natively supported.
Configuration Selector
#
The configuration selector uses the initial design, surrogate model, acquisition maximizer/function, runhistory,
runhistory encoder, and random design to select the next configuration. The configuration selector is directly
used by the intensifier and is called everytime a new configuration is requested.
The idea behind the configuration selector is straight forward:
Yield the initial design configurations.
Train the surrogate model with the data from the runhistory encoder.
Get the next
retrain_after
configurations from the acquisition function/maximizer and yield them.
After all
retrain_after
configurations were yield, go back to step 2.
Note
The configuration selector is a generator and yields configurations. Therefore, the current state of the 
selector is saved and when the intensifier calls
next
, the selector continues there where it stopped.
Note
Everytime the surrogate model is trained, the multi-objective algorithm is updated via
update_on_iteration_start
.
Multi-Objective Algorithm
#
The multi-objective algorithm is used to scalarize multi-objective values. The multi-objective algorithm 
gets normalized objective values passed and returns a single value. The resulting value (called by the 
runhistory encoder) is then used to train the surrogate model.
Warning
Depending on the multi-objective algorithm, the values for the runhistory encoder might differ each time 
the surrogate model is trained. Let's take ParEGO for example:
Everytime a new configuration is sampled (see ConfigSelector), the objective weights are updated. Therefore,
the scalarized values are different and the acquisition maximizer might return completely different configurations.
RunHistory
#
The runhistory holds all (un-)evaluated trials of the optimization run. You can use the runhistory to 
get (running) configs, (running) trials, trials of a specific config, and more.
The runhistory encoder iterates over the runhistory to receive data for the surrogate model. The following 
code shows how to iterate over the runhistory:
smac
=
HPOFacade
(
...
)
# Iterate over all trials
for
trial_info
,
trial_value
in
smac
.
runhistory
.
items
():
# Trial info
config
=
trial_info
.
config
instance
=
trial_info
.
instance
budget
=
trial_info
.
budget
seed
=
trial_info
.
seed
# Trial value
cost
=
trial_value
.
cost
time
=
trial_value
.
time
status
=
trial_value
.
status
starttime
=
trial_value
.
starttime
endtime
=
trial_value
.
endtime
additional_info
=
trial_value
.
additional_info
# Iterate over all configs
for
config
in
smac
.
runhistory
.
get_configs
():
# Get the cost of all trials of this config
average_cost
=
smac
.
runhistory
.
average_cost
(
config
)
Warning
The intensifier uses a callback to update the incumbent everytime a new trial is added to the runhistory.
RunHistory Encoder
#
The runhistory encoder is used to encode the runhistory data into a format that can be used by the surrogate model.
Only trials with the status
considered_states
and timeout trials are considered. Multi-objective values are 
scalarized using the
normalize_costs
function (uses
objective_bounds
from the runhistory). Afterwards, the 
normalized value is processed by the multi-objective algorithm.
Callback
#
Callbacks provide the ability to easily execute code before, inside, and after the Bayesian optimization loop.
To add a callback, you have to inherit from
smac.Callback
and overwrite the methods (if needed).
Afterwards, you can pass the callbacks to any facade.
from
smac
import
MultiFidelityFacade
,
Callback
class
CustomCallback
(
Callback
):
def
on_start
(
self
,
smbo
:
SMBO
)
->
None
:
pass
def
on_end
(
self
,
smbo
:
SMBO
)
->
None
:
pass
def
on_iteration_start
(
self
,
smbo
:
SMBO
)
->
None
:
pass
def
on_iteration_end
(
self
,
smbo
:
SMBO
,
info
:
RunInfo
,
value
:
RunValue
)
->
bool
|
None
:
# We just do a simple printing here
print
(
info
,
value
)
smac
=
MultiFidelityFacade
(
...
callbacks
=
[
CustomCallback
()]
)
smac
.
optimize
()
            Please analyze the dataset and documentation to determine:
            1. Should multi-fidelity optimization be used? (Consider dataset size and training time)
            2. What budget range is appropriate? (Consider training epochs or data subsets)
            3. How many workers should be used? (Consider available resources)
            4. Are there any special considerations for this dataset type?

            Then generate a scenario configuration that best suits this dataset.
            
--------------------------------------------------------------------------------
[2025-06-07 09:19:51] [Metadata: {'component': 'scenario', 'action': 'run'}] Running scenario code:
--------------------------------------------------------------------------------
[2025-06-07 09:19:58] [Metadata: {'component': 'train_function'}] **Generate production-grade Python code for a machine learning training function with the following STRICT requirements:**

---

### **Function signature** must be:

```python
from ConfigSpace import Configuration
def train(cfg: Configuration, dataset: Any, seed: int) -> float:
```

---

### **Function Behavior Requirements:**

* The function **must accept** a `dataset` dictionary with:

  * `dataset['X']`: feature matrix or input tensor
  * `dataset['y']`: label vector or label tensor

* Assume `cfg` is a sampled configuration object:

  * Access primitive values using `cfg.get('key')` (only `int`, `float`, `str`, etc.).
  * **Do not access or manipulate non-primitive hyperparameter objects**.

* The function must return the **average training loss** over 10 epochs.

* You must carefully read and follow the dataset description provided, which includes:
  * Data format and dimensions
  * Required preprocessing steps
  * Special handling requirements
  * Framework-specific considerations

```python
return loss  # float
```

* Lower `loss` means a better model.

---

### **Frameworks**

You may choose **PyTorch**, **TensorFlow**, or **scikit-learn**, depending on the dataset and supporting code provided.

---

### **Model Requirements**

* Infer input and output dimensions dynamically from the dataset
* Follow the data format requirements specified in the dataset description
* Handle any necessary data transformations as described in the dataset description

---

### **Supporting Code Provided:**

* ConfigSpace definition: `from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace.forbidden import ForbiddenAndConjunction, ForbiddenEqualsClause
from ConfigSpace.conditions import EqualsCondition

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    model_type = Categorical("model_type", ["cnn", "mlp"], default="cnn")
    normalize = Categorical("normalize", [True, False], default=True)
    
    # CNN hyperparameters
    cnn_layers = Integer("cnn_layers", (1, 3), default=2)
    cnn_filters_1 = Integer("cnn_filters_1", (8, 64), default=32, log=True)
    cnn_filters_2 = Integer("cnn_filters_2", (8, 64), default=32, log=True)
    cnn_filters_3 = Integer("cnn_filters_3", (8, 64), default=32, log=True)
    cnn_kernel_size = Integer("cnn_kernel_size", (3, 5), default=3)
    cnn_pooling = Categorical("cnn_pooling", ["max", "avg"], default="max")
    
    # MLP hyperparameters
    mlp_layers = Integer("mlp_layers", (1, 3), default=2)
    mlp_units_1 = Integer("mlp_units_1", (16, 512), default=128, log=True)
    mlp_units_2 = Integer("mlp_units_2", (16, 512), default=128, log=True)
    mlp_units_3 = Integer("mlp_units_3", (16, 512), default=128, log=True)
    dropout = Float("dropout", (0.0, 0.9), default=0.5)
    
    # Learning rate and optimizer
    learning_rate = Float("learning_rate", (1e-5, 1e-2), default=1e-3, log=True)
    optimizer = Categorical("optimizer", ["adam", "sgd"], default="adam")

    # Add hyperparameters to the ConfigurationSpace
    cs.add_hyperparameters([model_type, normalize, learning_rate, optimizer])
    
    # CNN parameters
    cs.add_hyperparameters([cnn_layers, cnn_filters_1, cnn_filters_2, cnn_filters_3, cnn_kernel_size, cnn_pooling])
    
    # MLP parameters
    cs.add_hyperparameters([mlp_layers, mlp_units_1, mlp_units_2, mlp_units_3, dropout])

    # Define conditions
    cnn_params = [cnn_layers, cnn_filters_1, cnn_filters_2, cnn_filters_3, cnn_kernel_size, cnn_pooling]
    mlp_params = [mlp_layers, mlp_units_1, mlp_units_2, mlp_units_3, dropout]

    for param in cnn_params:
      cs.add_condition(EqualsCondition(param, model_type, "cnn"))
    for param in mlp_params:
      cs.add_condition(EqualsCondition(param, model_type, "mlp"))
    
    # Define forbidden clauses
    forbidden_filter_comb1 = ForbiddenAndConjunction(
        ForbiddenEqualsClause(model_type, "cnn"),
        ForbiddenEqualsClause(cnn_layers, 1),
        ForbiddenEqualsClause(cnn_filters_2, 32)
    )

    cs.add_forbidden_clause(forbidden_filter_comb1)

    return cs
`
* SMAC scenario: `import os

from smac import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs):
    scenario = Scenario(
        configspace=cs,
        output_directory="./automl_results",
        deterministic=False,
        n_workers=2,
        min_budget=1,
        max_budget=3
    )
    return scenario
`
* Dataset description: `This is an image dataset.

Number of classes: 10
Class distribution:
1    6742
7    6265
3    6131
2    5958
9    5949
0    5923
6    5918
8    5851
4    5842
5    5421
Name: count, dtype: int64

Image Data Handling Requirements:
1. Input Format Requirements:
   - For CNN models: Input must be in (batch, channels, height, width) format
   - For dense/linear layers: Input should be flattened

2. Data Processing Steps:
   a) For flattened input (2D):
      - Calculate dimensions: height = width = int(sqrt(n_features))
      - Verify square dimensions: height * height == n_features
      - Reshape to (N, 1, H, W) for CNNs
   b) For 3D input (N, H, W):
      - Add channel dimension: reshape to (N, 1, H, W)
   c) For 4D input:
      - Verify channel order matches framework requirements

3. Framework-Specific Format:
   - PyTorch: (N, C, H, W)
   - TensorFlow: (N, H, W, C)
   - Convert between formats if necessary

4. Normalization:
   - Scale pixel values to [0, 1] by dividing by 255.0
   - Or standardize to mean=0, std=1
`

---

### **Additional Instructions**

* The code must not hardcode dataset dimensions
* The function must be runnable and not assume unavailable classes or modules
* You must only output the `def train(...)` function and nothing else
* Always check dataset description for format hints and requirements before processing

--------------------------------------------------------------------------------
[2025-06-07 09:19:58] [Metadata: {'component': 'train_function', 'action': 'run'}] Running train_function code:
--------------------------------------------------------------------------------
[2025-06-07 09:19:59] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#1): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-06-07 09:19:59] [Metadata: {'component': 'train_function', 'action': 'fix'}] The following python code is generated by an LLM which now has run into the following errors:
expected sequence of length 60000 at dim 0 (got 784)

Your task is to fix the issues in the code. The requirements below MUST be respected:

1. Do not change the function name or its purpose.
2. Fix all syntax and runtime errors.
3. Use only valid parameters.
4. Do not change the logic unless necessary for fixing errors.
5. Return ONLY the corrected function code  no explanations, comments, or extra output.
6. The function must be syntactically and semantically correct, and executable with `exec`.

Buggy code:
```python
from typing import Any
from ConfigSpace import Configuration
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from math import sqrt


def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a machine learning model based on the provided configuration and dataset.

    Args:
        cfg (Configuration): A ConfigSpace Configuration object containing the hyperparameters.
        dataset (Any): A dictionary containing the training data, with keys 'X' (features) and 'y' (labels).
        seed (int): Random seed for reproducibility.

    Returns:
        float: The average training loss over 10 epochs.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions
    n_samples = X.shape[0]
    n_features = X.shape[1]
    n_classes = len(np.unique(y))

    # Data Preprocessing and Formatting
    X = X.astype(np.float32)
    if cfg.get("normalize"):
        X = X / 255.0  # Normalize to [0, 1]
    else:
      X = (X - np.mean(X)) / np.std(X)  # Standardize

    # Reshape and convert to tensor
    if cfg.get("model_type") == "cnn":
        height = width = int(sqrt(n_features))
        assert height * height == n_features, "Input is not square"
        X = X.reshape(n_samples, 1, height, width)  # Add channel dimension
        X = torch.tensor(X, dtype=torch.float32)
    else:
        X = torch.tensor(X, dtype=torch.float32)  # Flattened input for MLP
    y = torch.tensor(y, dtype=torch.long)

    # Model Definition
    if cfg.get("model_type") == "cnn":
        class CNN(nn.Module):
            def __init__(self, num_classes):
                super(CNN, self).__init__()
                layers = []
                in_channels = 1  # MNIST-like data has 1 channel
                for i in range(cfg.get("cnn_layers")):
                    filters = cfg.get(f"cnn_filters_{i+1}") if i < 3 else 32 # Default to 32 if not defined
                    layers.append(nn.Conv2d(in_channels, filters, kernel_size=cfg.get("cnn_kernel_size")))
                    layers.append(nn.ReLU())
                    if cfg.get("cnn_pooling") == "max":
                        layers.append(nn.MaxPool2d(2))
                    else:
                        layers.append(nn.AvgPool2d(2))
                    in_channels = filters
                self.features = nn.Sequential(*layers)

                # Determine the output size after convolutional layers
                self.fc = nn.Linear(self._get_conv_output(X.shape[1:]), num_classes)

            def _get_conv_output(self, shape):
              bs = 1
              input = torch.autograd.Variable(torch.rand(bs, *shape))
              output_feat = self.features(input)
              n_size = output_feat.data.view(bs, -1).size(1)
              return n_size

            def forward(self, x):
                x = self.features(x)
                x = torch.flatten(x, 1)
                x = self.fc(x)
                return x

        model = CNN(num_classes=n_classes)

    else:  # MLP
        class MLP(nn.Module):
            def __init__(self, input_size, num_classes):
                super(MLP, self).__init__()
                layers = []
                input_dim = input_size
                for i in range(cfg.get("mlp_layers")):
                    units = cfg.get(f"mlp_units_{i+1}") if i < 3 else 128 # Default to 128 if not defined
                    layers.append(nn.Linear(input_dim, units))
                    layers.append(nn.ReLU())
                    layers.append(nn.Dropout(cfg.get("dropout")))
                    input_dim = units
                layers.append(nn.Linear(input_dim, num_classes))
                self.net = nn.Sequential(*layers)

            def forward(self, x):
                return self.net(x)

        model = MLP(input_size=n_features, num_classes=n_classes)

    # Optimizer
    if cfg.get("optimizer") == "adam":
        optimizer = optim.Adam(model.parameters(), lr=cfg.get("learning_rate"))
    else:
        optimizer = optim.SGD(model.parameters(), lr=cfg.get("learning_rate"))

    criterion = nn.CrossEntropyLoss()

    # Training Loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / epochs

    return avg_loss
```

--------------------------------------------------------------------------------
[2025-06-07 09:20:06] [Metadata: {'component': 'train_function', 'action': 'run'}] Running train_function code:
--------------------------------------------------------------------------------
[2025-06-07 09:20:06] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#2): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-06-07 09:20:06] [Metadata: {'component': 'train_function', 'action': 'fix'}] The following python code is generated by an LLM which now has run into the following errors:
expected sequence of length 60000 at dim 0 (got 784)
expected sequence of length 60000 at dim 0 (got 784)

Your task is to fix the issues in the code. The requirements below MUST be respected:

1. Do not change the function name or its purpose.
2. Fix all syntax and runtime errors.
3. Use only valid parameters.
4. Do not change the logic unless necessary for fixing errors.
5. Return ONLY the corrected function code  no explanations, comments, or extra output.
6. The function must be syntactically and semantically correct, and executable with `exec`.

Buggy code:
```python
from typing import Any
from ConfigSpace import Configuration
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from math import sqrt


def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a machine learning model based on the provided configuration and dataset.

    Args:
        cfg (Configuration): A ConfigSpace Configuration object containing the hyperparameters.
        dataset (Any): A dictionary containing the training data, with keys 'X' (features) and 'y' (labels).
        seed (int): Random seed for reproducibility.

    Returns:
        float: The average training loss over 10 epochs.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions
    n_samples = X.shape[0]
    n_features = X.shape[1]
    n_classes = len(np.unique(y))

    # Data Preprocessing and Formatting
    X = X.astype(np.float32)
    if cfg.get("normalize"):
        X = X / 255.0  # Normalize to [0, 1]
    else:
        X = (X - np.mean(X)) / np.std(X)  # Standardize

    # Reshape and convert to tensor
    if cfg.get("model_type") == "cnn":
        height = width = int(sqrt(n_features))
        assert height * height == n_features, "Input is not square"
        X = X.reshape(n_samples, 1, height, width)  # Add channel dimension
        X = torch.tensor(X, dtype=torch.float32)
    else:
        X = torch.tensor(X, dtype=torch.float32)  # Flattened input for MLP
    y = torch.tensor(y, dtype=torch.long)

    # Model Definition
    if cfg.get("model_type") == "cnn":
        class CNN(nn.Module):
            def __init__(self, num_classes):
                super(CNN, self).__init__()
                layers = []
                in_channels = 1  # MNIST-like data has 1 channel
                for i in range(cfg.get("cnn_layers")):
                    filters = cfg.get(f"cnn_filters_{i+1}") if f"cnn_filters_{i+1}" in cfg else 32 # Default to 32 if not defined
                    layers.append(nn.Conv2d(in_channels, filters, kernel_size=cfg.get("cnn_kernel_size")))
                    layers.append(nn.ReLU())
                    if cfg.get("cnn_pooling") == "max":
                        layers.append(nn.MaxPool2d(2))
                    else:
                        layers.append(nn.AvgPool2d(2))
                    in_channels = filters
                self.features = nn.Sequential(*layers)

                # Determine the output size after convolutional layers
                self.fc = nn.Linear(self._get_conv_output((1, height, width)), num_classes)

            def _get_conv_output(self, shape):
              bs = 1
              input = torch.randn(bs, *shape)
              output_feat = self.features(input)
              n_size = output_feat.data.view(bs, -1).size(1)
              return n_size

            def forward(self, x):
                x = self.features(x)
                x = torch.flatten(x, 1)
                x = self.fc(x)
                return x

        model = CNN(num_classes=n_classes)

    else:  # MLP
        class MLP(nn.Module):
            def __init__(self, input_size, num_classes):
                super(MLP, self).__init__()
                layers = []
                input_dim = input_size
                for i in range(cfg.get("mlp_layers")):
                    units = cfg.get(f"mlp_units_{i+1}") if f"mlp_units_{i+1}" in cfg else 128 # Default to 128 if not defined
                    layers.append(nn.Linear(input_dim, units))
                    layers.append(nn.ReLU())
                    layers.append(nn.Dropout(cfg.get("dropout")))
                    input_dim = units
                layers.append(nn.Linear(input_dim, num_classes))
                self.net = nn.Sequential(*layers)

            def forward(self, x):
                return self.net(x)

        model = MLP(input_size=n_features, num_classes=n_classes)

    # Optimizer
    if cfg.get("optimizer") == "adam":
        optimizer = optim.Adam(model.parameters(), lr=cfg.get("learning_rate"))
    else:
        optimizer = optim.SGD(model.parameters(), lr=cfg.get("learning_rate"))

    criterion = nn.CrossEntropyLoss()

    # Training Loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / epochs

    return avg_loss
```

--------------------------------------------------------------------------------
[2025-06-07 09:20:13] [Metadata: {'component': 'train_function', 'action': 'run'}] Running train_function code:
--------------------------------------------------------------------------------
[2025-06-07 09:20:13] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#3): expected sequence of length 60000 at dim 0 (got 784)
--------------------------------------------------------------------------------
[2025-06-07 09:20:13] [Metadata: {'component': 'train_function', 'action': 'fix'}] The following python code is generated by an LLM which now has run into the following errors:
expected sequence of length 60000 at dim 0 (got 784)
expected sequence of length 60000 at dim 0 (got 784)
expected sequence of length 60000 at dim 0 (got 784)

Your task is to fix the issues in the code. The requirements below MUST be respected:

1. Do not change the function name or its purpose.
2. Fix all syntax and runtime errors.
3. Use only valid parameters.
4. Do not change the logic unless necessary for fixing errors.
5. Return ONLY the corrected function code  no explanations, comments, or extra output.
6. The function must be syntactically and semantically correct, and executable with `exec`.

Buggy code:
```python
from typing import Any
from ConfigSpace import Configuration
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from math import sqrt


def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a machine learning model based on the provided configuration and dataset.

    Args:
        cfg (Configuration): A ConfigSpace Configuration object containing the hyperparameters.
        dataset (Any): A dictionary containing the training data, with keys 'X' (features) and 'y' (labels).
        seed (int): Random seed for reproducibility.

    Returns:
        float: The average training loss over 10 epochs.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions
    n_samples = X.shape[0]
    n_features = X.shape[1]
    n_classes = len(np.unique(y))

    # Data Preprocessing and Formatting
    X = X.astype(np.float32)
    if cfg.get("normalize"):
        X = X / 255.0  # Normalize to [0, 1]
    else:
        X = (X - np.mean(X)) / np.std(X)  # Standardize

    # Reshape and convert to tensor
    if cfg.get("model_type") == "cnn":
        height = width = int(sqrt(n_features))
        assert height * height == n_features, "Input is not square"
        X = X.reshape(n_samples, 1, height, width)  # Add channel dimension
        X = torch.tensor(X, dtype=torch.float32)
    else:
        X = torch.tensor(X, dtype=torch.float32)  # Flattened input for MLP
    y = torch.tensor(y, dtype=torch.long)

    # Model Definition
    if cfg.get("model_type") == "cnn":
        class CNN(nn.Module):
            def __init__(self, num_classes):
                super(CNN, self).__init__()
                layers = []
                in_channels = 1  # MNIST-like data has 1 channel
                for i in range(cfg.get("cnn_layers")):
                    filters = cfg.get(f"cnn_filters_{i+1}") if f"cnn_filters_{i+1}" in cfg else 32 # Default to 32 if not defined
                    layers.append(nn.Conv2d(in_channels, filters, kernel_size=cfg.get("cnn_kernel_size")))
                    layers.append(nn.ReLU())
                    if cfg.get("cnn_pooling") == "max":
                        layers.append(nn.MaxPool2d(2))
                    else:
                        layers.append(nn.AvgPool2d(2))
                    in_channels = filters
                self.features = nn.Sequential(*layers)

                # Determine the output size after convolutional layers
                self.fc = nn.Linear(self._get_conv_output((1, height, width)), num_classes)

            def _get_conv_output(self, shape):
              bs = 1
              input = torch.randn(bs, *shape)
              output_feat = self.features(input)
              n_size = output_feat.data.view(bs, -1).size(1)
              return n_size

            def forward(self, x):
                x = self.features(x)
                x = torch.flatten(x, 1)
                x = self.fc(x)
                return x

        model = CNN(num_classes=n_classes)

    else:  # MLP
        class MLP(nn.Module):
            def __init__(self, input_size, num_classes):
                super(MLP, self).__init__()
                layers = []
                input_dim = input_size
                for i in range(cfg.get("mlp_layers")):
                    units = cfg.get(f"mlp_units_{i+1}") if f"mlp_units_{i+1}" in cfg else 128 # Default to 128 if not defined
                    layers.append(nn.Linear(input_dim, units))
                    layers.append(nn.ReLU())
                    layers.append(nn.Dropout(cfg.get("dropout")))
                    input_dim = units
                layers.append(nn.Linear(input_dim, num_classes))
                self.net = nn.Sequential(*layers)

            def forward(self, x):
                return self.net(x)

        model = MLP(input_size=n_features, num_classes=n_classes)

    # Optimizer
    if cfg.get("optimizer") == "adam":
        optimizer = optim.Adam(model.parameters(), lr=cfg.get("learning_rate"))
    else:
        optimizer = optim.SGD(model.parameters(), lr=cfg.get("learning_rate"))

    criterion = nn.CrossEntropyLoss()

    # Training Loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / epochs

    return avg_loss
```

--------------------------------------------------------------------------------
[2025-06-07 09:20:19] [Metadata: {'component': 'train_function', 'action': 'run'}] Running train_function code:
--------------------------------------------------------------------------------
[2025-06-07 09:20:20] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#4): 'DataFrame' object has no attribute 'reshape'
--------------------------------------------------------------------------------
[2025-06-07 09:20:20] [Metadata: {'component': 'train_function', 'action': 'fix'}] The following python code is generated by an LLM which now has run into the following errors:
expected sequence of length 60000 at dim 0 (got 784)
expected sequence of length 60000 at dim 0 (got 784)
expected sequence of length 60000 at dim 0 (got 784)
'DataFrame' object has no attribute 'reshape'

Your task is to fix the issues in the code. The requirements below MUST be respected:

1. Do not change the function name or its purpose.
2. Fix all syntax and runtime errors.
3. Use only valid parameters.
4. Do not change the logic unless necessary for fixing errors.
5. Return ONLY the corrected function code  no explanations, comments, or extra output.
6. The function must be syntactically and semantically correct, and executable with `exec`.

Buggy code:
```python
from typing import Any
from ConfigSpace import Configuration
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from math import sqrt


def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a machine learning model based on the provided configuration and dataset.

    Args:
        cfg (Configuration): A ConfigSpace Configuration object containing the hyperparameters.
        dataset (Any): A dictionary containing the training data, with keys 'X' (features) and 'y' (labels).
        seed (int): Random seed for reproducibility.

    Returns:
        float: The average training loss over 10 epochs.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    X = dataset['X']
    y = dataset['y']

    # Infer input and output dimensions
    n_samples = X.shape[0]
    n_features = X.shape[1]
    n_classes = len(np.unique(y))

    # Data Preprocessing and Formatting
    X = X.astype(np.float32)
    if cfg.get("normalize", False):
        X = X / 255.0  # Normalize to [0, 1]
    else:
        X = (X - np.mean(X)) / np.std(X)  # Standardize

    # Reshape and convert to tensor
    if cfg.get("model_type") == "cnn":
        height = width = int(sqrt(n_features))
        assert height * height == n_features, "Input is not square"
        X = X.reshape(n_samples, 1, height, width)  # Add channel dimension
        X = torch.tensor(X, dtype=torch.float32)
    else:
        X = torch.tensor(X, dtype=torch.float32)  # Flattened input for MLP
    y = torch.tensor(y, dtype=torch.long)

    # Model Definition
    if cfg.get("model_type") == "cnn":
        class CNN(nn.Module):
            def __init__(self, num_classes):
                super(CNN, self).__init__()
                layers = []
                in_channels = 1  # MNIST-like data has 1 channel
                for i in range(cfg.get("cnn_layers")):
                    filters = cfg.get(f"cnn_filters_{i+1}", 32)  # Default to 32 if not defined
                    layers.append(nn.Conv2d(in_channels, filters, kernel_size=cfg.get("cnn_kernel_size")))
                    layers.append(nn.ReLU())
                    if cfg.get("cnn_pooling") == "max":
                        layers.append(nn.MaxPool2d(2))
                    else:
                        layers.append(nn.AvgPool2d(2))
                    in_channels = filters
                self.features = nn.Sequential(*layers)

                # Determine the output size after convolutional layers
                self.fc = nn.Linear(self._get_conv_output((1, height, width)), num_classes)

            def _get_conv_output(self, shape):
                bs = 1
                input = torch.randn(bs, *shape)
                output_feat = self.features(input)
                n_size = output_feat.data.view(bs, -1).size(1)
                return n_size

            def forward(self, x):
                x = self.features(x)
                x = torch.flatten(x, 1)
                x = self.fc(x)
                return x

        model = CNN(num_classes=n_classes)

    else:  # MLP
        class MLP(nn.Module):
            def __init__(self, input_size, num_classes):
                super(MLP, self).__init__()
                layers = []
                input_dim = input_size
                for i in range(cfg.get("mlp_layers")):
                    units = cfg.get(f"mlp_units_{i+1}", 128)  # Default to 128 if not defined
                    layers.append(nn.Linear(input_dim, units))
                    layers.append(nn.ReLU())
                    layers.append(nn.Dropout(cfg.get("dropout")))
                    input_dim = units
                layers.append(nn.Linear(input_dim, num_classes))
                self.net = nn.Sequential(*layers)

            def forward(self, x):
                return self.net(x)

        model = MLP(input_size=n_features, num_classes=n_classes)

    # Optimizer
    if cfg.get("optimizer") == "adam":
        optimizer = optim.Adam(model.parameters(), lr=cfg.get("learning_rate"))
    else:
        optimizer = optim.SGD(model.parameters(), lr=cfg.get("learning_rate"))

    criterion = nn.CrossEntropyLoss()
    X = X.view(X.shape[0], -1)
    # Training Loop
    epochs = 10
    total_loss = 0.0
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / epochs

    return avg_loss
```

--------------------------------------------------------------------------------
[2025-06-07 09:20:26] [Metadata: {'component': 'train_function', 'action': 'run'}] Running train_function code:
--------------------------------------------------------------------------------
[2025-06-07 09:20:26] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#5): 'DataFrame' object has no attribute 'reshape'
--------------------------------------------------------------------------------
[2025-06-07 09:20:26] [Metadata: {'component': 'train_function', 'action': 'retry'}] Retry limit reached for train_function. Fetching fresh code from LLM.
--------------------------------------------------------------------------------
[2025-06-07 09:20:35] [Metadata: {'component': 'train_function', 'action': 'run'}] Running train_function code:
--------------------------------------------------------------------------------
