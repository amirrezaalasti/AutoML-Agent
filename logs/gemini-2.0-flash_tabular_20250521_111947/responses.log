[2025-05-21 11:19:51] [Metadata: {'component': 'config'}] ```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace import ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    classifier = Categorical("classifier", ["SVM", "KNN", "DecisionTree"], default="SVM")
    cs.add_hyperparameter(classifier)

    # SVM parameters
    svm_kernel = Categorical("svm_kernel", ["linear", "rbf", "poly", "sigmoid"], default="rbf")
    svm_C = Float("svm_C", (1e-5, 10), default=1.0, log=True)
    svm_gamma = Float("svm_gamma", (1e-5, 10), default=0.1, log=True)
    svm_degree = Integer("svm_degree", (2, 5), default=3)

    cs.add_hyperparameters([svm_kernel, svm_C, svm_gamma, svm_degree])

    # KNN parameters
    knn_n_neighbors = Integer("knn_n_neighbors", (1, 20), default=5)
    knn_weights = Categorical("knn_weights", ["uniform", "distance"], default="uniform")
    knn_algorithm = Categorical("knn_algorithm", ["auto", "ball_tree", "kd_tree", "brute"], default="auto")
    knn_leaf_size = Integer("knn_leaf_size", (10, 50), default=30)
    knn_p = Integer("knn_p", (1, 5), default=2)

    cs.add_hyperparameters([knn_n_neighbors, knn_weights, knn_algorithm, knn_leaf_size, knn_p])

    # Decision Tree parameters
    dt_criterion = Categorical("dt_criterion", ["gini", "entropy", "log_loss"], default="gini")
    dt_max_depth = Integer("dt_max_depth", (1, 20), default=5)
    dt_min_samples_split = Integer("dt_min_samples_split", (2, 20), default=2)
    dt_min_samples_leaf = Integer("dt_min_samples_leaf", (1, 10), default=1)

    cs.add_hyperparameters([dt_criterion, dt_max_depth, dt_min_samples_split, dt_min_samples_leaf])

    # Forbidden Clauses
    forbidden_svm = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "SVM"),
        ForbiddenEqualsClause(knn_n_neighbors, 5)
    )

    forbidden_knn = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "KNN"),
        ForbiddenEqualsClause(svm_kernel, "rbf")
    )

    forbidden_dt = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "DecisionTree"),
        ForbiddenEqualsClause(svm_kernel, "rbf")
    )

    cs.add_forbidden_clause(forbidden_svm)
    cs.add_forbidden_clause(forbidden_knn)
    cs.add_forbidden_clause(forbidden_dt)

    return cs
```
--------------------------------------------------------------------------------
[2025-05-21 11:19:51] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace import ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    classifier = Categorical("classifier", ["SVM", "KNN", "DecisionTree"], default="SVM")
    cs.add_hyperparameter(classifier)

    # SVM parameters
    svm_kernel = Categorical("svm_kernel", ["linear", "rbf", "poly", "sigmoid"], default="rbf")
    svm_C = Float("svm_C", (1e-5, 10), default=1.0, log=True)
    svm_gamma = Float("svm_gamma", (1e-5, 10), default=0.1, log=True)
    svm_degree = Integer("svm_degree", (2, 5), default=3)

    cs.add_hyperparameters([svm_kernel, svm_C, svm_gamma, svm_degree])

    # KNN parameters
    knn_n_neighbors = Integer("knn_n_neighbors", (1, 20), default=5)
    knn_weights = Categorical("knn_weights", ["uniform", "distance"], default="uniform")
    knn_algorithm = Categorical("knn_algorithm", ["auto", "ball_tree", "kd_tree", "brute"], default="auto")
    knn_leaf_size = Integer("knn_leaf_size", (10, 50), default=30)
    knn_p = Integer("knn_p", (1, 5), default=2)

    cs.add_hyperparameters([knn_n_neighbors, knn_weights, knn_algorithm, knn_leaf_size, knn_p])

    # Decision Tree parameters
    dt_criterion = Categorical("dt_criterion", ["gini", "entropy", "log_loss"], default="gini")
    dt_max_depth = Integer("dt_max_depth", (1, 20), default=5)
    dt_min_samples_split = Integer("dt_min_samples_split", (2, 20), default=2)
    dt_min_samples_leaf = Integer("dt_min_samples_leaf", (1, 10), default=1)

    cs.add_hyperparameters([dt_criterion, dt_max_depth, dt_min_samples_split, dt_min_samples_leaf])

    # Forbidden Clauses
    forbidden_svm = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "SVM"),
        ForbiddenEqualsClause(knn_n_neighbors, 5)
    )

    forbidden_knn = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "KNN"),
        ForbiddenEqualsClause(svm_kernel, "rbf")
    )

    forbidden_dt = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "DecisionTree"),
        ForbiddenEqualsClause(svm_kernel, "rbf")
    )

    cs.add_forbidden_clause(forbidden_svm)
    cs.add_forbidden_clause(forbidden_knn)
    cs.add_forbidden_clause(forbidden_dt)

    return cs

--------------------------------------------------------------------------------
[2025-05-21 11:19:51] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#1): Given vector violates forbidden clause: (Forbidden: classifier == 'SVM' && Forbidden: knn_n_neighbors == 5)
--------------------------------------------------------------------------------
[2025-05-21 11:19:56] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace import ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    classifier = Categorical("classifier", ["SVM", "KNN", "DecisionTree"], default="SVM")
    cs.add_hyperparameter(classifier)

    # SVM parameters
    svm_kernel = Categorical("svm_kernel", ["linear", "rbf", "poly", "sigmoid"], default="rbf")
    svm_C = Float("svm_C", (1e-5, 10), default=1.0, log=True)
    svm_gamma = Float("svm_gamma", (1e-5, 10), default=0.1, log=True)
    svm_degree = Integer("svm_degree", (2, 5), default=3)

    cs.add_hyperparameters([svm_kernel, svm_C, svm_gamma, svm_degree])

    # KNN parameters
    knn_n_neighbors = Integer("knn_n_neighbors", (1, 20), default=5)
    knn_weights = Categorical("knn_weights", ["uniform", "distance"], default="uniform")
    knn_algorithm = Categorical("knn_algorithm", ["auto", "ball_tree", "kd_tree", "brute"], default="auto")
    knn_leaf_size = Integer("knn_leaf_size", (10, 50), default=30)
    knn_p = Integer("knn_p", (1, 5), default=2)

    cs.add_hyperparameters([knn_n_neighbors, knn_weights, knn_algorithm, knn_leaf_size, knn_p])

    # Decision Tree parameters
    dt_criterion = Categorical("dt_criterion", ["gini", "entropy", "log_loss"], default="gini")
    dt_max_depth = Integer("dt_max_depth", (1, 20), default=5)
    dt_min_samples_split = Integer("dt_min_samples_split", (2, 20), default=2)
    dt_min_samples_leaf = Integer("dt_min_samples_leaf", (1, 10), default=1)

    cs.add_hyperparameters([dt_criterion, dt_max_depth, dt_min_samples_split, dt_min_samples_leaf])

    # Forbidden Clauses
    forbidden_svm = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "SVM"),
        ~ForbiddenEqualsClause(classifier, "SVM")
    )

    forbidden_knn = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "KNN"),
        ~ForbiddenEqualsClause(classifier, "KNN")
    )

    forbidden_dt = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "DecisionTree"),
        ~ForbiddenEqualsClause(classifier, "DecisionTree")
    )

    cs.add_forbidden_clause(forbidden_svm)
    cs.add_forbidden_clause(forbidden_knn)
    cs.add_forbidden_clause(forbidden_dt)

    # Conditionals
    cs.add_condition(EqualsCondition(svm_kernel, classifier, "SVM"))
    cs.add_condition(EqualsCondition(knn_n_neighbors, classifier, "KNN"))
    cs.add_condition(EqualsCondition(dt_criterion, classifier, "DecisionTree"))

    cs.add_condition(EqualsCondition(svm_C, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_gamma, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_degree, classifier, "SVM"))

    cs.add_condition(EqualsCondition(knn_weights, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_algorithm, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_leaf_size, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_p, classifier, "KNN"))

    cs.add_condition(EqualsCondition(dt_max_depth, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_split, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_leaf, classifier, "DecisionTree"))

    return cs
```
--------------------------------------------------------------------------------
[2025-05-21 11:19:56] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace import ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    classifier = Categorical("classifier", ["SVM", "KNN", "DecisionTree"], default="SVM")
    cs.add_hyperparameter(classifier)

    # SVM parameters
    svm_kernel = Categorical("svm_kernel", ["linear", "rbf", "poly", "sigmoid"], default="rbf")
    svm_C = Float("svm_C", (1e-5, 10), default=1.0, log=True)
    svm_gamma = Float("svm_gamma", (1e-5, 10), default=0.1, log=True)
    svm_degree = Integer("svm_degree", (2, 5), default=3)

    cs.add_hyperparameters([svm_kernel, svm_C, svm_gamma, svm_degree])

    # KNN parameters
    knn_n_neighbors = Integer("knn_n_neighbors", (1, 20), default=5)
    knn_weights = Categorical("knn_weights", ["uniform", "distance"], default="uniform")
    knn_algorithm = Categorical("knn_algorithm", ["auto", "ball_tree", "kd_tree", "brute"], default="auto")
    knn_leaf_size = Integer("knn_leaf_size", (10, 50), default=30)
    knn_p = Integer("knn_p", (1, 5), default=2)

    cs.add_hyperparameters([knn_n_neighbors, knn_weights, knn_algorithm, knn_leaf_size, knn_p])

    # Decision Tree parameters
    dt_criterion = Categorical("dt_criterion", ["gini", "entropy", "log_loss"], default="gini")
    dt_max_depth = Integer("dt_max_depth", (1, 20), default=5)
    dt_min_samples_split = Integer("dt_min_samples_split", (2, 20), default=2)
    dt_min_samples_leaf = Integer("dt_min_samples_leaf", (1, 10), default=1)

    cs.add_hyperparameters([dt_criterion, dt_max_depth, dt_min_samples_split, dt_min_samples_leaf])

    # Forbidden Clauses
    forbidden_svm = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "SVM"),
        ~ForbiddenEqualsClause(classifier, "SVM")
    )

    forbidden_knn = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "KNN"),
        ~ForbiddenEqualsClause(classifier, "KNN")
    )

    forbidden_dt = ForbiddenAndConjunction(
        ForbiddenEqualsClause(classifier, "DecisionTree"),
        ~ForbiddenEqualsClause(classifier, "DecisionTree")
    )

    cs.add_forbidden_clause(forbidden_svm)
    cs.add_forbidden_clause(forbidden_knn)
    cs.add_forbidden_clause(forbidden_dt)

    # Conditionals
    cs.add_condition(EqualsCondition(svm_kernel, classifier, "SVM"))
    cs.add_condition(EqualsCondition(knn_n_neighbors, classifier, "KNN"))
    cs.add_condition(EqualsCondition(dt_criterion, classifier, "DecisionTree"))

    cs.add_condition(EqualsCondition(svm_C, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_gamma, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_degree, classifier, "SVM"))

    cs.add_condition(EqualsCondition(knn_weights, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_algorithm, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_leaf_size, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_p, classifier, "KNN"))

    cs.add_condition(EqualsCondition(dt_max_depth, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_split, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_leaf, classifier, "DecisionTree"))

    return cs

--------------------------------------------------------------------------------
[2025-05-21 11:19:56] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#2): bad operand type for unary ~: 'ForbiddenEqualsClause'
--------------------------------------------------------------------------------
[2025-05-21 11:20:01] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace import ForbiddenAndConjunction, ForbiddenEqualsClause, EqualsCondition

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    classifier = Categorical("classifier", ["SVM", "KNN", "DecisionTree"], default="SVM")
    cs.add_hyperparameter(classifier)

    # SVM parameters
    svm_kernel = Categorical("svm_kernel", ["linear", "rbf", "poly", "sigmoid"], default="rbf")
    svm_C = Float("svm_C", (1e-5, 10), default=1.0, log=True)
    svm_gamma = Float("svm_gamma", (1e-5, 10), default=0.1, log=True)
    svm_degree = Integer("svm_degree", (2, 5), default=3)

    cs.add_hyperparameters([svm_kernel, svm_C, svm_gamma, svm_degree])

    # KNN parameters
    knn_n_neighbors = Integer("knn_n_neighbors", (1, 20), default=5)
    knn_weights = Categorical("knn_weights", ["uniform", "distance"], default="uniform")
    knn_algorithm = Categorical("knn_algorithm", ["auto", "ball_tree", "kd_tree", "brute"], default="auto")
    knn_leaf_size = Integer("knn_leaf_size", (10, 50), default=30)
    knn_p = Integer("knn_p", (1, 5), default=2)

    cs.add_hyperparameters([knn_n_neighbors, knn_weights, knn_algorithm, knn_leaf_size, knn_p])

    # Decision Tree parameters
    dt_criterion = Categorical("dt_criterion", ["gini", "entropy", "log_loss"], default="gini")
    dt_max_depth = Integer("dt_max_depth", (1, 20), default=5)
    dt_min_samples_split = Integer("dt_min_samples_split", (2, 20), default=2)
    dt_min_samples_leaf = Integer("dt_min_samples_leaf", (1, 10), default=1)

    cs.add_hyperparameters([dt_criterion, dt_max_depth, dt_min_samples_split, dt_min_samples_leaf])

    # Conditionals
    cs.add_condition(EqualsCondition(svm_kernel, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_C, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_gamma, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_degree, classifier, "SVM"))

    cs.add_condition(EqualsCondition(knn_n_neighbors, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_weights, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_algorithm, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_leaf_size, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_p, classifier, "KNN"))

    cs.add_condition(EqualsCondition(dt_criterion, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_max_depth, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_split, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_leaf, classifier, "DecisionTree"))

    return cs
```
--------------------------------------------------------------------------------
[2025-05-21 11:20:01] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer
from ConfigSpace import ForbiddenAndConjunction, ForbiddenEqualsClause, EqualsCondition

def get_configspace():
    cs = ConfigurationSpace()

    # Define hyperparameters
    classifier = Categorical("classifier", ["SVM", "KNN", "DecisionTree"], default="SVM")
    cs.add_hyperparameter(classifier)

    # SVM parameters
    svm_kernel = Categorical("svm_kernel", ["linear", "rbf", "poly", "sigmoid"], default="rbf")
    svm_C = Float("svm_C", (1e-5, 10), default=1.0, log=True)
    svm_gamma = Float("svm_gamma", (1e-5, 10), default=0.1, log=True)
    svm_degree = Integer("svm_degree", (2, 5), default=3)

    cs.add_hyperparameters([svm_kernel, svm_C, svm_gamma, svm_degree])

    # KNN parameters
    knn_n_neighbors = Integer("knn_n_neighbors", (1, 20), default=5)
    knn_weights = Categorical("knn_weights", ["uniform", "distance"], default="uniform")
    knn_algorithm = Categorical("knn_algorithm", ["auto", "ball_tree", "kd_tree", "brute"], default="auto")
    knn_leaf_size = Integer("knn_leaf_size", (10, 50), default=30)
    knn_p = Integer("knn_p", (1, 5), default=2)

    cs.add_hyperparameters([knn_n_neighbors, knn_weights, knn_algorithm, knn_leaf_size, knn_p])

    # Decision Tree parameters
    dt_criterion = Categorical("dt_criterion", ["gini", "entropy", "log_loss"], default="gini")
    dt_max_depth = Integer("dt_max_depth", (1, 20), default=5)
    dt_min_samples_split = Integer("dt_min_samples_split", (2, 20), default=2)
    dt_min_samples_leaf = Integer("dt_min_samples_leaf", (1, 10), default=1)

    cs.add_hyperparameters([dt_criterion, dt_max_depth, dt_min_samples_split, dt_min_samples_leaf])

    # Conditionals
    cs.add_condition(EqualsCondition(svm_kernel, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_C, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_gamma, classifier, "SVM"))
    cs.add_condition(EqualsCondition(svm_degree, classifier, "SVM"))

    cs.add_condition(EqualsCondition(knn_n_neighbors, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_weights, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_algorithm, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_leaf_size, classifier, "KNN"))
    cs.add_condition(EqualsCondition(knn_p, classifier, "KNN"))

    cs.add_condition(EqualsCondition(dt_criterion, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_max_depth, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_split, classifier, "DecisionTree"))
    cs.add_condition(EqualsCondition(dt_min_samples_leaf, classifier, "DecisionTree"))

    return cs

--------------------------------------------------------------------------------
[2025-05-21 11:20:01] [Metadata: {'component': 'config', 'status': 'success'}] Configuration space generated successfully
--------------------------------------------------------------------------------
[2025-05-21 11:20:02] [Metadata: {'component': 'scenario'}] ```python
from smac import Scenario
from ConfigSpace import ConfigurationSpace

def generate_scenario(cs):
    scenario = Scenario(
        configspace=cs,
        objectives="validation_loss",
        output_directory="./automl_results",
        deterministic=False,
        min_budget=1,
        max_budget=100,
        n_workers=4
    )
    return scenario
```
--------------------------------------------------------------------------------
[2025-05-21 11:20:02] [Metadata: {'component': 'scenario', 'action': 'run'}] from smac import Scenario
from ConfigSpace import ConfigurationSpace

def generate_scenario(cs):
    scenario = Scenario(
        configspace=cs,
        objectives="validation_loss",
        output_directory="./automl_results",
        deterministic=False,
        min_budget=1,
        max_budget=100,
        n_workers=4
    )
    return scenario

--------------------------------------------------------------------------------
[2025-05-21 11:20:02] [Metadata: {'component': 'scenario', 'status': 'success'}] Scenario generated successfully
--------------------------------------------------------------------------------
[2025-05-21 11:20:06] [Metadata: {'component': 'train_function'}] ```python
from typing import Any

from ConfigSpace import Configuration
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import log_loss


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a machine learning model based on the provided configuration and dataset.

    Args:
        cfg (Configuration): A ConfigurationSpace object containing the hyperparameter settings.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Split data into training and validation sets (80/20 split)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    classifier_name = cfg.get("classifier")

    if classifier_name == "SVM":
        # SVM
        kernel = cfg.get("svm_kernel")
        C = cfg.get("svm_C")
        gamma = cfg.get("svm_gamma")
        degree = cfg.get("svm_degree")

        model = SVC(kernel=kernel, C=C, gamma=gamma, degree=degree, probability=True)  # probability=True for log_loss
    elif classifier_name == "KNN":
        # KNN
        n_neighbors = cfg.get("knn_n_neighbors")
        weights = cfg.get("knn_weights")
        algorithm = cfg.get("knn_algorithm")
        leaf_size = cfg.get("knn_leaf_size")
        p = cfg.get("knn_p")

        model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, leaf_size=leaf_size, p=p)
    elif classifier_name == "DecisionTree":
        # Decision Tree
        criterion = cfg.get("dt_criterion")
        max_depth = cfg.get("dt_max_depth")
        min_samples_split = cfg.get("dt_min_samples_split")
        min_samples_leaf = cfg.get("dt_min_samples_leaf")

        model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)
    else:
        raise ValueError(f"Unknown classifier: {classifier_name}")

    losses = []
    for _ in range(10):
        model.fit(X_train, y_train)  # Train on training set for each epoch
        y_pred = model.predict_proba(X_val)  # Predict probabilities on validation set
        loss = log_loss(y_val, y_pred)  # Evaluate using log_loss
        losses.append(loss)

    return np.mean(losses)  # Average loss over 10 epochs
```
--------------------------------------------------------------------------------
[2025-05-21 11:20:06] [Metadata: {'component': 'train_function', 'action': 'run'}] from typing import Any

from ConfigSpace import Configuration
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import log_loss


def train(cfg: Configuration, dataset: Any) -> float:
    """
    Trains a machine learning model based on the provided configuration and dataset.

    Args:
        cfg (Configuration): A ConfigurationSpace object containing the hyperparameter settings.
        dataset (Any): A dictionary containing the training data with keys 'X' (features) and 'y' (labels).

    Returns:
        float: The average training loss over 10 epochs.
    """

    X = dataset['X']
    y = dataset['y']

    # Split data into training and validation sets (80/20 split)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    classifier_name = cfg.get("classifier")

    if classifier_name == "SVM":
        # SVM
        kernel = cfg.get("svm_kernel")
        C = cfg.get("svm_C")
        gamma = cfg.get("svm_gamma")
        degree = cfg.get("svm_degree")

        model = SVC(kernel=kernel, C=C, gamma=gamma, degree=degree, probability=True)  # probability=True for log_loss
    elif classifier_name == "KNN":
        # KNN
        n_neighbors = cfg.get("knn_n_neighbors")
        weights = cfg.get("knn_weights")
        algorithm = cfg.get("knn_algorithm")
        leaf_size = cfg.get("knn_leaf_size")
        p = cfg.get("knn_p")

        model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, leaf_size=leaf_size, p=p)
    elif classifier_name == "DecisionTree":
        # Decision Tree
        criterion = cfg.get("dt_criterion")
        max_depth = cfg.get("dt_max_depth")
        min_samples_split = cfg.get("dt_min_samples_split")
        min_samples_leaf = cfg.get("dt_min_samples_leaf")

        model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)
    else:
        raise ValueError(f"Unknown classifier: {classifier_name}")

    losses = []
    for _ in range(10):
        model.fit(X_train, y_train)  # Train on training set for each epoch
        y_pred = model.predict_proba(X_val)  # Predict probabilities on validation set
        loss = log_loss(y_val, y_pred)  # Evaluate using log_loss
        losses.append(loss)

    return np.mean(losses)  # Average loss over 10 epochs

--------------------------------------------------------------------------------
[2025-05-21 11:20:07] [Metadata: {'component': 'train_function', 'status': 'success', 'loss': 0.06720675870502113}] Training executed successfully, loss: 0.06720675870502113
--------------------------------------------------------------------------------
