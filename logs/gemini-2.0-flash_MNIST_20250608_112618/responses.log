[2025-06-08 11:27:05] [Metadata: {'component': 'config'}] ```python
from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.hyperparameters import UnParametrizedHyperparameter


def get_configspace() -> ConfigurationSpace:
    """
    Creates a configuration space for a CNN model suitable for image classification.
    """
    cs = ConfigurationSpace()

    # Data Augmentation
    data_augmentation = CategoricalHyperparameter(
        "data_augmentation", ["none", "horizontal_flip", "random_rotation"], default_value="none"
    )
    cs.add_hyperparameter(data_augmentation)

    random_rotation_degree = UniformIntegerHyperparameter(
        "random_rotation_degree", lower=1, upper=45, default_value=10
    )
    cs.add_hyperparameter(random_rotation_degree)

    condition_rotation = InCondition(random_rotation_degree, data_augmentation, ["random_rotation"])
    cs.add_condition(condition_rotation)


    # Batch Size
    batch_size = UniformIntegerHyperparameter(
        "batch_size", lower=32, upper=256, default_value=128, q=32,
        docstring="The batch size to use during training."
    )
    cs.add_hyperparameter(batch_size)

    # Epochs
    epochs = UniformIntegerHyperparameter(
        "epochs", lower=5, upper=50, default_value=10, q=5,
        docstring="Number of epochs to train."
    )
    cs.add_hyperparameter(epochs)

    # Learning Rate
    learning_rate = UniformFloatHyperparameter(
        "learning_rate", lower=1e-4, upper=1e-2, default_value=1e-3, log=True,
        docstring="The learning rate for the optimizer."
    )
    cs.add_hyperparameter(learning_rate)

    # Optimizer
    optimizer = CategoricalHyperparameter(
        "optimizer", ["adam", "sgd", "rmsprop"], default_value="adam",
        docstring="The optimizer to use for training."
    )
    cs.add_hyperparameter(optimizer)

    # Adam Specific Parameters
    adam_beta1 = UniformFloatHyperparameter(
        "adam_beta1", lower=0.8, upper=0.999, default_value=0.9,
        docstring="Beta1 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta1)
    adam_beta2 = UniformFloatHyperparameter(
        "adam_beta2", lower=0.9, upper=0.9999, default_value=0.999,
        docstring="Beta2 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta2)

    condition_adam_beta1 = InCondition(child=adam_beta1, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta1)
    condition_adam_beta2 = InCondition(child=adam_beta2, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta2)

    # SGD Specific Parameters
    sgd_momentum = UniformFloatHyperparameter(
        "sgd_momentum", lower=0.0, upper=0.99, default_value=0.0,
        docstring="Momentum for SGD optimizer"
    )
    cs.add_hyperparameter(sgd_momentum)
    condition_sgd_momentum = InCondition(child=sgd_momentum, parent=optimizer, values=['sgd'])
    cs.add_condition(condition_sgd_momentum)

    # RMSprop Specific Parameters
    rmsprop_rho = UniformFloatHyperparameter(
        "rmsprop_rho", lower=0.9, upper=0.999, default_value=0.9,
        docstring="Rho parameter for RMSprop optimizer"
    )
    cs.add_hyperparameter(rmsprop_rho)
    condition_rmsprop_rho = InCondition(child=rmsprop_rho, parent=optimizer, values=['rmsprop'])
    cs.add_condition(condition_rmsprop_rho)


    # Convolutional Layers
    num_conv_layers = UniformIntegerHyperparameter(
        "num_conv_layers", lower=1, upper=5, default_value=3,
        docstring="Number of convolutional layers in the network."
    )
    cs.add_hyperparameter(num_conv_layers)

    # Filters for each convolutional layer
    filters_layer_1 = UniformIntegerHyperparameter(
        "filters_layer_1", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the first convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_1)
    filters_layer_2 = UniformIntegerHyperparameter(
        "filters_layer_2", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the second convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_2)
    filters_layer_3 = UniformIntegerHyperparameter(
        "filters_layer_3", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the third convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_3)
    filters_layer_4 = UniformIntegerHyperparameter(
        "filters_layer_4", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the fourth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_4)
    filters_layer_5 = UniformIntegerHyperparameter(
        "filters_layer_5", lower=32, upper=256, default_value=256, log=True,
        docstring="Number of filters in the fifth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_5)


    # Kernel Size
    kernel_size = UniformIntegerHyperparameter(
        "kernel_size", lower=3, upper=5, default_value=3,
        docstring="Size of the convolutional kernel (e.g., 3 for 3x3)."
    )
    cs.add_hyperparameter(kernel_size)

    # Pooling Type
    pooling_type = CategoricalHyperparameter(
        "pooling_type", ["max", "average"], default_value="max",
        docstring="Type of pooling layer to use."
    )
    cs.add_hyperparameter(pooling_type)

    # Dense Layers
    num_dense_layers = UniformIntegerHyperparameter(
        "num_dense_layers", lower=1, upper=3, default_value=2,
        docstring="Number of dense layers in the network."
    )
    cs.add_hyperparameter(num_dense_layers)


    dense_units_1 = UniformIntegerHyperparameter(
        "dense_units_1", lower=64, upper=512, default_value=256, log=True,
        docstring="Number of units in the first dense layer."
    )
    cs.add_hyperparameter(dense_units_1)

    dense_units_2 = UniformIntegerHyperparameter(
        "dense_units_2", lower=64, upper=512, default_value=128, log=True,
        docstring="Number of units in the second dense layer."
    )
    cs.add_hyperparameter(dense_units_2)

    dense_units_3 = UniformIntegerHyperparameter(
        "dense_units_3", lower=64, upper=512, default_value=64, log=True,
        docstring="Number of units in the third dense layer."
    )
    cs.add_hyperparameter(dense_units_3)


    # Dropout Rate
    dropout_rate = UniformFloatHyperparameter(
        "dropout_rate", lower=0.0, upper=0.5, default_value=0.25,
        docstring="Dropout rate for regularization."
    )
    cs.add_hyperparameter(dropout_rate)


    # Conditions for number of layers
    condition_layer_2 = InCondition(child=filters_layer_2, parent=num_conv_layers, values=[2, 3, 4, 5])
    cs.add_condition(condition_layer_2)

    condition_layer_3 = InCondition(child=filters_layer_3, parent=num_conv_layers, values=[3, 4, 5])
    cs.add_condition(condition_layer_3)

    condition_layer_4 = InCondition(child=filters_layer_4, parent=num_conv_layers, values=[4, 5])
    cs.add_condition(condition_layer_4)

    condition_layer_5 = InCondition(child=filters_layer_5, parent=num_conv_layers, values=[5])
    cs.add_condition(condition_layer_5)

    condition_dense_layer_2 = InCondition(child=dense_units_2, parent=num_dense_layers, values=[2,3])
    cs.add_condition(condition_dense_layer_2)

    condition_dense_layer_3 = InCondition(child=dense_units_3, parent=num_dense_layers, values=[3])
    cs.add_condition(condition_dense_layer_3)


    return cs
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:05] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.hyperparameters import UnParametrizedHyperparameter


def get_configspace() -> ConfigurationSpace:
    """
    Creates a configuration space for a CNN model suitable for image classification.
    """
    cs = ConfigurationSpace()

    # Data Augmentation
    data_augmentation = CategoricalHyperparameter(
        "data_augmentation", ["none", "horizontal_flip", "random_rotation"], default_value="none"
    )
    cs.add_hyperparameter(data_augmentation)

    random_rotation_degree = UniformIntegerHyperparameter(
        "random_rotation_degree", lower=1, upper=45, default_value=10
    )
    cs.add_hyperparameter(random_rotation_degree)

    condition_rotation = InCondition(random_rotation_degree, data_augmentation, ["random_rotation"])
    cs.add_condition(condition_rotation)


    # Batch Size
    batch_size = UniformIntegerHyperparameter(
        "batch_size", lower=32, upper=256, default_value=128, q=32,
        docstring="The batch size to use during training."
    )
    cs.add_hyperparameter(batch_size)

    # Epochs
    epochs = UniformIntegerHyperparameter(
        "epochs", lower=5, upper=50, default_value=10, q=5,
        docstring="Number of epochs to train."
    )
    cs.add_hyperparameter(epochs)

    # Learning Rate
    learning_rate = UniformFloatHyperparameter(
        "learning_rate", lower=1e-4, upper=1e-2, default_value=1e-3, log=True,
        docstring="The learning rate for the optimizer."
    )
    cs.add_hyperparameter(learning_rate)

    # Optimizer
    optimizer = CategoricalHyperparameter(
        "optimizer", ["adam", "sgd", "rmsprop"], default_value="adam",
        docstring="The optimizer to use for training."
    )
    cs.add_hyperparameter(optimizer)

    # Adam Specific Parameters
    adam_beta1 = UniformFloatHyperparameter(
        "adam_beta1", lower=0.8, upper=0.999, default_value=0.9,
        docstring="Beta1 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta1)
    adam_beta2 = UniformFloatHyperparameter(
        "adam_beta2", lower=0.9, upper=0.9999, default_value=0.999,
        docstring="Beta2 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta2)

    condition_adam_beta1 = InCondition(child=adam_beta1, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta1)
    condition_adam_beta2 = InCondition(child=adam_beta2, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta2)

    # SGD Specific Parameters
    sgd_momentum = UniformFloatHyperparameter(
        "sgd_momentum", lower=0.0, upper=0.99, default_value=0.0,
        docstring="Momentum for SGD optimizer"
    )
    cs.add_hyperparameter(sgd_momentum)
    condition_sgd_momentum = InCondition(child=sgd_momentum, parent=optimizer, values=['sgd'])
    cs.add_condition(condition_sgd_momentum)

    # RMSprop Specific Parameters
    rmsprop_rho = UniformFloatHyperparameter(
        "rmsprop_rho", lower=0.9, upper=0.999, default_value=0.9,
        docstring="Rho parameter for RMSprop optimizer"
    )
    cs.add_hyperparameter(rmsprop_rho)
    condition_rmsprop_rho = InCondition(child=rmsprop_rho, parent=optimizer, values=['rmsprop'])
    cs.add_condition(condition_rmsprop_rho)


    # Convolutional Layers
    num_conv_layers = UniformIntegerHyperparameter(
        "num_conv_layers", lower=1, upper=5, default_value=3,
        docstring="Number of convolutional layers in the network."
    )
    cs.add_hyperparameter(num_conv_layers)

    # Filters for each convolutional layer
    filters_layer_1 = UniformIntegerHyperparameter(
        "filters_layer_1", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the first convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_1)
    filters_layer_2 = UniformIntegerHyperparameter(
        "filters_layer_2", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the second convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_2)
    filters_layer_3 = UniformIntegerHyperparameter(
        "filters_layer_3", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the third convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_3)
    filters_layer_4 = UniformIntegerHyperparameter(
        "filters_layer_4", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the fourth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_4)
    filters_layer_5 = UniformIntegerHyperparameter(
        "filters_layer_5", lower=32, upper=256, default_value=256, log=True,
        docstring="Number of filters in the fifth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_5)


    # Kernel Size
    kernel_size = UniformIntegerHyperparameter(
        "kernel_size", lower=3, upper=5, default_value=3,
        docstring="Size of the convolutional kernel (e.g., 3 for 3x3)."
    )
    cs.add_hyperparameter(kernel_size)

    # Pooling Type
    pooling_type = CategoricalHyperparameter(
        "pooling_type", ["max", "average"], default_value="max",
        docstring="Type of pooling layer to use."
    )
    cs.add_hyperparameter(pooling_type)

    # Dense Layers
    num_dense_layers = UniformIntegerHyperparameter(
        "num_dense_layers", lower=1, upper=3, default_value=2,
        docstring="Number of dense layers in the network."
    )
    cs.add_hyperparameter(num_dense_layers)


    dense_units_1 = UniformIntegerHyperparameter(
        "dense_units_1", lower=64, upper=512, default_value=256, log=True,
        docstring="Number of units in the first dense layer."
    )
    cs.add_hyperparameter(dense_units_1)

    dense_units_2 = UniformIntegerHyperparameter(
        "dense_units_2", lower=64, upper=512, default_value=128, log=True,
        docstring="Number of units in the second dense layer."
    )
    cs.add_hyperparameter(dense_units_2)

    dense_units_3 = UniformIntegerHyperparameter(
        "dense_units_3", lower=64, upper=512, default_value=64, log=True,
        docstring="Number of units in the third dense layer."
    )
    cs.add_hyperparameter(dense_units_3)


    # Dropout Rate
    dropout_rate = UniformFloatHyperparameter(
        "dropout_rate", lower=0.0, upper=0.5, default_value=0.25,
        docstring="Dropout rate for regularization."
    )
    cs.add_hyperparameter(dropout_rate)


    # Conditions for number of layers
    condition_layer_2 = InCondition(child=filters_layer_2, parent=num_conv_layers, values=[2, 3, 4, 5])
    cs.add_condition(condition_layer_2)

    condition_layer_3 = InCondition(child=filters_layer_3, parent=num_conv_layers, values=[3, 4, 5])
    cs.add_condition(condition_layer_3)

    condition_layer_4 = InCondition(child=filters_layer_4, parent=num_conv_layers, values=[4, 5])
    cs.add_condition(condition_layer_4)

    condition_layer_5 = InCondition(child=filters_layer_5, parent=num_conv_layers, values=[5])
    cs.add_condition(condition_layer_5)

    condition_dense_layer_2 = InCondition(child=dense_units_2, parent=num_dense_layers, values=[2,3])
    cs.add_condition(condition_dense_layer_2)

    condition_dense_layer_3 = InCondition(child=dense_units_3, parent=num_dense_layers, values=[3])
    cs.add_condition(condition_dense_layer_3)


    return cs

--------------------------------------------------------------------------------
[2025-06-08 11:27:05] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#1): UniformIntegerHyperparameter.__init__() got an unexpected keyword argument 'q'
--------------------------------------------------------------------------------
[2025-06-08 11:27:15] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.hyperparameters import UnParametrizedHyperparameter


def get_configspace() -> ConfigurationSpace:
    """
    Creates a configuration space for a CNN model suitable for image classification.
    """
    cs = ConfigurationSpace()

    # Data Augmentation
    data_augmentation = CategoricalHyperparameter(
        "data_augmentation", ["none", "horizontal_flip", "random_rotation"], default_value="none"
    )
    cs.add_hyperparameter(data_augmentation)

    random_rotation_degree = UniformIntegerHyperparameter(
        "random_rotation_degree", lower=1, upper=45, default_value=10
    )
    cs.add_hyperparameter(random_rotation_degree)

    condition_rotation = InCondition(random_rotation_degree, data_augmentation, ["random_rotation"])
    cs.add_condition(condition_rotation)


    # Batch Size
    batch_size = UniformIntegerHyperparameter(
        "batch_size", lower=32, upper=256, default_value=128
    )
    cs.add_hyperparameter(batch_size)

    # Epochs
    epochs = UniformIntegerHyperparameter(
        "epochs", lower=5, upper=50, default_value=10
    )
    cs.add_hyperparameter(epochs)

    # Learning Rate
    learning_rate = UniformFloatHyperparameter(
        "learning_rate", lower=1e-4, upper=1e-2, default_value=1e-3, log=True,
        docstring="The learning rate for the optimizer."
    )
    cs.add_hyperparameter(learning_rate)

    # Optimizer
    optimizer = CategoricalHyperparameter(
        "optimizer", ["adam", "sgd", "rmsprop"], default_value="adam",
        docstring="The optimizer to use for training."
    )
    cs.add_hyperparameter(optimizer)

    # Adam Specific Parameters
    adam_beta1 = UniformFloatHyperparameter(
        "adam_beta1", lower=0.8, upper=0.999, default_value=0.9,
        docstring="Beta1 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta1)
    adam_beta2 = UniformFloatHyperparameter(
        "adam_beta2", lower=0.9, upper=0.9999, default_value=0.999,
        docstring="Beta2 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta2)

    condition_adam_beta1 = InCondition(child=adam_beta1, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta1)
    condition_adam_beta2 = InCondition(child=adam_beta2, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta2)

    # SGD Specific Parameters
    sgd_momentum = UniformFloatHyperparameter(
        "sgd_momentum", lower=0.0, upper=0.99, default_value=0.0,
        docstring="Momentum for SGD optimizer"
    )
    cs.add_hyperparameter(sgd_momentum)
    condition_sgd_momentum = InCondition(child=sgd_momentum, parent=optimizer, values=['sgd'])
    cs.add_condition(condition_sgd_momentum)

    # RMSprop Specific Parameters
    rmsprop_rho = UniformFloatHyperparameter(
        "rmsprop_rho", lower=0.9, upper=0.999, default_value=0.9,
        docstring="Rho parameter for RMSprop optimizer"
    )
    cs.add_hyperparameter(rmsprop_rho)
    condition_rmsprop_rho = InCondition(child=rmsprop_rho, parent=optimizer, values=['rmsprop'])
    cs.add_condition(condition_rmsprop_rho)


    # Convolutional Layers
    num_conv_layers = UniformIntegerHyperparameter(
        "num_conv_layers", lower=1, upper=5, default_value=3,
        docstring="Number of convolutional layers in the network."
    )
    cs.add_hyperparameter(num_conv_layers)

    # Filters for each convolutional layer
    filters_layer_1 = UniformIntegerHyperparameter(
        "filters_layer_1", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the first convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_1)
    filters_layer_2 = UniformIntegerHyperparameter(
        "filters_layer_2", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the second convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_2)
    filters_layer_3 = UniformIntegerHyperparameter(
        "filters_layer_3", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the third convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_3)
    filters_layer_4 = UniformIntegerHyperparameter(
        "filters_layer_4", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the fourth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_4)
    filters_layer_5 = UniformIntegerHyperparameter(
        "filters_layer_5", lower=32, upper=256, default_value=256, log=True,
        docstring="Number of filters in the fifth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_5)


    # Kernel Size
    kernel_size = UniformIntegerHyperparameter(
        "kernel_size", lower=3, upper=5, default_value=3,
        docstring="Size of the convolutional kernel (e.g., 3 for 3x3)."
    )
    cs.add_hyperparameter(kernel_size)

    # Pooling Type
    pooling_type = CategoricalHyperparameter(
        "pooling_type", ["max", "average"], default_value="max",
        docstring="Type of pooling layer to use."
    )
    cs.add_hyperparameter(pooling_type)

    # Dense Layers
    num_dense_layers = UniformIntegerHyperparameter(
        "num_dense_layers", lower=1, upper=3, default_value=2,
        docstring="Number of dense layers in the network."
    )
    cs.add_hyperparameter(num_dense_layers)


    dense_units_1 = UniformIntegerHyperparameter(
        "dense_units_1", lower=64, upper=512, default_value=256, log=True,
        docstring="Number of units in the first dense layer."
    )
    cs.add_hyperparameter(dense_units_1)

    dense_units_2 = UniformIntegerHyperparameter(
        "dense_units_2", lower=64, upper=512, default_value=128, log=True,
        docstring="Number of units in the second dense layer."
    )
    cs.add_hyperparameter(dense_units_2)

    dense_units_3 = UniformIntegerHyperparameter(
        "dense_units_3", lower=64, upper=512, default_value=64, log=True,
        docstring="Number of units in the third dense layer."
    )
    cs.add_hyperparameter(dense_units_3)


    # Dropout Rate
    dropout_rate = UniformFloatHyperparameter(
        "dropout_rate", lower=0.0, upper=0.5, default_value=0.25,
        docstring="Dropout rate for regularization."
    )
    cs.add_hyperparameter(dropout_rate)


    # Conditions for number of layers
    condition_layer_2 = InCondition(child=filters_layer_2, parent=num_conv_layers, values=[2, 3, 4, 5])
    cs.add_condition(condition_layer_2)

    condition_layer_3 = InCondition(child=filters_layer_3, parent=num_conv_layers, values=[3, 4, 5])
    cs.add_condition(condition_layer_3)

    condition_layer_4 = InCondition(child=filters_layer_4, parent=num_conv_layers, values=[4, 5])
    cs.add_condition(condition_layer_4)

    condition_layer_5 = InCondition(child=filters_layer_5, parent=num_conv_layers, values=[5])
    cs.add_condition(condition_layer_5)

    condition_dense_layer_2 = InCondition(child=dense_units_2, parent=num_dense_layers, values=[2,3])
    cs.add_condition(condition_dense_layer_2)

    condition_dense_layer_3 = InCondition(child=dense_units_3, parent=num_dense_layers, values=[3])
    cs.add_condition(condition_dense_layer_3)


    return cs
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:15] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.hyperparameters import UnParametrizedHyperparameter


def get_configspace() -> ConfigurationSpace:
    """
    Creates a configuration space for a CNN model suitable for image classification.
    """
    cs = ConfigurationSpace()

    # Data Augmentation
    data_augmentation = CategoricalHyperparameter(
        "data_augmentation", ["none", "horizontal_flip", "random_rotation"], default_value="none"
    )
    cs.add_hyperparameter(data_augmentation)

    random_rotation_degree = UniformIntegerHyperparameter(
        "random_rotation_degree", lower=1, upper=45, default_value=10
    )
    cs.add_hyperparameter(random_rotation_degree)

    condition_rotation = InCondition(random_rotation_degree, data_augmentation, ["random_rotation"])
    cs.add_condition(condition_rotation)


    # Batch Size
    batch_size = UniformIntegerHyperparameter(
        "batch_size", lower=32, upper=256, default_value=128
    )
    cs.add_hyperparameter(batch_size)

    # Epochs
    epochs = UniformIntegerHyperparameter(
        "epochs", lower=5, upper=50, default_value=10
    )
    cs.add_hyperparameter(epochs)

    # Learning Rate
    learning_rate = UniformFloatHyperparameter(
        "learning_rate", lower=1e-4, upper=1e-2, default_value=1e-3, log=True,
        docstring="The learning rate for the optimizer."
    )
    cs.add_hyperparameter(learning_rate)

    # Optimizer
    optimizer = CategoricalHyperparameter(
        "optimizer", ["adam", "sgd", "rmsprop"], default_value="adam",
        docstring="The optimizer to use for training."
    )
    cs.add_hyperparameter(optimizer)

    # Adam Specific Parameters
    adam_beta1 = UniformFloatHyperparameter(
        "adam_beta1", lower=0.8, upper=0.999, default_value=0.9,
        docstring="Beta1 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta1)
    adam_beta2 = UniformFloatHyperparameter(
        "adam_beta2", lower=0.9, upper=0.9999, default_value=0.999,
        docstring="Beta2 parameter for Adam optimizer",
    )
    cs.add_hyperparameter(adam_beta2)

    condition_adam_beta1 = InCondition(child=adam_beta1, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta1)
    condition_adam_beta2 = InCondition(child=adam_beta2, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta2)

    # SGD Specific Parameters
    sgd_momentum = UniformFloatHyperparameter(
        "sgd_momentum", lower=0.0, upper=0.99, default_value=0.0,
        docstring="Momentum for SGD optimizer"
    )
    cs.add_hyperparameter(sgd_momentum)
    condition_sgd_momentum = InCondition(child=sgd_momentum, parent=optimizer, values=['sgd'])
    cs.add_condition(condition_sgd_momentum)

    # RMSprop Specific Parameters
    rmsprop_rho = UniformFloatHyperparameter(
        "rmsprop_rho", lower=0.9, upper=0.999, default_value=0.9,
        docstring="Rho parameter for RMSprop optimizer"
    )
    cs.add_hyperparameter(rmsprop_rho)
    condition_rmsprop_rho = InCondition(child=rmsprop_rho, parent=optimizer, values=['rmsprop'])
    cs.add_condition(condition_rmsprop_rho)


    # Convolutional Layers
    num_conv_layers = UniformIntegerHyperparameter(
        "num_conv_layers", lower=1, upper=5, default_value=3,
        docstring="Number of convolutional layers in the network."
    )
    cs.add_hyperparameter(num_conv_layers)

    # Filters for each convolutional layer
    filters_layer_1 = UniformIntegerHyperparameter(
        "filters_layer_1", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the first convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_1)
    filters_layer_2 = UniformIntegerHyperparameter(
        "filters_layer_2", lower=32, upper=256, default_value=64, log=True,
        docstring="Number of filters in the second convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_2)
    filters_layer_3 = UniformIntegerHyperparameter(
        "filters_layer_3", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the third convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_3)
    filters_layer_4 = UniformIntegerHyperparameter(
        "filters_layer_4", lower=32, upper=256, default_value=128, log=True,
        docstring="Number of filters in the fourth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_4)
    filters_layer_5 = UniformIntegerHyperparameter(
        "filters_layer_5", lower=32, upper=256, default_value=256, log=True,
        docstring="Number of filters in the fifth convolutional layer."
    )
    cs.add_hyperparameter(filters_layer_5)


    # Kernel Size
    kernel_size = UniformIntegerHyperparameter(
        "kernel_size", lower=3, upper=5, default_value=3,
        docstring="Size of the convolutional kernel (e.g., 3 for 3x3)."
    )
    cs.add_hyperparameter(kernel_size)

    # Pooling Type
    pooling_type = CategoricalHyperparameter(
        "pooling_type", ["max", "average"], default_value="max",
        docstring="Type of pooling layer to use."
    )
    cs.add_hyperparameter(pooling_type)

    # Dense Layers
    num_dense_layers = UniformIntegerHyperparameter(
        "num_dense_layers", lower=1, upper=3, default_value=2,
        docstring="Number of dense layers in the network."
    )
    cs.add_hyperparameter(num_dense_layers)


    dense_units_1 = UniformIntegerHyperparameter(
        "dense_units_1", lower=64, upper=512, default_value=256, log=True,
        docstring="Number of units in the first dense layer."
    )
    cs.add_hyperparameter(dense_units_1)

    dense_units_2 = UniformIntegerHyperparameter(
        "dense_units_2", lower=64, upper=512, default_value=128, log=True,
        docstring="Number of units in the second dense layer."
    )
    cs.add_hyperparameter(dense_units_2)

    dense_units_3 = UniformIntegerHyperparameter(
        "dense_units_3", lower=64, upper=512, default_value=64, log=True,
        docstring="Number of units in the third dense layer."
    )
    cs.add_hyperparameter(dense_units_3)


    # Dropout Rate
    dropout_rate = UniformFloatHyperparameter(
        "dropout_rate", lower=0.0, upper=0.5, default_value=0.25,
        docstring="Dropout rate for regularization."
    )
    cs.add_hyperparameter(dropout_rate)


    # Conditions for number of layers
    condition_layer_2 = InCondition(child=filters_layer_2, parent=num_conv_layers, values=[2, 3, 4, 5])
    cs.add_condition(condition_layer_2)

    condition_layer_3 = InCondition(child=filters_layer_3, parent=num_conv_layers, values=[3, 4, 5])
    cs.add_condition(condition_layer_3)

    condition_layer_4 = InCondition(child=filters_layer_4, parent=num_conv_layers, values=[4, 5])
    cs.add_condition(condition_layer_4)

    condition_layer_5 = InCondition(child=filters_layer_5, parent=num_conv_layers, values=[5])
    cs.add_condition(condition_layer_5)

    condition_dense_layer_2 = InCondition(child=dense_units_2, parent=num_dense_layers, values=[2,3])
    cs.add_condition(condition_dense_layer_2)

    condition_dense_layer_3 = InCondition(child=dense_units_3, parent=num_dense_layers, values=[3])
    cs.add_condition(condition_dense_layer_3)


    return cs

--------------------------------------------------------------------------------
[2025-06-08 11:27:15] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#2): UniformFloatHyperparameter.__init__() got an unexpected keyword argument 'docstring'
--------------------------------------------------------------------------------
[2025-06-08 11:27:25] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.hyperparameters import UnParametrizedHyperparameter


def get_configspace() -> ConfigurationSpace:
    """
    Creates a configuration space for a CNN model suitable for image classification.
    """
    cs = ConfigurationSpace()

    # Data Augmentation
    data_augmentation = CategoricalHyperparameter(
        "data_augmentation", ["none", "horizontal_flip", "random_rotation"], default_value="none"
    )
    cs.add_hyperparameter(data_augmentation)

    random_rotation_degree = UniformIntegerHyperparameter(
        "random_rotation_degree", lower=1, upper=45, default_value=10
    )
    cs.add_hyperparameter(random_rotation_degree)

    condition_rotation = InCondition(random_rotation_degree, data_augmentation, ["random_rotation"])
    cs.add_condition(condition_rotation)


    # Batch Size
    batch_size = UniformIntegerHyperparameter(
        "batch_size", lower=32, upper=256, default_value=128
    )
    cs.add_hyperparameter(batch_size)

    # Epochs
    epochs = UniformIntegerHyperparameter(
        "epochs", lower=5, upper=50, default_value=10
    )
    cs.add_hyperparameter(epochs)

    # Learning Rate
    learning_rate = UniformFloatHyperparameter(
        "learning_rate", lower=1e-4, upper=1e-2, default_value=1e-3, log=True
    )
    cs.add_hyperparameter(learning_rate)

    # Optimizer
    optimizer = CategoricalHyperparameter(
        "optimizer", ["adam", "sgd", "rmsprop"], default_value="adam"
    )
    cs.add_hyperparameter(optimizer)

    # Adam Specific Parameters
    adam_beta1 = UniformFloatHyperparameter(
        "adam_beta1", lower=0.8, upper=0.999, default_value=0.9
    )
    cs.add_hyperparameter(adam_beta1)
    adam_beta2 = UniformFloatHyperparameter(
        "adam_beta2", lower=0.9, upper=0.9999, default_value=0.999
    )
    cs.add_hyperparameter(adam_beta2)

    condition_adam_beta1 = InCondition(child=adam_beta1, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta1)
    condition_adam_beta2 = InCondition(child=adam_beta2, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta2)

    # SGD Specific Parameters
    sgd_momentum = UniformFloatHyperparameter(
        "sgd_momentum", lower=0.0, upper=0.99, default_value=0.0
    )
    cs.add_hyperparameter(sgd_momentum)
    condition_sgd_momentum = InCondition(child=sgd_momentum, parent=optimizer, values=['sgd'])
    cs.add_condition(condition_sgd_momentum)

    # RMSprop Specific Parameters
    rmsprop_rho = UniformFloatHyperparameter(
        "rmsprop_rho", lower=0.9, upper=0.999, default_value=0.9
    )
    cs.add_hyperparameter(rmsprop_rho)
    condition_rmsprop_rho = InCondition(child=rmsprop_rho, parent=optimizer, values=['rmsprop'])
    cs.add_condition(condition_rmsprop_rho)


    # Convolutional Layers
    num_conv_layers = UniformIntegerHyperparameter(
        "num_conv_layers", lower=1, upper=5, default_value=3
    )
    cs.add_hyperparameter(num_conv_layers)

    # Filters for each convolutional layer
    filters_layer_1 = UniformIntegerHyperparameter(
        "filters_layer_1", lower=32, upper=256, default_value=64, log=True
    )
    cs.add_hyperparameter(filters_layer_1)
    filters_layer_2 = UniformIntegerHyperparameter(
        "filters_layer_2", lower=32, upper=256, default_value=64, log=True
    )
    cs.add_hyperparameter(filters_layer_2)
    filters_layer_3 = UniformIntegerHyperparameter(
        "filters_layer_3", lower=32, upper=256, default_value=128, log=True
    )
    cs.add_hyperparameter(filters_layer_3)
    filters_layer_4 = UniformIntegerHyperparameter(
        "filters_layer_4", lower=32, upper=256, default_value=128, log=True
    )
    cs.add_hyperparameter(filters_layer_4)
    filters_layer_5 = UniformIntegerHyperparameter(
        "filters_layer_5", lower=32, upper=256, default_value=256, log=True
    )
    cs.add_hyperparameter(filters_layer_5)


    # Kernel Size
    kernel_size = UniformIntegerHyperparameter(
        "kernel_size", lower=3, upper=5, default_value=3
    )
    cs.add_hyperparameter(kernel_size)

    # Pooling Type
    pooling_type = CategoricalHyperparameter(
        "pooling_type", ["max", "average"], default_value="max"
    )
    cs.add_hyperparameter(pooling_type)

    # Dense Layers
    num_dense_layers = UniformIntegerHyperparameter(
        "num_dense_layers", lower=1, upper=3, default_value=2
    )
    cs.add_hyperparameter(num_dense_layers)


    dense_units_1 = UniformIntegerHyperparameter(
        "dense_units_1", lower=64, upper=512, default_value=256, log=True
    )
    cs.add_hyperparameter(dense_units_1)

    dense_units_2 = UniformIntegerHyperparameter(
        "dense_units_2", lower=64, upper=512, default_value=128, log=True
    )
    cs.add_hyperparameter(dense_units_2)

    dense_units_3 = UniformIntegerHyperparameter(
        "dense_units_3", lower=64, upper=512, default_value=64, log=True
    )
    cs.add_hyperparameter(dense_units_3)


    # Dropout Rate
    dropout_rate = UniformFloatHyperparameter(
        "dropout_rate", lower=0.0, upper=0.5, default_value=0.25
    )
    cs.add_hyperparameter(dropout_rate)


    # Conditions for number of layers
    condition_layer_2 = InCondition(child=filters_layer_2, parent=num_conv_layers, values=[2, 3, 4, 5])
    cs.add_condition(condition_layer_2)

    condition_layer_3 = InCondition(child=filters_layer_3, parent=num_conv_layers, values=[3, 4, 5])
    cs.add_condition(condition_layer_3)

    condition_layer_4 = InCondition(child=filters_layer_4, parent=num_conv_layers, values=[4, 5])
    cs.add_condition(condition_layer_4)

    condition_layer_5 = InCondition(child=filters_layer_5, parent=num_conv_layers, values=[5])
    cs.add_condition(condition_layer_5)

    condition_dense_layer_2 = InCondition(child=dense_units_2, parent=num_dense_layers, values=[2,3])
    cs.add_condition(condition_dense_layer_2)

    condition_dense_layer_3 = InCondition(child=dense_units_3, parent=num_dense_layers, values=[3])
    cs.add_condition(condition_dense_layer_3)


    return cs
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:25] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.hyperparameters import UnParametrizedHyperparameter


def get_configspace() -> ConfigurationSpace:
    """
    Creates a configuration space for a CNN model suitable for image classification.
    """
    cs = ConfigurationSpace()

    # Data Augmentation
    data_augmentation = CategoricalHyperparameter(
        "data_augmentation", ["none", "horizontal_flip", "random_rotation"], default_value="none"
    )
    cs.add_hyperparameter(data_augmentation)

    random_rotation_degree = UniformIntegerHyperparameter(
        "random_rotation_degree", lower=1, upper=45, default_value=10
    )
    cs.add_hyperparameter(random_rotation_degree)

    condition_rotation = InCondition(random_rotation_degree, data_augmentation, ["random_rotation"])
    cs.add_condition(condition_rotation)


    # Batch Size
    batch_size = UniformIntegerHyperparameter(
        "batch_size", lower=32, upper=256, default_value=128
    )
    cs.add_hyperparameter(batch_size)

    # Epochs
    epochs = UniformIntegerHyperparameter(
        "epochs", lower=5, upper=50, default_value=10
    )
    cs.add_hyperparameter(epochs)

    # Learning Rate
    learning_rate = UniformFloatHyperparameter(
        "learning_rate", lower=1e-4, upper=1e-2, default_value=1e-3, log=True
    )
    cs.add_hyperparameter(learning_rate)

    # Optimizer
    optimizer = CategoricalHyperparameter(
        "optimizer", ["adam", "sgd", "rmsprop"], default_value="adam"
    )
    cs.add_hyperparameter(optimizer)

    # Adam Specific Parameters
    adam_beta1 = UniformFloatHyperparameter(
        "adam_beta1", lower=0.8, upper=0.999, default_value=0.9
    )
    cs.add_hyperparameter(adam_beta1)
    adam_beta2 = UniformFloatHyperparameter(
        "adam_beta2", lower=0.9, upper=0.9999, default_value=0.999
    )
    cs.add_hyperparameter(adam_beta2)

    condition_adam_beta1 = InCondition(child=adam_beta1, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta1)
    condition_adam_beta2 = InCondition(child=adam_beta2, parent=optimizer, values=['adam'])
    cs.add_condition(condition_adam_beta2)

    # SGD Specific Parameters
    sgd_momentum = UniformFloatHyperparameter(
        "sgd_momentum", lower=0.0, upper=0.99, default_value=0.0
    )
    cs.add_hyperparameter(sgd_momentum)
    condition_sgd_momentum = InCondition(child=sgd_momentum, parent=optimizer, values=['sgd'])
    cs.add_condition(condition_sgd_momentum)

    # RMSprop Specific Parameters
    rmsprop_rho = UniformFloatHyperparameter(
        "rmsprop_rho", lower=0.9, upper=0.999, default_value=0.9
    )
    cs.add_hyperparameter(rmsprop_rho)
    condition_rmsprop_rho = InCondition(child=rmsprop_rho, parent=optimizer, values=['rmsprop'])
    cs.add_condition(condition_rmsprop_rho)


    # Convolutional Layers
    num_conv_layers = UniformIntegerHyperparameter(
        "num_conv_layers", lower=1, upper=5, default_value=3
    )
    cs.add_hyperparameter(num_conv_layers)

    # Filters for each convolutional layer
    filters_layer_1 = UniformIntegerHyperparameter(
        "filters_layer_1", lower=32, upper=256, default_value=64, log=True
    )
    cs.add_hyperparameter(filters_layer_1)
    filters_layer_2 = UniformIntegerHyperparameter(
        "filters_layer_2", lower=32, upper=256, default_value=64, log=True
    )
    cs.add_hyperparameter(filters_layer_2)
    filters_layer_3 = UniformIntegerHyperparameter(
        "filters_layer_3", lower=32, upper=256, default_value=128, log=True
    )
    cs.add_hyperparameter(filters_layer_3)
    filters_layer_4 = UniformIntegerHyperparameter(
        "filters_layer_4", lower=32, upper=256, default_value=128, log=True
    )
    cs.add_hyperparameter(filters_layer_4)
    filters_layer_5 = UniformIntegerHyperparameter(
        "filters_layer_5", lower=32, upper=256, default_value=256, log=True
    )
    cs.add_hyperparameter(filters_layer_5)


    # Kernel Size
    kernel_size = UniformIntegerHyperparameter(
        "kernel_size", lower=3, upper=5, default_value=3
    )
    cs.add_hyperparameter(kernel_size)

    # Pooling Type
    pooling_type = CategoricalHyperparameter(
        "pooling_type", ["max", "average"], default_value="max"
    )
    cs.add_hyperparameter(pooling_type)

    # Dense Layers
    num_dense_layers = UniformIntegerHyperparameter(
        "num_dense_layers", lower=1, upper=3, default_value=2
    )
    cs.add_hyperparameter(num_dense_layers)


    dense_units_1 = UniformIntegerHyperparameter(
        "dense_units_1", lower=64, upper=512, default_value=256, log=True
    )
    cs.add_hyperparameter(dense_units_1)

    dense_units_2 = UniformIntegerHyperparameter(
        "dense_units_2", lower=64, upper=512, default_value=128, log=True
    )
    cs.add_hyperparameter(dense_units_2)

    dense_units_3 = UniformIntegerHyperparameter(
        "dense_units_3", lower=64, upper=512, default_value=64, log=True
    )
    cs.add_hyperparameter(dense_units_3)


    # Dropout Rate
    dropout_rate = UniformFloatHyperparameter(
        "dropout_rate", lower=0.0, upper=0.5, default_value=0.25
    )
    cs.add_hyperparameter(dropout_rate)


    # Conditions for number of layers
    condition_layer_2 = InCondition(child=filters_layer_2, parent=num_conv_layers, values=[2, 3, 4, 5])
    cs.add_condition(condition_layer_2)

    condition_layer_3 = InCondition(child=filters_layer_3, parent=num_conv_layers, values=[3, 4, 5])
    cs.add_condition(condition_layer_3)

    condition_layer_4 = InCondition(child=filters_layer_4, parent=num_conv_layers, values=[4, 5])
    cs.add_condition(condition_layer_4)

    condition_layer_5 = InCondition(child=filters_layer_5, parent=num_conv_layers, values=[5])
    cs.add_condition(condition_layer_5)

    condition_dense_layer_2 = InCondition(child=dense_units_2, parent=num_dense_layers, values=[2,3])
    cs.add_condition(condition_dense_layer_2)

    condition_dense_layer_3 = InCondition(child=dense_units_3, parent=num_dense_layers, values=[3])
    cs.add_condition(condition_dense_layer_3)


    return cs

--------------------------------------------------------------------------------
[2025-06-08 11:27:25] [Metadata: {'component': 'config', 'status': 'success'}] Configuration space generated successfully
--------------------------------------------------------------------------------
[2025-06-08 11:27:28] [Metadata: {'component': 'scenario'}] ```python
import os
from smac import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour
    cpu_limit = 3600 # 1 hour. Should not exceed walltime.

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        cpu_limit=cpu_limit,
        memory_limit=memory_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers # Number of parallel workers
        # trial_resource_limits = # Removed because it's redundant with memory and time limits.
    )

    return scenario
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:28] [Metadata: {'component': 'scenario', 'action': 'run'}] import os
from smac import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour
    cpu_limit = 3600 # 1 hour. Should not exceed walltime.

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        cpu_limit=cpu_limit,
        memory_limit=memory_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers # Number of parallel workers
        # trial_resource_limits = # Removed because it's redundant with memory and time limits.
    )

    return scenario

--------------------------------------------------------------------------------
[2025-06-08 11:27:28] [Metadata: {'error_type': 'SCENARIO_ERROR'}] [SCENARIO_ERROR] Error in scenario (#1): Scenario.__init__() got an unexpected keyword argument 'cpu_limit'
--------------------------------------------------------------------------------
[2025-06-08 11:27:31] [Metadata: {'component': 'scenario', 'action': 'fix'}] ```python
import os
from smac import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        memory_limit=memory_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers # Number of parallel workers
        # trial_resource_limits = # Removed because it's redundant with memory and time limits.
    )

    return scenario
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:31] [Metadata: {'component': 'scenario', 'action': 'run'}] import os
from smac import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        memory_limit=memory_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers # Number of parallel workers
        # trial_resource_limits = # Removed because it's redundant with memory and time limits.
    )

    return scenario

--------------------------------------------------------------------------------
[2025-06-08 11:27:31] [Metadata: {'error_type': 'SCENARIO_ERROR'}] [SCENARIO_ERROR] Error in scenario (#2): Scenario.__init__() got an unexpected keyword argument 'memory_limit'
--------------------------------------------------------------------------------
[2025-06-08 11:27:34] [Metadata: {'component': 'scenario', 'action': 'fix'}] ```python
import os
from smac import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers
        # trial_resource_limits = # Removed because it's redundant with memory and time limits.
    )

    scenario.memory_limit = memory_limit
    return scenario
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:34] [Metadata: {'component': 'scenario', 'action': 'run'}] import os
from smac import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers
        # trial_resource_limits = # Removed because it's redundant with memory and time limits.
    )

    scenario.memory_limit = memory_limit
    return scenario

--------------------------------------------------------------------------------
[2025-06-08 11:27:34] [Metadata: {'error_type': 'SCENARIO_ERROR'}] [SCENARIO_ERROR] Error in scenario (#3): cannot assign to field 'memory_limit'
--------------------------------------------------------------------------------
[2025-06-08 11:27:37] [Metadata: {'component': 'scenario', 'action': 'fix'}] ```python
import os
from smac.scenario import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers,
        memory_limit=memory_limit
    )

    return scenario
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:37] [Metadata: {'component': 'scenario', 'action': 'run'}] import os
from smac.scenario import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    # Number of trials (function evaluations)
    n_trials = 500 # Adjust based on available resources and complexity

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers,
        memory_limit=memory_limit
    )

    return scenario

--------------------------------------------------------------------------------
[2025-06-08 11:27:37] [Metadata: {'error_type': 'SCENARIO_ERROR'}] [SCENARIO_ERROR] Error in scenario (#4): Scenario.__init__() got an unexpected keyword argument 'memory_limit'
--------------------------------------------------------------------------------
[2025-06-08 11:27:40] [Metadata: {'component': 'scenario', 'action': 'fix'}] ```python
import os
from smac.scenario import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers,
        #memory_limit=memory_limit,  # Removed invalid argument for Scenario
    )

    scenario.memory_limit = memory_limit # Setting memory limit after initialization


    return scenario
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:40] [Metadata: {'component': 'scenario', 'action': 'run'}] import os
from smac.scenario import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers,
        #memory_limit=memory_limit,  # Removed invalid argument for Scenario
    )

    scenario.memory_limit = memory_limit # Setting memory limit after initialization


    return scenario

--------------------------------------------------------------------------------
[2025-06-08 11:27:40] [Metadata: {'error_type': 'SCENARIO_ERROR'}] [SCENARIO_ERROR] Error in scenario (#5): name 'n_trials' is not defined
--------------------------------------------------------------------------------
[2025-06-08 11:27:42] [Metadata: {'component': 'scenario', 'action': 'fix'}] ```python
import os
from smac.scenario import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    n_trials = 10 # Define n_trials, the number of trials

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers,
    )

    #scenario.memory_limit = memory_limit # Setting memory limit after initialization - invalid

    return scenario
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:42] [Metadata: {'component': 'scenario', 'action': 'run'}] import os
from smac.scenario import Scenario
from ConfigSpace import ConfigurationSpace


def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    """
    Generates a SMAC scenario for hyperparameter optimization, specifically tailored for image datasets.

    Args:
        cs (ConfigurationSpace): The configuration space to be optimized.

    Returns:
        Scenario: A configured SMAC Scenario object.
    """

    # Define the output directory for SMAC results
    output_dir = "./smac_output"
    os.makedirs(output_dir, exist_ok=True)

    # Determine the number of available cores.  Using os.cpu_count() may not be appropriate
    # in all environments (e.g., Docker containers).  Consider using a resource-aware method.
    n_workers = os.cpu_count() or 1 # Default to 1 worker if os.cpu_count() is None

    # Define budget settings: min_budget, max_budget
    # These depend heavily on the complexity of the model and the dataset size.
    # For an image dataset with 10 classes and ~60k examples,
    # these values need careful consideration.
    # Example: budget is based on the number of epochs/iterations
    min_budget = 3  # Minimum number of epochs/iterations
    max_budget = 27  # Maximum number of epochs/iterations

    # Set walltime and CPU time limits (in seconds)
    walltime_limit = 3600  # 1 hour

    # Define resource limits for each trial
    memory_limit = 4096  # 4GB memory limit (in MB)

    n_trials = 10 # Define n_trials, the number of trials

    scenario = Scenario(
        configspace=cs,
        name="image_dataset_optimization",
        output_directory=output_dir,
        deterministic=False,  # Enable for reproducibility during testing
        # but disable for better generalization during actual optimization
        n_trials=n_trials,
        walltime_limit=walltime_limit,
        min_budget=min_budget,
        max_budget=max_budget,
        n_workers=n_workers,
    )

    #scenario.memory_limit = memory_limit # Setting memory limit after initialization - invalid

    return scenario

--------------------------------------------------------------------------------
[2025-06-08 11:27:42] [Metadata: {'component': 'scenario', 'status': 'success'}] Scenario generated successfully
--------------------------------------------------------------------------------
[2025-06-08 11:27:56] [Metadata: {'component': 'train_function'}] ```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    n_features = X.shape[1] if len(X.shape) == 2 else X.shape[1] * X.shape[2] if len(X.shape) == 3 else X.shape[1] * X.shape[2] * X.shape[3]
    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            raise ValueError("Input features are not a square image.")
        X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    model = CNN(num_classes)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)
```
--------------------------------------------------------------------------------
[2025-06-08 11:27:56] [Metadata: {'component': 'train_function', 'action': 'run'}] import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    n_features = X.shape[1] if len(X.shape) == 2 else X.shape[1] * X.shape[2] if len(X.shape) == 3 else X.shape[1] * X.shape[2] * X.shape[3]
    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            raise ValueError("Input features are not a square image.")
        X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    model = CNN(num_classes)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)

--------------------------------------------------------------------------------
[2025-06-08 11:27:56] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#1): 'DataFrame' object has no attribute 'reshape'
--------------------------------------------------------------------------------
[2025-06-08 11:28:09] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    if isinstance(X, np.ndarray):
        if len(X.shape) == 2:
            n_features = X.shape[1]
        elif len(X.shape) == 3:
            n_features = X.shape[1] * X.shape[2]
        elif len(X.shape) == 4:
            n_features = X.shape[1] * X.shape[2] * X.shape[3]
        else:
            raise ValueError("Input data must be 2D, 3D, or 4D array.")
    else:
        raise TypeError("Input data X must be a numpy array.")

    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            raise ValueError("Input features are not a square image.")
        X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    model = CNN(num_classes)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {{optimizer_name}}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)
```
--------------------------------------------------------------------------------
[2025-06-08 11:28:09] [Metadata: {'component': 'train_function', 'action': 'run'}] import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    if isinstance(X, np.ndarray):
        if len(X.shape) == 2:
            n_features = X.shape[1]
        elif len(X.shape) == 3:
            n_features = X.shape[1] * X.shape[2]
        elif len(X.shape) == 4:
            n_features = X.shape[1] * X.shape[2] * X.shape[3]
        else:
            raise ValueError("Input data must be 2D, 3D, or 4D array.")
    else:
        raise TypeError("Input data X must be a numpy array.")

    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            raise ValueError("Input features are not a square image.")
        X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    model = CNN(num_classes)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {{optimizer_name}}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)

--------------------------------------------------------------------------------
[2025-06-08 11:28:09] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#2): Input data X must be a numpy array.
--------------------------------------------------------------------------------
[2025-06-08 11:28:22] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math
import pandas as pd

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Check if X is a Pandas DataFrame and convert to NumPy array
    if isinstance(X, pd.DataFrame):
        X = X.values
    
    # Check if y is a Pandas DataFrame or Series and convert to NumPy array
    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):
        y = y.values

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    if isinstance(X, np.ndarray):
        if len(X.shape) == 2:
            n_features = X.shape[1]
        elif len(X.shape) == 3:
            n_features = X.shape[1] * X.shape[2]
        elif len(X.shape) == 4:
            n_features = X.shape[1] * X.shape[2] * X.shape[3]
        else:
            raise ValueError("Input data must be 2D, 3D, or 4D array.")
    else:
        raise TypeError("Input data X must be a numpy array.")

    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            raise ValueError("Input features are not a square image.")
        X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    model = CNN(num_classes)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)
```
--------------------------------------------------------------------------------
[2025-06-08 11:28:22] [Metadata: {'component': 'train_function', 'action': 'run'}] import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math
import pandas as pd

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Check if X is a Pandas DataFrame and convert to NumPy array
    if isinstance(X, pd.DataFrame):
        X = X.values
    
    # Check if y is a Pandas DataFrame or Series and convert to NumPy array
    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):
        y = y.values

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    if isinstance(X, np.ndarray):
        if len(X.shape) == 2:
            n_features = X.shape[1]
        elif len(X.shape) == 3:
            n_features = X.shape[1] * X.shape[2]
        elif len(X.shape) == 4:
            n_features = X.shape[1] * X.shape[2] * X.shape[3]
        else:
            raise ValueError("Input data must be 2D, 3D, or 4D array.")
    else:
        raise TypeError("Input data X must be a numpy array.")

    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            raise ValueError("Input features are not a square image.")
        X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    model = CNN(num_classes)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)

--------------------------------------------------------------------------------
[2025-06-08 11:28:23] [Metadata: {'error_type': 'TRAIN_FUNCTION_ERROR'}] [TRAIN_FUNCTION_ERROR] Error in train_function (#3): Given input size: (53x1x1). Calculated output size: (53x0x0). Output size is too small
--------------------------------------------------------------------------------
[2025-06-08 11:28:37] [Metadata: {'component': 'train_function', 'action': 'fix'}] ```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math
import pandas as pd

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Check if X is a Pandas DataFrame and convert to NumPy array
    if isinstance(X, pd.DataFrame):
        X = X.values
    
    # Check if y is a Pandas DataFrame or Series and convert to NumPy array
    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):
        y = y.values

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    if isinstance(X, np.ndarray):
        if len(X.shape) == 2:
            n_features = X.shape[1]
        elif len(X.shape) == 3:
            n_features = X.shape[1] * X.shape[2]
        elif len(X.shape) == 4:
            n_features = X.shape[1] * X.shape[2] * X.shape[3]
        else:
            raise ValueError("Input data must be 2D, 3D, or 4D array.")
    else:
        raise TypeError("Input data X must be a numpy array.")

    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            # Attempt to reshape to a rectangular image if not square
            aspect_ratio = X.shape[1]
            width = int(math.sqrt(aspect_ratio))
            while aspect_ratio % width != 0:
                width -= 1
            height = aspect_ratio // width
            X = X.reshape(n_samples, 1, height, width)

        else:
            X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format
    elif len(X.shape) == 4:
        # Already in NCHW format, do nothing
        pass
    else:
        raise ValueError("Input data must be 2D, 3D, or 4D array.")

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes, height, width):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    # Determine height and width based on the reshaped data
    if len(X.shape) == 4:
        height, width = X.shape[2], X.shape[3]
    else:
        raise ValueError("X tensor should have 4 dimensions after reshaping")
    model = CNN(num_classes, height, width)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {{optimizer_name}}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)
```
--------------------------------------------------------------------------------
[2025-06-08 11:28:37] [Metadata: {'component': 'train_function', 'action': 'run'}] import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from ConfigSpace import Configuration
from typing import Any
import math
import pandas as pd

def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a CNN model on the given dataset using the provided configuration.
    """
    torch.manual_seed(seed)
    np.random.seed(seed)

    # Extract data and labels
    X, y = dataset['X'], dataset['y']

    # Check if X is a Pandas DataFrame and convert to NumPy array
    if isinstance(X, pd.DataFrame):
        X = X.values
    
    # Check if y is a Pandas DataFrame or Series and convert to NumPy array
    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):
        y = y.values

    # Determine input shape and handle data format
    n_samples = X.shape[0]
    if isinstance(X, np.ndarray):
        if len(X.shape) == 2:
            n_features = X.shape[1]
        elif len(X.shape) == 3:
            n_features = X.shape[1] * X.shape[2]
        elif len(X.shape) == 4:
            n_features = X.shape[1] * X.shape[2] * X.shape[3]
        else:
            raise ValueError("Input data must be 2D, 3D, or 4D array.")
    else:
        raise TypeError("Input data X must be a numpy array.")

    num_classes = len(torch.unique(torch.tensor(y)))

    if len(X.shape) == 2:
        # Flattened input
        height = width = int(math.sqrt(n_features))
        if height * height != n_features:
            # Attempt to reshape to a rectangular image if not square
            aspect_ratio = X.shape[1]
            width = int(math.sqrt(aspect_ratio))
            while aspect_ratio % width != 0:
                width -= 1
            height = aspect_ratio // width
            X = X.reshape(n_samples, 1, height, width)

        else:
            X = X.reshape(n_samples, 1, height, width)  # NCHW format
    elif len(X.shape) == 3:
        # 3D input (N, H, W)
        X = X.reshape(n_samples, 1, X.shape[1], X.shape[2]) # NCHW format
    elif len(X.shape) == 4:
        # Already in NCHW format, do nothing
        pass
    else:
        raise ValueError("Input data must be 2D, 3D, or 4D array.")

    # Normalize pixel values to [0, 1]
    X = X.astype(np.float32) / 255.0

    # Convert data to PyTorch tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    # Data augmentation (basic)
    data_augmentation = cfg.get("data_augmentation")
    if data_augmentation == "horizontal_flip":
        X = torch.cat([X, torch.flip(X, dims=[3])], dim=0)
        y = torch.cat([y, y], dim=0)
    elif data_augmentation == "random_rotation":
        degrees = cfg.get("random_rotation_degree")
        # Simple rotation (replace with a proper augmentation library for better results)
        angle = np.random.uniform(-degrees, degrees)
        # rotation logic here would significantly increase code size

    # Define hyperparameters
    batch_size = cfg.get("batch_size")
    learning_rate = cfg.get("learning_rate")
    epochs = cfg.get("epochs")
    num_conv_layers = cfg.get("num_conv_layers")
    filters_layer_1 = cfg.get("filters_layer_1")
    filters_layer_2 = cfg.get("filters_layer_2") if num_conv_layers >= 2 else 0
    filters_layer_3 = cfg.get("filters_layer_3") if num_conv_layers >= 3 else 0
    filters_layer_4 = cfg.get("filters_layer_4") if num_conv_layers >= 4 else 0
    filters_layer_5 = cfg.get("filters_layer_5") if num_conv_layers >= 5 else 0
    kernel_size = cfg.get("kernel_size")
    pooling_type = cfg.get("pooling_type")
    num_dense_layers = cfg.get("num_dense_layers")
    dense_units_1 = cfg.get("dense_units_1")
    dense_units_2 = cfg.get("dense_units_2") if num_dense_layers >= 2 else 0
    dense_units_3 = cfg.get("dense_units_3") if num_dense_layers >= 3 else 0
    dropout_rate = cfg.get("dropout_rate")
    optimizer_name = cfg.get("optimizer")
    adam_beta1 = cfg.get("adam_beta1") if optimizer_name == 'adam' else 0.9
    adam_beta2 = cfg.get("adam_beta2") if optimizer_name == 'adam' else 0.999
    sgd_momentum = cfg.get("sgd_momentum") if optimizer_name == 'sgd' else 0.0
    rmsprop_rho = cfg.get("rmsprop_rho") if optimizer_name == 'rmsprop' else 0.9


    # Define CNN model
    class CNN(nn.Module):
        def __init__(self, num_classes, height, width):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, filters_layer_1, kernel_size=kernel_size)
            self.relu1 = nn.ReLU()
            self.pool1 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)

            conv_layers = [self.conv1, self.relu1, self.pool1]
            in_channels = filters_layer_1

            if num_conv_layers >= 2:
                self.conv2 = nn.Conv2d(in_channels, filters_layer_2, kernel_size=kernel_size)
                self.relu2 = nn.ReLU()
                self.pool2 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv2, self.relu2, self.pool2])
                in_channels = filters_layer_2
            else:
                self.conv2 = self.relu2 = self.pool2 = None

            if num_conv_layers >= 3:
                self.conv3 = nn.Conv2d(in_channels, filters_layer_3, kernel_size=kernel_size)
                self.relu3 = nn.ReLU()
                self.pool3 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv3, self.relu3, self.pool3])
                in_channels = filters_layer_3
            else:
                 self.conv3 = self.relu3 = self.pool3 = None

            if num_conv_layers >= 4:
                self.conv4 = nn.Conv2d(in_channels, filters_layer_4, kernel_size=kernel_size)
                self.relu4 = nn.ReLU()
                self.pool4 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv4, self.relu4, self.pool4])
                in_channels = filters_layer_4
            else:
                 self.conv4 = self.relu4 = self.pool4 = None

            if num_conv_layers >= 5:
                self.conv5 = nn.Conv2d(in_channels, filters_layer_5, kernel_size=kernel_size)
                self.relu5 = nn.ReLU()
                self.pool5 = nn.MaxPool2d(2) if pooling_type == "max" else nn.AvgPool2d(2)
                conv_layers.extend([self.conv5, self.relu5, self.pool5])
            else:
                 self.conv5 = self.relu5 = self.pool5 = None

            self.conv_layers = nn.Sequential(*conv_layers)

            # Calculate the output size of the convolutional layers dynamically
            test_input = torch.randn(1, 1, height, width)
            with torch.no_grad():
                output_conv = self.conv_layers(test_input)
            conv_output_size = output_conv.view(1, -1).size(1)

            dense_layers = []
            in_features = conv_output_size

            self.fc1 = nn.Linear(in_features, dense_units_1)
            self.relu_fc1 = nn.ReLU()
            self.dropout1 = nn.Dropout(dropout_rate)
            dense_layers.extend([self.fc1, self.relu_fc1, self.dropout1])
            in_features = dense_units_1

            if num_dense_layers >= 2:
                self.fc2 = nn.Linear(in_features, dense_units_2)
                self.relu_fc2 = nn.ReLU()
                self.dropout2 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc2, self.relu_fc2, self.dropout2])
                in_features = dense_units_2
            else:
                 self.fc2 = self.relu_fc2 = self.dropout2 = None

            if num_dense_layers >= 3:
                self.fc3 = nn.Linear(in_features, dense_units_3)
                self.relu_fc3 = nn.ReLU()
                self.dropout3 = nn.Dropout(dropout_rate)
                dense_layers.extend([self.fc3, self.relu_fc3, self.dropout3])
            else:
                 self.fc3 = self.relu_fc3 = self.dropout3 = None

            self.dense_layers = nn.Sequential(*dense_layers)
            in_features = dense_units_3 if num_dense_layers == 3 else dense_units_2 if num_dense_layers == 2 else dense_units_1

            self.fc_out = nn.Linear(in_features, num_classes)

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)  # Flatten
            x = self.dense_layers(x)
            x = self.fc_out(x)
            return x

    # Instantiate the model
    # Determine height and width based on the reshaped data
    if len(X.shape) == 4:
        height, width = X.shape[2], X.shape[3]
    else:
        raise ValueError("X tensor should have 4 dimensions after reshaping")
    model = CNN(num_classes, height, width)

    # Define loss function
    criterion = nn.CrossEntropyLoss()

    # Define optimizer
    if optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(adam_beta1, adam_beta2))
    elif optimizer_name == "sgd":
        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, rho=rmsprop_rho)
    else:
        raise ValueError(f"Unknown optimizer: {{optimizer_name}}")

    # Create data loader
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Training loop
    model.train()
    for epoch in range(epochs):
        for inputs, labels in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Return the final loss
    model.eval()
    with torch.no_grad():
        outputs = model(X)
        loss = criterion(outputs, y).item()

    return float(loss)

--------------------------------------------------------------------------------
[2025-06-08 11:31:17] [Metadata: {'component': 'train_function', 'status': 'success', 'loss': 0.35053908824920654}] Training executed successfully, loss: 0.35053908824920654
--------------------------------------------------------------------------------
