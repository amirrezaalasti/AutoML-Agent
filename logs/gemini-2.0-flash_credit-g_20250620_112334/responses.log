[2025-06-20 11:23:46] [Metadata: {'component': 'config'}] ```python
from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.forbidden import ForbiddenEqualsClause, ForbiddenAndConjunction

def get_configspace() -> ConfigurationSpace:
    """
    Creates a ConfigurationSpace for a Random Forest classifier, appropriate for
    the German Credit dataset.
    """
    cs = ConfigurationSpace()

    # Number of trees in the forest
    n_estimators = UniformIntegerHyperparameter(
        "n_estimators", lower=10, upper=200, default_value=100,
        q=10,  # Quantization: only multiples of 10 are allowed
        doc="Number of trees in the random forest"
    )
    cs.add_hyperparameter(n_estimators)

    # Criterion for splitting
    criterion = CategoricalHyperparameter(
        "criterion", choices=["gini", "entropy"], default_value="gini",
        doc="The function to measure the quality of a split"
    )
    cs.add_hyperparameter(criterion)

    # Maximum depth of the trees
    max_depth = UniformIntegerHyperparameter(
        "max_depth", lower=2, upper=32, default_value=10,
        q=2,  # Quantization: only multiples of 2 are allowed
        doc="Maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
    )
    cs.add_hyperparameter(max_depth)

    # Minimum number of samples required to split an internal node
    min_samples_split = UniformIntegerHyperparameter(
        "min_samples_split", lower=2, upper=20, default_value=2,
        q=1,
        doc="The minimum number of samples required to split an internal node"
    )
    cs.add_hyperparameter(min_samples_split)

    # Minimum number of samples required to be at a leaf node
    min_samples_leaf = UniformIntegerHyperparameter(
        "min_samples_leaf", lower=1, upper=20, default_value=1,
        q=1,
        doc="The minimum number of samples required to be at a leaf node"
    )
    cs.add_hyperparameter(min_samples_leaf)

    # Feature fraction to consider when looking for the best split
    max_features = UniformFloatHyperparameter(
        "max_features", lower=0.1, upper=1.0, default_value=1.0,
        doc="The number of features to consider when looking for the best split"
    )
    cs.add_hyperparameter(max_features)

    # Bootstrap samples
    bootstrap = CategoricalHyperparameter(
        "bootstrap", choices=[True, False], default_value=True,
        doc="Whether bootstrap samples are used when building trees."
    )
    cs.add_hyperparameter(bootstrap)

    # Conditional hyperparameter for max_samples
    max_samples = UniformFloatHyperparameter(
        "max_samples", lower=0.1, upper=1.0, default_value=1.0,
        doc="If bootstrap is True, the number of samples to draw from X to train each base estimator."
    )
    cs.add_hyperparameter(max_samples)

    # Condition max_samples requires bootstrap to be True
    condition = InCondition(child=max_samples, parent=bootstrap, values=[True])
    cs.add_condition(condition)

    # Add forbidden clause:  criterion == "entropy" and  min_samples_leaf > 5
    forbidden_clause_entropy_leaf = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "entropy"),
        ForbiddenEqualsClause(min_samples_leaf, 10)
    )

    # Add forbidden clause: criterion == "gini" and min_samples_split > 15
    forbidden_clause_gini_split = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "gini"),
        ForbiddenEqualsClause(min_samples_split, 18)
    )

    # Add forbidden clauses to the configuration space
    cs.add_forbidden_clause(forbidden_clause_entropy_leaf)
    cs.add_forbidden_clause(forbidden_clause_gini_split)


    return cs
```
--------------------------------------------------------------------------------
[2025-06-20 11:23:46] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.forbidden import ForbiddenEqualsClause, ForbiddenAndConjunction

def get_configspace() -> ConfigurationSpace:
    """
    Creates a ConfigurationSpace for a Random Forest classifier, appropriate for
    the German Credit dataset.
    """
    cs = ConfigurationSpace()

    # Number of trees in the forest
    n_estimators = UniformIntegerHyperparameter(
        "n_estimators", lower=10, upper=200, default_value=100,
        q=10,  # Quantization: only multiples of 10 are allowed
        doc="Number of trees in the random forest"
    )
    cs.add_hyperparameter(n_estimators)

    # Criterion for splitting
    criterion = CategoricalHyperparameter(
        "criterion", choices=["gini", "entropy"], default_value="gini",
        doc="The function to measure the quality of a split"
    )
    cs.add_hyperparameter(criterion)

    # Maximum depth of the trees
    max_depth = UniformIntegerHyperparameter(
        "max_depth", lower=2, upper=32, default_value=10,
        q=2,  # Quantization: only multiples of 2 are allowed
        doc="Maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
    )
    cs.add_hyperparameter(max_depth)

    # Minimum number of samples required to split an internal node
    min_samples_split = UniformIntegerHyperparameter(
        "min_samples_split", lower=2, upper=20, default_value=2,
        q=1,
        doc="The minimum number of samples required to split an internal node"
    )
    cs.add_hyperparameter(min_samples_split)

    # Minimum number of samples required to be at a leaf node
    min_samples_leaf = UniformIntegerHyperparameter(
        "min_samples_leaf", lower=1, upper=20, default_value=1,
        q=1,
        doc="The minimum number of samples required to be at a leaf node"
    )
    cs.add_hyperparameter(min_samples_leaf)

    # Feature fraction to consider when looking for the best split
    max_features = UniformFloatHyperparameter(
        "max_features", lower=0.1, upper=1.0, default_value=1.0,
        doc="The number of features to consider when looking for the best split"
    )
    cs.add_hyperparameter(max_features)

    # Bootstrap samples
    bootstrap = CategoricalHyperparameter(
        "bootstrap", choices=[True, False], default_value=True,
        doc="Whether bootstrap samples are used when building trees."
    )
    cs.add_hyperparameter(bootstrap)

    # Conditional hyperparameter for max_samples
    max_samples = UniformFloatHyperparameter(
        "max_samples", lower=0.1, upper=1.0, default_value=1.0,
        doc="If bootstrap is True, the number of samples to draw from X to train each base estimator."
    )
    cs.add_hyperparameter(max_samples)

    # Condition max_samples requires bootstrap to be True
    condition = InCondition(child=max_samples, parent=bootstrap, values=[True])
    cs.add_condition(condition)

    # Add forbidden clause:  criterion == "entropy" and  min_samples_leaf > 5
    forbidden_clause_entropy_leaf = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "entropy"),
        ForbiddenEqualsClause(min_samples_leaf, 10)
    )

    # Add forbidden clause: criterion == "gini" and min_samples_split > 15
    forbidden_clause_gini_split = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "gini"),
        ForbiddenEqualsClause(min_samples_split, 18)
    )

    # Add forbidden clauses to the configuration space
    cs.add_forbidden_clause(forbidden_clause_entropy_leaf)
    cs.add_forbidden_clause(forbidden_clause_gini_split)


    return cs

--------------------------------------------------------------------------------
[2025-06-20 11:23:46] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#1): UniformIntegerHyperparameter.__init__() got an unexpected keyword argument 'q'
--------------------------------------------------------------------------------
[2025-06-20 11:23:50] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.forbidden import ForbiddenEqualsClause, ForbiddenAndConjunction

def get_configspace() -> ConfigurationSpace:
    """
    Creates a ConfigurationSpace for a Random Forest classifier, appropriate for
    the German Credit dataset.
    """
    cs = ConfigurationSpace()

    # Number of trees in the forest
    n_estimators = UniformIntegerHyperparameter(
        "n_estimators", lower=10, upper=200, default_value=100,
        doc="Number of trees in the random forest"
    )
    cs.add_hyperparameter(n_estimators)

    # Criterion for splitting
    criterion = CategoricalHyperparameter(
        "criterion", choices=["gini", "entropy"], default_value="gini",
        doc="The function to measure the quality of a split"
    )
    cs.add_hyperparameter(criterion)

    # Maximum depth of the trees
    max_depth = UniformIntegerHyperparameter(
        "max_depth", lower=2, upper=32, default_value=10,
        doc="Maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
    )
    cs.add_hyperparameter(max_depth)

    # Minimum number of samples required to split an internal node
    min_samples_split = UniformIntegerHyperparameter(
        "min_samples_split", lower=2, upper=20, default_value=2,
        doc="The minimum number of samples required to split an internal node"
    )
    cs.add_hyperparameter(min_samples_split)

    # Minimum number of samples required to be at a leaf node
    min_samples_leaf = UniformIntegerHyperparameter(
        "min_samples_leaf", lower=1, upper=20, default_value=1,
        doc="The minimum number of samples required to be at a leaf node"
    )
    cs.add_hyperparameter(min_samples_leaf)

    # Feature fraction to consider when looking for the best split
    max_features = UniformFloatHyperparameter(
        "max_features", lower=0.1, upper=1.0, default_value=1.0,
        doc="The number of features to consider when looking for the best split"
    )
    cs.add_hyperparameter(max_features)

    # Bootstrap samples
    bootstrap = CategoricalHyperparameter(
        "bootstrap", choices=[True, False], default_value=True,
        doc="Whether bootstrap samples are used when building trees."
    )
    cs.add_hyperparameter(bootstrap)

    # Conditional hyperparameter for max_samples
    max_samples = UniformFloatHyperparameter(
        "max_samples", lower=0.1, upper=1.0, default_value=1.0,
        doc="If bootstrap is True, the number of samples to draw from X to train each base estimator."
    )
    cs.add_hyperparameter(max_samples)

    # Condition max_samples requires bootstrap to be True
    condition = InCondition(child=max_samples, parent=bootstrap, values=[True])
    cs.add_condition(condition)

    # Add forbidden clause:  criterion == "entropy" and  min_samples_leaf > 5
    forbidden_clause_entropy_leaf = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "entropy"),
        ForbiddenEqualsClause(min_samples_leaf, 10)
    )

    # Add forbidden clause: criterion == "gini" and min_samples_split > 15
    forbidden_clause_gini_split = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "gini"),
        ForbiddenEqualsClause(min_samples_split, 18)
    )

    # Add forbidden clauses to the configuration space
    cs.add_forbidden_clause(forbidden_clause_entropy_leaf)
    cs.add_forbidden_clause(forbidden_clause_gini_split)


    return cs
```
--------------------------------------------------------------------------------
[2025-06-20 11:23:50] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.forbidden import ForbiddenEqualsClause, ForbiddenAndConjunction

def get_configspace() -> ConfigurationSpace:
    """
    Creates a ConfigurationSpace for a Random Forest classifier, appropriate for
    the German Credit dataset.
    """
    cs = ConfigurationSpace()

    # Number of trees in the forest
    n_estimators = UniformIntegerHyperparameter(
        "n_estimators", lower=10, upper=200, default_value=100,
        doc="Number of trees in the random forest"
    )
    cs.add_hyperparameter(n_estimators)

    # Criterion for splitting
    criterion = CategoricalHyperparameter(
        "criterion", choices=["gini", "entropy"], default_value="gini",
        doc="The function to measure the quality of a split"
    )
    cs.add_hyperparameter(criterion)

    # Maximum depth of the trees
    max_depth = UniformIntegerHyperparameter(
        "max_depth", lower=2, upper=32, default_value=10,
        doc="Maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
    )
    cs.add_hyperparameter(max_depth)

    # Minimum number of samples required to split an internal node
    min_samples_split = UniformIntegerHyperparameter(
        "min_samples_split", lower=2, upper=20, default_value=2,
        doc="The minimum number of samples required to split an internal node"
    )
    cs.add_hyperparameter(min_samples_split)

    # Minimum number of samples required to be at a leaf node
    min_samples_leaf = UniformIntegerHyperparameter(
        "min_samples_leaf", lower=1, upper=20, default_value=1,
        doc="The minimum number of samples required to be at a leaf node"
    )
    cs.add_hyperparameter(min_samples_leaf)

    # Feature fraction to consider when looking for the best split
    max_features = UniformFloatHyperparameter(
        "max_features", lower=0.1, upper=1.0, default_value=1.0,
        doc="The number of features to consider when looking for the best split"
    )
    cs.add_hyperparameter(max_features)

    # Bootstrap samples
    bootstrap = CategoricalHyperparameter(
        "bootstrap", choices=[True, False], default_value=True,
        doc="Whether bootstrap samples are used when building trees."
    )
    cs.add_hyperparameter(bootstrap)

    # Conditional hyperparameter for max_samples
    max_samples = UniformFloatHyperparameter(
        "max_samples", lower=0.1, upper=1.0, default_value=1.0,
        doc="If bootstrap is True, the number of samples to draw from X to train each base estimator."
    )
    cs.add_hyperparameter(max_samples)

    # Condition max_samples requires bootstrap to be True
    condition = InCondition(child=max_samples, parent=bootstrap, values=[True])
    cs.add_condition(condition)

    # Add forbidden clause:  criterion == "entropy" and  min_samples_leaf > 5
    forbidden_clause_entropy_leaf = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "entropy"),
        ForbiddenEqualsClause(min_samples_leaf, 10)
    )

    # Add forbidden clause: criterion == "gini" and min_samples_split > 15
    forbidden_clause_gini_split = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "gini"),
        ForbiddenEqualsClause(min_samples_split, 18)
    )

    # Add forbidden clauses to the configuration space
    cs.add_forbidden_clause(forbidden_clause_entropy_leaf)
    cs.add_forbidden_clause(forbidden_clause_gini_split)


    return cs

--------------------------------------------------------------------------------
[2025-06-20 11:23:50] [Metadata: {'error_type': 'CONFIG_ERROR'}] [CONFIG_ERROR] Error in config (#2): UniformIntegerHyperparameter.__init__() got an unexpected keyword argument 'doc'
--------------------------------------------------------------------------------
[2025-06-20 11:23:55] [Metadata: {'component': 'config', 'action': 'fix'}] ```python
from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.forbidden import ForbiddenEqualsClause, ForbiddenAndConjunction

def get_configspace() -> ConfigurationSpace:
    """
    Creates a ConfigurationSpace for a Random Forest classifier, appropriate for
    the German Credit dataset.
    """
    cs = ConfigurationSpace()

    # Number of trees in the forest
    n_estimators = UniformIntegerHyperparameter(
        "n_estimators", lower=10, upper=200, default_value=100
    )
    cs.add_hyperparameter(n_estimators)
    n_estimators.doc = "Number of trees in the random forest"

    # Criterion for splitting
    criterion = CategoricalHyperparameter(
        "criterion", choices=["gini", "entropy"], default_value="gini"
    )
    cs.add_hyperparameter(criterion)
    criterion.doc = "The function to measure the quality of a split"

    # Maximum depth of the trees
    max_depth = UniformIntegerHyperparameter(
        "max_depth", lower=2, upper=32, default_value=10
    )
    cs.add_hyperparameter(max_depth)
    max_depth.doc = "Maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."

    # Minimum number of samples required to split an internal node
    min_samples_split = UniformIntegerHyperparameter(
        "min_samples_split", lower=2, upper=20, default_value=2
    )
    cs.add_hyperparameter(min_samples_split)
    min_samples_split.doc = "The minimum number of samples required to split an internal node"

    # Minimum number of samples required to be at a leaf node
    min_samples_leaf = UniformIntegerHyperparameter(
        "min_samples_leaf", lower=1, upper=20, default_value=1
    )
    cs.add_hyperparameter(min_samples_leaf)
    min_samples_leaf.doc = "The minimum number of samples required to be at a leaf node"

    # Feature fraction to consider when looking for the best split
    max_features = UniformFloatHyperparameter(
        "max_features", lower=0.1, upper=1.0, default_value=1.0
    )
    cs.add_hyperparameter(max_features)
    max_features.doc = "The number of features to consider when looking for the best split"

    # Bootstrap samples
    bootstrap = CategoricalHyperparameter(
        "bootstrap", choices=[True, False], default_value=True
    )
    cs.add_hyperparameter(bootstrap)
    bootstrap.doc = "Whether bootstrap samples are used when building trees."

    # Conditional hyperparameter for max_samples
    max_samples = UniformFloatHyperparameter(
        "max_samples", lower=0.1, upper=1.0, default_value=1.0
    )
    cs.add_hyperparameter(max_samples)
    max_samples.doc = "If bootstrap is True, the number of samples to draw from X to train each base estimator."

    # Condition max_samples requires bootstrap to be True
    condition = InCondition(child=max_samples, parent=bootstrap, values=[True])
    cs.add_condition(condition)

    # Add forbidden clause:  criterion == "entropy" and  min_samples_leaf > 5
    forbidden_clause_entropy_leaf = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "entropy"),
        ForbiddenEqualsClause(min_samples_leaf, 10)
    )

    # Add forbidden clause: criterion == "gini" and min_samples_split > 15
    forbidden_clause_gini_split = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "gini"),
        ForbiddenEqualsClause(min_samples_split, 18)
    )

    # Add forbidden clauses to the configuration space
    cs.add_forbidden_clause(forbidden_clause_entropy_leaf)
    cs.add_forbidden_clause(forbidden_clause_gini_split)


    return cs
```
--------------------------------------------------------------------------------
[2025-06-20 11:23:55] [Metadata: {'component': 'config', 'action': 'run'}] from ConfigSpace import ConfigurationSpace, UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter
from ConfigSpace.conditions import InCondition
from ConfigSpace.forbidden import ForbiddenEqualsClause, ForbiddenAndConjunction

def get_configspace() -> ConfigurationSpace:
    """
    Creates a ConfigurationSpace for a Random Forest classifier, appropriate for
    the German Credit dataset.
    """
    cs = ConfigurationSpace()

    # Number of trees in the forest
    n_estimators = UniformIntegerHyperparameter(
        "n_estimators", lower=10, upper=200, default_value=100
    )
    cs.add_hyperparameter(n_estimators)
    n_estimators.doc = "Number of trees in the random forest"

    # Criterion for splitting
    criterion = CategoricalHyperparameter(
        "criterion", choices=["gini", "entropy"], default_value="gini"
    )
    cs.add_hyperparameter(criterion)
    criterion.doc = "The function to measure the quality of a split"

    # Maximum depth of the trees
    max_depth = UniformIntegerHyperparameter(
        "max_depth", lower=2, upper=32, default_value=10
    )
    cs.add_hyperparameter(max_depth)
    max_depth.doc = "Maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."

    # Minimum number of samples required to split an internal node
    min_samples_split = UniformIntegerHyperparameter(
        "min_samples_split", lower=2, upper=20, default_value=2
    )
    cs.add_hyperparameter(min_samples_split)
    min_samples_split.doc = "The minimum number of samples required to split an internal node"

    # Minimum number of samples required to be at a leaf node
    min_samples_leaf = UniformIntegerHyperparameter(
        "min_samples_leaf", lower=1, upper=20, default_value=1
    )
    cs.add_hyperparameter(min_samples_leaf)
    min_samples_leaf.doc = "The minimum number of samples required to be at a leaf node"

    # Feature fraction to consider when looking for the best split
    max_features = UniformFloatHyperparameter(
        "max_features", lower=0.1, upper=1.0, default_value=1.0
    )
    cs.add_hyperparameter(max_features)
    max_features.doc = "The number of features to consider when looking for the best split"

    # Bootstrap samples
    bootstrap = CategoricalHyperparameter(
        "bootstrap", choices=[True, False], default_value=True
    )
    cs.add_hyperparameter(bootstrap)
    bootstrap.doc = "Whether bootstrap samples are used when building trees."

    # Conditional hyperparameter for max_samples
    max_samples = UniformFloatHyperparameter(
        "max_samples", lower=0.1, upper=1.0, default_value=1.0
    )
    cs.add_hyperparameter(max_samples)
    max_samples.doc = "If bootstrap is True, the number of samples to draw from X to train each base estimator."

    # Condition max_samples requires bootstrap to be True
    condition = InCondition(child=max_samples, parent=bootstrap, values=[True])
    cs.add_condition(condition)

    # Add forbidden clause:  criterion == "entropy" and  min_samples_leaf > 5
    forbidden_clause_entropy_leaf = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "entropy"),
        ForbiddenEqualsClause(min_samples_leaf, 10)
    )

    # Add forbidden clause: criterion == "gini" and min_samples_split > 15
    forbidden_clause_gini_split = ForbiddenAndConjunction(
        ForbiddenEqualsClause(criterion, "gini"),
        ForbiddenEqualsClause(min_samples_split, 18)
    )

    # Add forbidden clauses to the configuration space
    cs.add_forbidden_clause(forbidden_clause_entropy_leaf)
    cs.add_forbidden_clause(forbidden_clause_gini_split)


    return cs

--------------------------------------------------------------------------------
[2025-06-20 11:23:55] [Metadata: {'component': 'config', 'status': 'success'}] Configuration space generated successfully
--------------------------------------------------------------------------------
[2025-06-20 11:23:56] [Metadata: {'component': 'scenario'}] ```python
from smac import Scenario
from ConfigSpace import ConfigurationSpace

def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    scenario = Scenario(
        configspace=cs,
        name="HyperparameterOptimization",
        output_directory="./logs/gemini-2.0-flash_credit-g_20250620_112334",
        deterministic=False,
        n_trials=10,
        n_workers=1
    )
    return scenario
```
--------------------------------------------------------------------------------
[2025-06-20 11:23:56] [Metadata: {'component': 'scenario', 'action': 'run'}] from smac import Scenario
from ConfigSpace import ConfigurationSpace

def generate_scenario(cs: ConfigurationSpace) -> Scenario:
    scenario = Scenario(
        configspace=cs,
        name="HyperparameterOptimization",
        output_directory="./logs/gemini-2.0-flash_credit-g_20250620_112334",
        deterministic=False,
        n_trials=10,
        n_workers=1
    )
    return scenario

--------------------------------------------------------------------------------
[2025-06-20 11:23:56] [Metadata: {'component': 'scenario', 'status': 'success'}] Scenario generated successfully
--------------------------------------------------------------------------------
[2025-06-20 11:23:59] [Metadata: {'component': 'train_function'}] ```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

from ConfigSpace import Configuration
from typing import Any


def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a Random Forest model on the German Credit dataset using the provided configuration.

    Args:
        cfg (Configuration): A configuration object containing the hyperparameters for the Random Forest.
        dataset (Any): A dictionary containing the training and validation data.  Assumes keys 'X' and 'y'.
        seed (int): Random seed for reproducibility.

    Returns:
        float: Negative validation accuracy.
    """
    np.random.seed(seed)

    # Extract data
    X = dataset['X']
    y = dataset['y']

    # Split data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)

    # Handle categorical features using Label Encoding
    categorical_features = X.select_dtypes(include=['category']).columns
    for col in categorical_features:
        le = LabelEncoder()
        X_train[col] = le.fit_transform(X_train[col])
        X_val[col] = le.transform(X_val[col])

    # Extract hyperparameters from configuration
    n_estimators = cfg.get("n_estimators")
    criterion = cfg.get("criterion")
    max_depth = cfg.get("max_depth")
    min_samples_split = cfg.get("min_samples_split")
    min_samples_leaf = cfg.get("min_samples_leaf")
    max_features = cfg.get("max_features")
    bootstrap = cfg.get("bootstrap")
    max_samples = cfg.get("max_samples") if bootstrap else None

    # Instantiate and train the Random Forest classifier
    rf = RandomForestClassifier(
        n_estimators=n_estimators,
        criterion=criterion,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        max_features=max_features,
        bootstrap=bootstrap,
        max_samples=max_samples,
        random_state=seed,
        n_jobs=-1  # Use all available cores
    )

    rf.fit(X_train, y_train)

    # Make predictions on the validation set
    y_pred = rf.predict(X_val)

    # Calculate validation accuracy
    accuracy = accuracy_score(y_val, y_pred)

    # Return negative accuracy (SMAC minimizes)
    return -accuracy
```
--------------------------------------------------------------------------------
[2025-06-20 11:23:59] [Metadata: {'component': 'train_function', 'action': 'run'}] import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

from ConfigSpace import Configuration
from typing import Any


def train(cfg: Configuration, dataset: Any, seed: int) -> float:
    """
    Trains a Random Forest model on the German Credit dataset using the provided configuration.

    Args:
        cfg (Configuration): A configuration object containing the hyperparameters for the Random Forest.
        dataset (Any): A dictionary containing the training and validation data.  Assumes keys 'X' and 'y'.
        seed (int): Random seed for reproducibility.

    Returns:
        float: Negative validation accuracy.
    """
    np.random.seed(seed)

    # Extract data
    X = dataset['X']
    y = dataset['y']

    # Split data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)

    # Handle categorical features using Label Encoding
    categorical_features = X.select_dtypes(include=['category']).columns
    for col in categorical_features:
        le = LabelEncoder()
        X_train[col] = le.fit_transform(X_train[col])
        X_val[col] = le.transform(X_val[col])

    # Extract hyperparameters from configuration
    n_estimators = cfg.get("n_estimators")
    criterion = cfg.get("criterion")
    max_depth = cfg.get("max_depth")
    min_samples_split = cfg.get("min_samples_split")
    min_samples_leaf = cfg.get("min_samples_leaf")
    max_features = cfg.get("max_features")
    bootstrap = cfg.get("bootstrap")
    max_samples = cfg.get("max_samples") if bootstrap else None

    # Instantiate and train the Random Forest classifier
    rf = RandomForestClassifier(
        n_estimators=n_estimators,
        criterion=criterion,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        max_features=max_features,
        bootstrap=bootstrap,
        max_samples=max_samples,
        random_state=seed,
        n_jobs=-1  # Use all available cores
    )

    rf.fit(X_train, y_train)

    # Make predictions on the validation set
    y_pred = rf.predict(X_val)

    # Calculate validation accuracy
    accuracy = accuracy_score(y_val, y_pred)

    # Return negative accuracy (SMAC minimizes)
    return -accuracy

--------------------------------------------------------------------------------
[2025-06-20 11:24:00] [Metadata: {'component': 'train_function', 'status': 'success', 'loss': -0.7}] Training executed successfully, loss: -0.7
--------------------------------------------------------------------------------
