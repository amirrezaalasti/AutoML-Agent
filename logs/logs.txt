Running config code:
from ConfigSpace import ConfigurationSpace, Categorical, Float, Integer, Constant, EqualsCondition, ForbiddenAndConjunction, ForbiddenEqualsClause

def get_configspace():
    cs = ConfigurationSpace(seed=1234)

    learning_rate = Categorical('learning_rate', ['constant', 'invscaling', 'adaptive'], default='constant')
    eta0 = Float('eta0', bounds=(1e-7, 1e-1), default=1e-4, log=True)
    power_t = Float('power_t', bounds=(0, 1), default=0.5)

    cs.add([learning_rate, eta0, power_t])

    cs.add_condition(EqualsCondition(eta0, learning_rate, 'constant'))

    penalty_and_loss = ForbiddenAndConjunction(
        ForbiddenEqualsClause(learning_rate, "adaptive"),
        ForbiddenEqualsClause(power_t, 0)
    )
    cs.add_forbidden_clause(penalty_and_loss)

    return cs

Configuration space generated: Configuration space object:
  Hyperparameters:
    eta0, Type: UniformFloat, Range: [1e-07, 0.1], Default: 0.0001, on log-scale
    learning_rate, Type: Categorical, Choices: {constant, invscaling, adaptive}, Default: constant
    power_t, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5
  Conditions:
    eta0 | learning_rate == 'constant'
  Forbidden Clauses:
    (Forbidden: learning_rate == 'adaptive' && Forbidden: power_t == 0)

Running scenario code:
from smac import Scenario

def generate_scenario(cs):
    scenario = Scenario({
        "run_obj": "quality",
        "output_dir": "./automl_results",
        "shared_model": False,
        "multi_objectives": ["validation_loss"],
        "abort_on_first_run_crash": True,
        "wallclock_limit": 3600.0,
        "ta_run_limit": 100,
        "memory_limit": 16000.0,
        "cutoff": 3600.0,
        "deterministic": False
    })
    return scenario

Scenario generated: Scenario(configspace={'run_obj': 'quality', 'output_dir': './automl_results', 'shared_model': False, 'multi_objectives': ['validation_loss'], 'abort_on_first_run_crash': True, 'wallclock_limit': 3600.0, 'ta_run_limit': 100, 'memory_limit': 16000.0, 'cutoff': 3600.0, 'deterministic': False}, name=None, output_directory=PosixPath('smac3_output'), deterministic=False, objectives='cost', crash_cost=inf, termination_cost_threshold=inf, walltime_limit=inf, cputime_limit=inf, trial_walltime_limit=None, trial_memory_limit=None, n_trials=100, use_default_config=False, instances=None, instance_features=None, min_budget=None, max_budget=None, seed=0, n_workers=1)
Generated training function code:
```python
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    input_size = dataset['X'].shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(dataset['X'], dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size, 128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)
```
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    input_size = dataset['X'].shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(dataset['X'], dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size, 128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#1): expected sequence of length 60000 at dim 0 (got 784)
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    input_size = dataset['X'].shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(dataset['X'].reshape(-1, input_size), dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size,128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch 
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#2): 'DataFrame' object has no attribute 'reshape'
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    input_size = dataset['X'].shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(dataset['X'], dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size,128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch 
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#3): expected sequence of length 60000 at dim 0 (got 784)
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    input_size = dataset['X'].shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(dataset['X'].reshape(-1, input_size), dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size,128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch 
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#4): 'DataFrame' object has no attribute 'reshape'
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any
import pandas as pd

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: pd.DataFrame) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    X = dataset.drop('y', axis=1).values
    y = dataset['y'].values
    input_size = X.shape[1]
    num_classes = len(np.unique(y))

    # Create dataset and data loader
    dataset = ImageDataset(X, y)
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size,128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch 
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over10 epochs
    return np.mean(losses)

Error in train_function (#5): 'dict' object has no attribute 'drop'
Retry limit reached for train_function. Fetching fresh code from LLM.
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    input_size = dataset['X'].shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(dataset['X'], dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size, 128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#1): expected sequence of length 60000 at dim 0 (got 784)
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: Any) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    X = np.array(dataset['X']).reshape(-1, 784) # Assuming 784 is the expected input size
    input_size = X.shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(X, dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size,128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, momentum=power_t)
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#2): '<=' not supported between instances of 'float' and 'NoneType'
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: dict) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    X = np.array(dataset['X']).reshape(-1, 784)  # Assuming 784 is the expected input size
    input_size = X.shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(X, dataset['y'].tolist()) # Convert to list
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size, 128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t')
            optimizer = optim.SGD(model.parameters(), lr=eta0, power_t=power_t) # corrected parameter
        except:
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#3): '<=' not supported between instances of 'float' and 'NoneType'
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: dict) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    X = np.array(dataset['X'])
    if X.ndim == 1 or X.shape[1] == 784:
        X = X.reshape(-1, 784) 
    else:
        X = X.reshape(X.shape[0], -1)
    input_size = X.shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(X, dataset['y']) 
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size, 128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0')
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t', 0.25) # Provide a default value
            optimizer = optim.SGD(model.parameters(), lr=eta0, power_t=power_t) 
        except Exception as e:
            print(f"An error occurred: {e}")
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Error in train_function (#4): '<=' not supported between instances of 'float' and 'NoneType'
Running train_function code:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from ConfigSpace import Configuration
from typing import Any

class ImageDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def train(cfg: Configuration, seed: int, dataset: dict) -> float:
    # Set random seed for reproducibility
    np.random.seed(seed)
    torch.manual_seed(seed)

    # Infer input and output dimensions dynamically from the dataset
    X = np.array(dataset['X'])
    if X.ndim == 1 or X.shape[1] == 784:
        X = X.reshape(-1, 784)
    else:
        X = X.reshape(X.shape[0], -1)
    input_size = X.shape[1]
    num_classes = len(np.unique(dataset['y']))

    # Create dataset and data loader
    dataset = ImageDataset(X, dataset['y'])
    data_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # Define model
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.fc1 = nn.Linear(input_size, 128)
            self.fc2 = nn.Linear(128, num_classes)

        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()

    learning_rate = cfg.get('learning_rate')
    eta0 = cfg.get('eta0', 0.01)  # Provide a default value
    if learning_rate == 'constant':
        optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'invscaling':
        try:
            power_t = cfg.get('power_t', 0.25)  # Provide a default value
            optimizer = optim.SGD(model.parameters(), lr=eta0, power_t=power_t)
        except Exception as e:
            print(f"An error occurred: {e}")
            optimizer = optim.SGD(model.parameters(), lr=eta0)
    elif learning_rate == 'adaptive':
        optimizer = optim.Adam(model.parameters(), lr=eta0)

    # Train model
    losses = []
    for epoch in range(10):
        for batch in data_loader:
            inputs, labels = batch
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            losses.append(loss.item())

    # Return average training loss over 10 epochs
    return np.mean(losses)

Training executed, loss: 2.0110555472199123
